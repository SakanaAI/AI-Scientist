# PROVABLE LEARNING-BASED ALGORITHM FOR SPARSE RECOVERY


**Xinshi Chen & Haoran Sun**
School of Mathematics
Georgia Institute of Technology
Atlanta, USA
_{xinshi.chen,haoransun}@gatech.edu_

ABSTRACT


**Le Song**
Machine Learning Department
MBZUAI & BioMap
UAE & China
songle@biomap.com


Recovering sparse parameters from observational data is a fundamental problem
in machine learning with wide applications. Many classic algorithms can solve
this problem with theoretical guarantees, but their performances rely on choosing
the correct hyperparameters. Besides, hand-designed algorithms do not fully exploit the particular problem distribution of interest. In this work, we propose a
deep learning method for algorithm learning called PLISA (Provable Learningbased Iterative Sparse recovery Algorithm). PLISA is designed by unrolling a
classic path-following algorithm for sparse recovery, with some components being more flexible and learnable. We theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, we analyze the empirical Rademacher
complexity of PLISA to characterize its generalization ability to solve new problems outside the training set. This paper contains novel theoretical contributions to
the area of learning-based algorithms in the sense that (i) PLISA is generically applicable to a broad class of sparse estimation problems, (ii) generalization analysis
has received less attention so far, and (iii) our analysis makes novel connections
between the generalization ability and algorithmic properties such as stability and
convergence of the unrolled algorithm, which leads to a tighter bound that can
explain the empirical observations. The techniques could potentially be applied to
analyze other learning-based algorithms in the literature.

INTRODUCTION


The problem of recovering a sparse vector Î²[âˆ—] from finite observations Z1:n (PÎ²âˆ— )[n] is fundamental in machine learning,
covering a broad family of problems including compressed âˆ¼

**observations ğ’ğŸ:ğ’** **true parameter ğœ·[âˆ—]**

sensing, sparse regression analysis, graphical model estimation, etc. It has also found applications in various domains.
For example, in magnetic resonance imaging, sparse signals
need to be reconstructed from measurements taken by a scanner. In computational biology, estimating a sparse graph structure from gene expression data is important for understanding
gene regulatory networks.


_MRI image_ _clean image_

_gene expression data_ _gene regulatory network_

Figure 1: Sparse recovery problems.


Various classic algorithms are available for solving sparse recovery problems. Many of them come
with theoretical guarantees for the recovery accuracy. However, the theoretical performance often
relies on choosing the correct hyperparameters, such as regularization parameters and the learning
rate, which may depend on unknown constants. Furthermore, in practice, similar problems may
need to be solved repeatedly, but it is hard for classic algorithms to fully utilize this information.

To alleviate these limitations, we consider the approach of learning-to-learn and propose a neural
algorithm, called PLISA (Provable Learning-based Iterative Sparse recovery Algorithm). PLISA
is a deep learning model that takes the observations Z1:n as the input and outputs an estimation for
**_Î²[âˆ—]. To make use of classic techniques developed by domain experts, we design the architecture_**
of PLISA by unrolling and modifying a classic path-following algorithm proposed by Wang et al.


-----

(2014). To benefit from learning, some components in this classic algorithm are made more flexible
with careful design and treated as learnable parameters in PLISA. These parameters can be learned
by optimizing the performances on a set of training problems. The learned PLISA can then be used
for solving other problems in the target distribution.

With the algorithm design problem converted to a deep learning problem, we ask the two fundamental questions in learning theory:

1. Capacity: Whatâ€™s the recovery accuracy achievable by PLISA? Can the flexible components in
PLISA lead to an algorithm which effectively improves the recovery performance?

2. Generalization: How well can the learned PLISA solve new problems outside the training set?
Is the generalization behavior related to the algorithmic properties of PLISA?

Aiming at supplying rigorous answers to these questions, we conduct theoretical analysis for PLISA
to provide guarantees for its representation and generalization ability. The results and the techniques
in our analysis can distinguish our work from existing studies on algorithm learning. We summarize
our novel contributions into the following three aspects.

**1. Theoretical understanding. In contrast to the plethora of empirical studies on algorithm learn-**
ing, there have been relatively few studies devoted to the theoretical understanding. Existing theoretical efforts primarily focus on analyzing the convergence rate achievable by the neural algorithm (Chen et al., 2018; Liu et al., 2019a; Zhang & Ghanem, 2018; Wu et al., 2020), but the
generalization error bound has received less attention so far. A substantial body of works only argue
intuitively that algorithm unrolling architectures can generalize well because they contain a small
number of parameters. In comparison, we provide theoretical guarantees for both the capacity and
the generalization ability of PLISA, which are more solid arguments.

**2. General setting. The problem setting in this paper is new and more challenging. Existing**
works mainly focus on a specific problem. For example, the compressed sensing problem with a
fixed design matrix is the mostly investigated one. PLISA, however, is generic and is applicable to
various sparse recovery problems as long as they satisfy certain conditions in Assumption C.1.

**3. Novel connection. The algorithmic structure in PLISA can make it behaves differently from**
conventional neural networks. Therefore, we largely utilize the analysis techniques in classic algorithms to derive its generalization bound. By combining the analysis tools of deep learning theory
and optimization algorithms, our result reveals a novel connection between the generalization ability
of PLISA and the algorithmic properties including the convergence rate and stability of the unrolled
algorithm. Benefit from this connection, our generalization bound is tight in the sense that it matches
the interesting behavior of PLISA observed in experiments - the generalization gap could decrease
in the number of layers, which is rarely observed in conventional neural networks.

2 PLISA: LEARNING TO SOLVE SPARSE ESTIMATION PROBLEMS

A sparse estimation problem is to recover Î²[âˆ—] from finite observations Z1:n sampled from PÎ²âˆ— .
As a concrete example, in a sparse linear regression problem, n observations _Zi = (xi, yi)_ _i=1_
_{_ _}[n]_
are sampled from a linear model y = x[âŠ¤]Î²[âˆ—] + Ïµ, and an algorithm needs to estimate Î²[âˆ—] from n
observations. Classic algorithms recover Î²[âˆ—] by minimizing a regularized empirical loss:
**_Î²Î»_** arg min Ln(Z1:n, Î²) + P (Î», Î²), (1)
_âˆˆ_
where Ln is an empirical loss that measures the â€œfitâ€ between the parameter Î² and observations
_Z1:n, and P_ (Î», Î²) is a sparsity regularization with coefficientb _Î». When Ln is the least square loss_
and P (Î», Î²) is Î» **_Î²_** 1, the optimization is known as LASSO and can be solved by the well-known
_âˆ¥_ _âˆ¥_
algorithm ISTA (Daubechies et al., 2004). Based on the idea of algorithm unrolling, Gregor &
LeCun (2010) proposed LISTA, a neural algorithm that interprets ISTA as layers of neural networks.
It has been demonstrated that LISTA outperforms ISTA thanks to its learnable components. Since
then, designing neural algorithms by unrolling ISTA has become an active research topic. However,
existing works mostly focus on the compressed sensing problem with a fixed design matrix only.

To enable for more general applicability, we design the architecture of PLISA by unrolling a classic path-following algorithm called APF (Wang et al., 2014) instead of ISTA. APF is applicable
to nonconvex losses and nonconvex penalty functions, covering a considerably larger range of objectives than LASSO. Designing the architecture based on APF allows PLISA to be applicable to


-----

a broader class of problems such as nonlinear sparse regression, graphical model estimation, etc.
Furthermore, employing nonconvexity can potentially lead to better statistical properties (Fan & Li,
2001; Fan et al., 2009; Loh & Wainwright, 2015), for which we will explain more in Section 3.

In the following, we will introduce APF and the architecture of our proposed PLISA. After that, we
will describe how to optimize the parameters in PLISA under the learning-to-learn setting.

2.1 A BRIEF INTRODUCTION TO APF

We briefly introduce the classic algorithm APF (Wang et al., 2014), and its details are presented in
Algorithm 3 in Appendix I. The key idea of path-following algorithms is creating a sequence of T
**many sub-objectives to gradually approach the target objective that is supposed to be more difficult**
to solve. More specifically, APF approximates the local minimizers of a sequence of sub-objectives:

**_Î²t_** **_Î²Î»t_** arg min _Ln(Z1:n, Î²) + P_ (Î»t, Î²), for t = 1, _, T,_ (2)
_â‰ˆ_ [b] _âˆˆ_ **_Î²_** _Â· Â· Â·_

where Î»1 > Î»2 > Â· Â· Â· > Î»T is a decreasing sequence of regularization parameters. The last
parameter Î»T is the target regularization parameter. As a result, APF contains T blocks, and each
block contains an iterative algorithm that minimizes one sub-objective in Eq. 2. The output of the
(t 1)-th block, denoted by Î²t 1, is used as the initialization of the t-th block, i.e., **_Î²t[0]_** [=][ Î²][t][âˆ’][1][.]
_âˆ’_ _âˆ’_
Then the t-th block minimizes the t-th sub-objective by the modified proximal gradient algorithm:

[e]

for k = 1, _, K,_ **_Î²t[k]_** _t_ **_Î²t[k][âˆ’][1]_** _Î±_ **_Î²Ln(Z1:n,_** **_Î²t[k][âˆ’][1]) +_** **_Î²Q(Î»t,_** **_Î²t[k][âˆ’][1])_** _._ (3)
_Â· Â· Â·_ _[â†T][Î±][Â·][Î»]_ _âˆ’_ _âˆ‡_ _âˆ‡_

output of t-th block: eÎ²t = **_Î²t[K][.]_**  e   [e] [e] [] (4)

The notation _Î´(Î²) := sign(Î²) max_ **_Î²_** _Î´, 0_ is the soft-thresholding function, and the function
_T_ [e] _{|_ _| âˆ’_ _}_
_Q is the concave component of P defined as Q(Î», Î²) := P_ (Î», Î²) _Î»_ **_Î²_** 1. The number of steps K
_âˆ’_ _âˆ¥_ _âˆ¥_
in each block is determined by certain stopping criteria. It can be seem that the update steps in each
block is similar to the ISTA algorithm, but it is modified in order to incorporate nonconvexity.



2.2 ARCHITECTURE OF PLISA

The architecture of PLISA is designed by unrolling the APF algorithm, and augmenting some learnable parameters Î¸. Therefore, the
architecture of PLISAÎ¸ contains T blocks and each block contains K
layers defined by the K-step algorithm in Eq. 3 (See Figure 2). Note
that in PLISAÎ¸, both K and T are pre-defined. The architecture of
PLISAÎ¸ is different from APF as summarized below:

1. Element-wise and learnable regularization parameters. Most
classic algorithms including APF employ a uniform regularization parameter Î»t across all entries of Î², but PLISAÎ¸ uses a ddimensional vector Î»t = [Î»t,1, Â· Â· Â·, Î»t,d][âŠ¤] to enforce different
levels of sparsity to different entries in Î². Furthermore, the regularization parameters in PLISAÎ¸ are learnable, which will be optimized during the training.


2. Learnable penalty function: Classic algorithms use a pre-defined input âˆ‡ğ¿!(ğ‘":!, ğŸ)
sparse penalty function P, but PLISAÎ¸ parameterizes it as a com- Figure 2: Architecture.

ğœ·$

_algorithm stepscell0ğ’˜,ğœ¶_ ğ€
ğœ·$%"

â€¦ â€¦

ğœ·# ğœ¼,ğ€[âˆ—]

_algorithm stepscell0ğ’˜,ğœ¶_ ğ€,

ğœ·" ğœ¼,ğ€[âˆ—]

cell0ğ’˜,ğœ¶ ğ€!

_algorithm steps_

ğœ·! = ğŸ ğœ¼,ğ€[âˆ—]

inputğ‘!:# âˆ‡ğ¿!(ğ‘":!, ğŸ) ğ€$

bination of q different penalty functions and learns the weights of each penalty. In other words,
PLISAÎ¸ can learn to select a specific combination of the penalty functions from training data.

3. Learnable step size: The step sizes in APF are selected by line-search but they are learnable in
PLISAÎ¸. Experimentally, we find the learned step sizes lead to a much faster algorithm.

In later sections of this paper, we will show how such differences can make PLISAÎ¸ perform better
than APF both empirically and theoretically.

Algorithm 1 and 2 present the mathematical details of the architecture, follow which we explain
some notations and definitions. Red-colored symbols indicate learnable parameters in PLISAÎ¸.


-----

**Algorithm 1: PLISAÎ¸ architecture**


**Algorithm 2: Layers in each block Block[K]w,Î±**


_#blocks: T_, #layers per block: K
_Parameters: Î¸ = {Î·, Î»[âˆ—], w, Î±}_
_Input: samples Z1:n_
**_Î²0_** **0,** **_Î»0_** **_Î²Ln(Z1:n, 0)_**
**For â† t = 1, . . ., T â†âˆ‡ do**

**_Î»t â†_** max {Ïƒ(Î·) â—¦ **_Î»tâˆ’1, Î»[âˆ—]}_**
**_Î²t â†_** Block[K]w,Î±[(][Z][1:][n][,][ Î²][t][âˆ’][1][,][ Î»][t][)]

**return Î²T**


_#blocks: T_, #layers per block: K
_Input:Parameters: samples Î¸ = Z {1:nÎ·, Î»[âˆ—], w, Î±}_ _Input:Î²t[0]_ _Z1:n, Î²tâˆ’1, Î»t_
**_Î²0_** **0,** **_Î»0_** **_Î²Ln(Z1:n, 0)_** **For[â†] k = 1[Î²][t][âˆ’], . . ., K[1]** **do**
**For â† t = 1, . . ., T â†âˆ‡ do** **1** e **_gt[k]_** **_Î²t[k][âˆ’][1]) +_** **_Î²Qw(Î»t,_** **_Î²t[k][âˆ’][1])_**

**_Î»t â†_** max {Ïƒ(Î·) â—¦ **_Î»tâˆ’1, Î»[âˆ—]}_** **_Î²t[k]_** _[â†âˆ‡][Î²][L]t[n][(][Z]Î²[1:]t[k][âˆ’][n][1][,][ e]_ _Î±_ **_gt[k] âˆ‡_**
**_Î²t_** Block[K]w,Î±[(][Z][1:][n][,][ Î²][t][âˆ’][1][,][ Î»][t][)] _[â†T][Î±][Â·][Î»]_ _âˆ’_ _Â·_ [e]

**return â† Î²T** **return Î²t =** **_Î²t[K]_** 

e e

**Regularzation parameters. In PLISAÎ¸, the element-wise regularization parameters are initialized[e]**
by a vector Î»0 := âˆ‡Î²Ln(Z1:n, 0), and then updated sequentially by
**_Î»t â†_** max {Ïƒ(Î·) â—¦ **_Î»tâˆ’1, Î»[âˆ—]},_** (5)
where Ïƒ(Â·), â—¦, and max{Â·, Â·} are element-wise sigmoid function, multiplication, and maximization.
_{Î·, Î»[âˆ—]} are both d-dimensional learnable parameters. Eq. 5 creates a sequence Î»1, Â· Â· Â·, Î»T through_
the decrease ratio Ïƒ(Î·), until they reach the target regularization parameters Î»[âˆ—].

**Penalty function. PLISAÎ¸ parameterizes the penalty function as follows,**

exp(wi)
_Pw(Î», Î²) =_ _i=1_ _wi_ _P_ [(][i][)](Î», Î²), where _wi =_ _q_ (6)

In other words,weights of these functions are determined by learnable parameters Pw is a learnable convex combination of[P][q] [f] Â· _q penalty functions f_ **_wP = [i[â€²]_** =1w[exp(]1, (P[w][i], w[(1)][â€²] [)] _[.], Â· Â· Â·q]. In this paper,, P_ [(][q][)]). The
_Â· Â· Â·_
we focus on learning the combination of three well-known penalty functions:

_P_ [(1)](Î», Î²) = âˆ¥Î» â—¦ **_Î²âˆ¥1, P_** [(2)](Î», Î²) = _j=1_ [MCP(][Î»][j][, Î²][j][)][, P][ (3)][(][Î»][,][ Î²][) =][ P]j[d]=1 [SCAD(][Î»][j][, Î²][j][)][,]

where P [(1)] is convex, and MCP (Zhang, 2010a) and SCAD (Fan & Li, 2001) are nonconvex penal_ties whose analytical forms are given in Appendix[P][d]_ B. One can include any other penalty functions as
long as they satisfy a set of conditions specified in Appendix B. Qw(Î», Î²) := Pw(Î», Î²) **_Î»_** **_Î²_** 1
_âˆ’âˆ¥_ _â—¦_ _âˆ¥_
represents the concave component of Pw. The analytical form of **_Î²Qw(Î»t, Î²) are in Appendix B._**
_âˆ‡_


2.3 LEARNING-TO-LEARN SETTING

Now we describe how to train the parameters Î¸ in PLISAÎ¸ under the learning-to-learn setting.

**Training set. Similar to other works in this domain, we assume the access to m problems from the**
target problem-space P, and use them as the training set:

_Dm = {(Z1:[(1)]n1_ _[,][ Î²][âˆ—][(1)][)][,][ Â· Â· Â·][,][ (][Z]1:[(][m]n[)]m_ _[,][ Î²][âˆ—][(][m][)][)][}]_ with (Z1:[(][i]n[)] _i_ _[,][ Î²][âˆ—][(][i][)][)][ âˆˆP][.]_
Here each estimation problem is represented by a pair of observations and the corresponding true
parameter to be recovered. A different problem i can contain a different number ni of observations.

**Training loss. Since the intermediate outputs Î²t(Z1:n; Î¸) of PLISAÎ¸ are also estimates of Î²[âˆ—], a**
common design of the training loss is the weighted sum of the intermediate estimation errors (Chen
et al., 2021). More specifically, we employ the following training loss:

_m_ _T_

2

_train[(][D][m][;][ Î¸][) := 1]_ _Î³[T][ âˆ’][t]_ **_Î²t(Z1:[(][i]n[)]_** _i_ [;][ Î¸][)][ âˆ’] **_[Î²][âˆ—][(][i][)]_** (7)
_L[Î³]_ _m_ 2 _[,]_

_i=1_ _t=1_

X X

where Î³ < 1 is a discounting factor If Î³ = 0 then the loss is only estimated at the last layer.

**Generalization error. The ultimate goal of algorithm learning is to minimize the estimation error**
on expectation over all problems in the target problem distribution:

_Lgen(P(P); Î¸) := E(Z1:n,Î²âˆ—)âˆ¼P(P) âˆ¥Î²T (Z1:n; Î¸) âˆ’_ **_Î²[âˆ—]âˆ¥2[2]_** _[,]_ (8)

where P(P) is a distribution in the target problem-space P. Let Î¸[âˆ—] _âˆˆ_ arg min Ltrain[Î³][=0] [(][D][m][;][ Î¸][)][ be a]
minimizer of the training loss. It is well-known that the generalization error can be bounded by:


_Lgen(P(P); Î¸[âˆ—]) â‰¤Lgen(P(P); Î¸[âˆ—]) âˆ’Ltrain[Î³][=0]_ [(][D][m][;][ Î¸][âˆ—][)] + _Ltrain[Î³][=0]_ [(][D][m][;][ Î¸][âˆ—][)]
generalization gap: Theorem 4.1 training error: Theorem 3.1

We will theoretically characterize these two terms in Theorem 3.1 and Theorem 4.1.

| {z } | {z }


(9)


-----

3 CAPACITY OF PLISA

Can PLISAÎ¸ achieve a small training error without using too many layers? How can designs of
element-wise regularization and learnable penalty functions help PLISAÎ¸ to achieve a smaller training error compared to classic algorithms? We answer this question theorectically in this section.

3.1 FIRST MAIN RESULT: CAPACITY

Let Î²t(Z1:n; Î¸) be the output of the t-th block in PLISAÎ¸. Let x _a denote entry-wise maximal_
_âˆ¨_
value max{x, a}. Let (x)S denote the sub-vector of x with entries indexed by the set S.
_TTheorem 3.1 be the number of blocks in (Capacity). Assume the problem space PLISAÎ¸ and let K be the number of layers in each block. For any P satisfies Assumption C.1 and Dm âŠ†P. Let_
_Îµ > 0, there exists a set of parameters Î¸ = {Î·, Î»[âˆ—], w, Î±} such that the estimation error of every_
_problem (Z1:n, Î²[âˆ—]) âˆˆDm is bounded as follows, âˆ€T > t0,_

_âˆ¥Î²T (Z1:n; Î¸) âˆ’_ **_Î²[âˆ—]âˆ¥2 â‰¤_** _Îµ[âˆ’][1]cÎ¸s[âˆ—]_ exp(âˆ’CÎ¸K(T âˆ’ _t0))_ **_optimization error_** (10)

+ c[â€²]Î¸[Îº][m][âˆ¥] [(][âˆ‡][Î²][L][n][(][Z][1:][n][,][ Î²][âˆ—][)][ âˆ¨] _[Îµ][)]S[âˆ—]_ _[âˆ¥][2][,]_ **_statistical error_** (11)
_where S[âˆ—]_ := supp(Î²[âˆ—]) is the support indices of Î²[âˆ—], cÎ¸, c[â€²]Î¸[, and][ C][Î¸][ are some positive values de-]
_pending on the chosen Î¸, and Îºm is a condition number which reveals the similarity of the problems_
_in Dm. Note that K and t0 are required to be larger than certain values, but we will elaborate in_
_Appendix E that the required lower bounds are small. See Appendix E for the proof of this theorem._

This estimation error can be interpreted as a combination of the optimization error (in Eq. 10) and the
statistical error (in Eq. 11). The optimization error decreases linearly in both K and T . The statistical
erroroccurs because of the randomness in Z1:n. The gradient at the true parameter **_Î²Ln(Z1:n, Î²[âˆ—])_**
_âˆ‡_
characterizes how well the finite samples Z1:n can represent the distribution PÎ²âˆ— .

A direct consequence of Theorem 3.1 is that the training error can be small without using too many
layers and blocks in PLISAÎ¸. We will also elaborate on how the entry-wise regularization and
learnable penalty function can effectively reduce the training error in the following.

_(i) Impact of entry-wise regularization. Restricting the regularization to be uniform across entries_
will lead to an error bound that replaces the statistical error ( **_Î²Ln(Z1:n, Î²[âˆ—])_** _Îµ)Sâˆ—_ 2 in Eq. 11
_âˆ¥_ _âˆ‡_ _âˆ¨_ _âˆ¥_
by _âˆšs[âˆ—]_ (âˆ¥âˆ‡Î²Ln(Z1:n, Î²[âˆ—])âˆ¥âˆ _âˆ¨_ _Îµ). To understand how the former has improved the latter, we_

can consider the sparse linear regression problem. If the design matrix is normalized such that
max1â‰¤jâ‰¤d âˆ¥([x1]j, Â· Â· Â·, [xn]j)âˆ¥2 â‰¤ _[âˆš]n, then âˆ¥_ (âˆ‡Î²Ln(Z1:n, Î²[âˆ—]) âˆ¨ _Îµ)Sâˆ—_ _âˆ¥2 â‰¤_ _C_ _s[âˆ—]/n with high_

probability. In comparison, _âˆšs[âˆ—]_ **_Î²Ln(Z1:n, Î²[âˆ—])_** _C_ _s[âˆ—]_ log d/n with high probability is a

_âˆ¥âˆ‡_ _âˆ¥âˆ_ _â‰¤_ p

slower statistical rate due to the term log d.

p

_(ii) Impact of learnable penalty function. To explain the the benefit of using learnable penalty_
function, we give a more refined bound for the statistical error in Eq. 11 in the following lemma.
**Lemma 3.1 (Refined bound). Assume the same conditions and parameters Î¸ in Theorem 3.1. As-**
_sume T â†’âˆ_ _so that the optimization error can be ignored. For simplicity, assume_ _w3 = 0 and only_
_consider the weights_ _w1 and_ _w2 for â„“1 penalty and MCP. Then for every problem (Z1:n, Î²[âˆ—]) âˆˆDm:_

_w2)Îºm_
_âˆ¥Î²âˆ(Z1:n; Î¸) âˆ’_ **_Î² f[âˆ—]âˆ¥2 â‰¤+_** [1+8(1] f[1+8(1+]ÏÏâˆ’âˆ’âˆ’âˆ’[âˆ’]wwfw[f][f]222/b/b)Îºm _âˆ¥âˆ¥((âˆ‡âˆ‡Î²Î²LLnn((ZZ1:1:nn,, Î² Î²[âˆ—][âˆ—])) âˆ¨ âˆ¨_ _ÎµÎµ))SS2[âˆ—]1[âˆ—]_ _[âˆ¥][2]_  SS12[âˆ—][âˆ—][: Small][: Large] f _Î²Î²j[âˆ—]j[âˆ—]_ _â€™sâ€™s_ _, (13)(12)_

_[âˆ¥][2]_

_where b > 1 is a hyperparameter inf MCP, and the index sets S1[âˆ—]_ _[and][ S]2[âˆ—]_ _[are defined as] _ _[ S]1[âˆ—]_ [:=] _[ {][j][ âˆˆ]_
_S[âˆ—]_ : _Î²j[âˆ—]_ _â‰¤_ _bÎ»[âˆ—]j_ _[}][ and][ S]2[âˆ—]_ [:=][ {][j][ âˆˆ] _[S][âˆ—]_ [:] _Î²j[âˆ—]_ _> bÎ»[âˆ—]j_ _[}][. See Appendix][ E][ for the proof.]_

This refined bound reveals the benefit of learning the penalty function because:

1. According to Lemma 3.1, the optimal penalty function is problem-dependent. For example, if
(8(bÏ + 1)Îºm + 1) ( **_Î²Ln(Z1:n, Î²[âˆ—])_** _Îµ)S1[âˆ—]_
_Îµ)S2[âˆ—]_ _âˆ’_ _w2âˆ¥ = 0âˆ‡_ can induce a smaller error bound. Otherwise, âˆ¨ _[âˆ¥][2][ >][ (8(][bÏ][âˆ’]_ _[âˆ’]_ [1)][Îº][m][ âˆ’] [1)][âˆ¥][(][âˆ‡]w[Î²]2 = 1[L][n][(][Z][1:] is better.[n][,][ Î²][âˆ—][)][ âˆ¨]
Therefore, learning is a more suitable way of choosing the penalty function.[âˆ¥][2][, choosing][ f]

2. The convergence speed CÎ¸ in Eq. 10 is also affected by the weights, monotonely decreasing

f

in _w2. Through gradient-based training, we can automatically find the optimal combination of_
penalty functions to strike a nice balance between the statistical error and convergence speed.
f


-----

4 GENERALIZATION ANALYSIS

How well can the learned PLISAÎ¸ solve new problems outside the training set? In this section, we
conduct the generalization analysis in a novel way to focus on answering the questions:

How is the generalization bound of PLISAÎ¸ related to its algorithmic properties?
And how is it different from conventional neural networks?

4.1 SECOND MAIN RESULT: GENERALIZATION BOUND

To analyze the generalization properties of neural networks, many works have adopted the analysis
framework of Bartlett & Mendelson (2002) to bound the Rademacher complexity via Dudleyâ€™s integral (Bartlett et al., 2017; Chen et al., 2019; Garg et al., 2020; Joukovsky et al., 2021). A key step
in this analysis framework is deriving the robustness of the training loss to the small perturbation in
model parameters Î¸. Since we can view PLISAÎ¸ as an iterative algorithm, we borrow the analysis
tools of classic optimization algorithms to derive its robustness in Î¸. The following lemma states this
key intermediate result, which connects the Lipschitz constant to algorithmic properties of PLISAÎ¸.

**Lemma 4.1PLISAÎ¸ contains (Robustness to T > t0 blocks and Î¸). Assume K layers. Consider a parameter space P satisfies Assumption C.1 and D Î˜m âˆ¼ in which the param-P(P)[m]. Assume**
_eters satisfy (i) Î± âˆˆ_ [Î±min, _Ï1+_ []][, (ii)][ Î·][j][ âˆˆ] [[][Ïƒ][âˆ’][1][(0][.][9)][, Î·][max][]][, (iii)][ f]w2 [1]b [+][ f]w3 _aâˆ’1_ 1 _[â‰¤]_ _[Î¾][max][ < Ï][âˆ’][, and]_

_(iv) Î»[âˆ—]j_ (Z1:n,Î²âˆ— )âˆˆDm
_Î·max, Î¾max[âˆˆ]_ [[8 sup], and Î»max. Then for any[|][[][âˆ‡][Î²][L][n] Î¸[(][Z] =[1:][n][,]Î·[ Î²], Î»[âˆ—][)]][âˆ—][j],[| âˆ¨] w, Î±[Îµ, Î»] and[max] Î¸[]][ with some positive constants][â€²] = **_Î·[â€²], Î»[âˆ—â€²], w[â€²], Î±[â€²]_** _in Î˜, and for[ Î±][min][,]_
_{_ _}_ _{_ _}_
_any recovery problem (Z1:n, Î²[âˆ—])_ _m, the following inequality holds,_
_âˆˆD_

_âˆ¥Î²T (Z1:n; Î¸) âˆ’_ **_Î²T (Z1:n; Î¸[â€²])âˆ¥2 â‰¤_** _c1K(T âˆ’_ _t0)âˆšs[âˆ—]_ _|Î± âˆ’_ _Î±[â€²]| exp(âˆ’CÎ˜K(T âˆ’_ _t0))_ (14)

convergence rate

+ _c2âˆ¥Î· âˆ’_ **_Î·[â€²]âˆ¥2 + c3âˆ¥Î»[âˆ—]_** _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2 + c4âˆšdâˆ¥w âˆ’_** **_w[â€²]âˆ¥2_** |(1 âˆ’ exp({zâˆ’CÎ˜KT ))}, (15)
  stability rate

| {z }

_where c1, c2, c3, c4 and CÎ˜ are some positive constants. Note that similar to Theorem 3.1, K and t0_
_are required to be larger than certain small values. See Appendix F.1 for the proof._

**Convergence rate & step size perturbation. In Eq. 14, the Lipschitz constant in the step size Î±**
scales at the same rate as the convergence rate of PLISAÎ¸, decreasing exponentially in T and K
(See Fig. 3 for a visualization). To understand this, consider when both step sizes Î± and Î±[â€²] are within
the convergence region (i.e., (0, Ï[âˆ’]+[1][]][). After infinitely many steps, their induced outputs will both]
converge to the same optimal point. This intuitively explains why the output perturbation caused by
_Î±-perturbation has the same decrease rate as the optimization error._


_âˆ¥Î²T (Z1:n; Î¸) âˆ’_ **_Î²T (Z1:n; Î¸[â€²])âˆ¥2 â‰¤_** _c1K(T âˆ’_ _t0)_


_c2âˆ¥Î· âˆ’_ **_Î·[â€²]âˆ¥2 + c3âˆ¥Î»[âˆ—]_** _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2 + c4_**


**Stability rate & regularization perturbation.** Convergence Rate Stability Generalization Bound
In the literature of optimization, stability of an
algorithm expresses its robustness to small perturbation in the optimization objective. This
is clearly related to the robustness of PLISAÎ¸ KT KT KT
to the perturbation in Î·, Î»[âˆ—], w, because these Convergence Rate Stability Generalization Bound
parameters jointly determine the regularization
_Pw(Î»t, Î²), which is a part of the optimiza-_
tion objective. Therefore, we exploit the analysis techniques for algorithmic stability to derive KT KT KT
the robustness in (Î·, Î»[âˆ—], w)-perturbation and ob
Convergence Rate Stability Generalization Bound

KT KT KT

Convergence Rate Stability Generalization Bound

KT KT KT

tain the Lipschitz constant in Eq. 15, which is Figure 3: Visualization of convergence, stability,

and generalization bound in Theorem 4.1. The two

bounded but increasing in T and K (See Fig. 3

sets of visualizations are obtained by choosing differ
for a visualization).

ent speeds CÎ˜ in the convergence rate and stability.

Based on the key result in Lemma 4.1, we can apply Dudleyâ€™s integral to measure the empirical
Rademachar complexity which immediately yields the following generalization bound.


-----

**Theorem 4.1 (Generalization gap). Assume the assumptions in Lemma 4.1. For any Ïµ > 0, with**
_probability at least 1 âˆ’_ _Ïµ, the generalization gap is bounded by_

_gen(P(_ ); Î¸) _train[(][D][m][;][ Î¸][)][ â‰¤]_ _[c][1]_ _m[âˆ’][1]_ log(4Ïµ[âˆ’][1]) + (16)
_L_ _P_ _âˆ’L[Î³][=0]_

_c2m[âˆ’][1]_ log _âˆšmKT_ exp( _CÎ˜K(T_ _t0))_ 1 + c3dmp _[âˆ’][1]_ log _âˆšm(1_ exp( _CÎ˜KT_ )) _,_
_âˆ’_ _âˆ’_ _âˆ¨_ _âˆ’_ _âˆ’_

q convergence rate stability

     

_where c1, c2, c3, CÎ˜ are constants independent of d, m, K and T_ _. See Appendix F for the proof._

| {z } | {z }

Fig. 3 visualizes how the generalization bound in Theorem 4.1 grows when KT increases. The two
sets of plots look slightly different by picking different constants CÎ˜. We have also tried varying
the values of c2, c3, d, m in Theorem 4.1. Overall, they lead to the two types of behaviors in Fig. 3.

An important observation in Theorem 4.1 and Figure 3 is that the generalization gap could decrease
_in the number of layers, and we will see in Section 7 that this matches the empirical observations._
It also distinguishes algorithm-unrolling based architectures from conventional neural networks,
whose generalization gaps rarely decrease in the number of layers.

_Remark. The above generalization results are conducted on a constrained parameter space (as de-_
scribed in Lemma 4.1) so that we can utilize the algorithmic properties of PLISAÎ¸. We focus on
this space because the analysis contains more interesting and new ingredients. For parameters outside this space, the analysis procedure is similar to other conventional recurrent networks. Since the
bound in Theorem 4.1 has matched the empirical observations, it is reasonable to believe that after
training, the learned parameters are likely to be in this â€˜niceâ€™ constrained space.

5 EXTENSION TO UNSUPERVISED LEARNING-TO-LEARN SETTING

Real-world datasets may not contain the ground-truth parameters Î²[âˆ—], but only contain the samples
loss to minimize the empirical loss functionfrom each task, Dm[U] [=][ {][Z]1:[(1)]n[,][ Â· Â· Â·][, Z]1:[(][m]n[)][}][. In this setting, we can construct an unsupervised training] Ln (e.g., the likelihood function) on the samples.


**Unsupervised training loss:** _train[(][D]m[U]_ [;][ Î¸][) := 1]
_L[U]_ _m_


_Ln2_ _Z1:[(][i]n[)]_ 2 _[,][ Î²][T][ (][Z]1:[(][i]n[)]_ 1 [;][ Î¸][)] (17)
_i=1_

X   


In this loss, both Z1:[(][i]n[)] 1 [and][ Z]1:[(][i]n[)] 2 [are subsets of][ Z]1:[(][i]n[)] [. The samples][ Z]1:[(][i]n[)] 1 [are used as the input to]

PLISAÎ¸ and the samples Z1:[(][i]n[)] 2 [are used for evaluating the output][ Î²][T][ from][ PLISA][Î¸][.]

Let Î¸U[âˆ—] _train[(][D]m[U]_ [;][ Î¸][)][ be a minimizer to this unsupervised loss.][ Theoretically][, to bound]
the generalization error of[âˆˆ] [arg min][ L][U] _Î¸U[âˆ—]_ [, we can show that]

_gen(P(_ );Î¸U[âˆ—] [)][ â‰¤] _m[C]_ _mi=1_ _Ln2_ _Z1:[(][i]n[)]_ 2 _[,][ Î²][T][ (][Z]1:[(][i]n[)]_ 1 [;][ Î¸]U[âˆ—] [)] _Ln2_ _Z1:[(][i]n[)]_ 2 _[,][ Î²][âˆ—][(][i][)][]_ (18)
_L_ _P_ _âˆ’_

P    unsupervised training error  

+ _gen|(P(_ ); Î¸U[âˆ—] [)][ âˆ’L][Î³]train[=0] [(][D][m][;][ Î¸]U[âˆ—]{z[)] + _m[C]_ _mi=1[âˆ¥âˆ‡][Î²][L][n]2_ [(][Z]1:[(][i]n[)] 2 _[,][ Î²]}_ _[âˆ—][(][i][)][)][âˆ¥]2[2]_ _._ (19)
_L_ _P_
generalization gap: Theorem 4.1 statistical error

P

Compared to Eq. 9|, this upper bound contains an additional statistical error, which appears because{z } | {z }
of the gap between the unsupervised loss and the true error that we aim to optimize. Clearly, in this
upper bound, the generalization gap can be bounded by Theorem 4.1. Furthermore, the unsupervised
training error in Eq. 18 can be bounded by combining Theorem 3.1 with the following in equality.

_Ln2 (Z1:n2_ _, Î²T (Z1:n1_ ; Î¸U[âˆ—] [))][ âˆ’] _[L][n]2_ [(][Z][1:][n]2 _[,][ Î²][âˆ—][)]_ (20)
_â‰¤_ _Ln2 (Z1:n2_ _, Î²T (Z1:n1_ ; Î¸[âˆ—])) âˆ’ _Ln2 (Z1:n2_ _, Î²[âˆ—])_

**_Î²Ln2_** (Z1:n2 _, Î²[âˆ—])_ 2 **_Î²T (Z1:n1_** ; Î¸[âˆ—]) **_Î²[âˆ—]_** 2 + _[Ï]2[+]_ 2 _._ (21)
_â‰¤âˆ¥âˆ‡_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _[âˆ¥][Î²][T][ (][Z][1:][n][1]_ [;][ Î¸][âˆ—][)][ âˆ’] **_[Î²][âˆ—][âˆ¥][2]_**
bounded by Theorem 3.1 bounded by Theorem 3.1

More details of the extension to unsupervised setting can be found in Appendix| {z } | {z H. }


-----

6 RELATED WORK

Learning-to-learn has become an active research direction in recent years (Bora et al., 2017;
Franceschi et al., 2017; Niculae et al., 2018; Denevi et al., 2018; PoganË‡ciÂ´c et al., 2019; Liu et al.,

2019b; Berthet et al., 2020). Many works share the idea of unrolling or differentiating through algorithms to design the architecture (Yang et al., 2017; Borgerding et al., 2017; Corbineau et al.,
2019; Xie et al., 2019; Shrivastava et al., 2020; Chen et al., 2020a; Wei et al., 2020; Indyk et al.,
2019; Grover et al., 2019; Wu et al., 2019). A well-known example of learning-based algorithm is
LISTA (Gregor & LeCun, 2010) which interprets ISTA (Daubechies et al., 2004) as layers of neural networks and has been an active research topic (Zhang & Ghanem, 2018; Kamilov & Mansour,
2016; Chen et al., 2018; Liu et al., 2019a; Wu et al., 2020; Kim & Park, 2020).

However, the generalization of algorithm learning has received less attention. The only exceptions
are several works. However, Chen et al. (2020b) and Wang et al. (2021) only consider learning
to optimize quadratic losses. Behboodi et al. (2020); Joukovsky et al. (2021) do not connect the
generalization analysis with algorithmic properties to provide tighter bounds as in our work. Unlike
our work that analyzes the Lipschitz continuity (Lemma 4.1), the work of Gupta & Roughgarden
(2017); Balcan et al. (2021) studied the generalization of learning-based algorithms with a focus
on scenarios when the Lipschitz continuity is unavailable. We will refer the audience to Shlezinger
et al. (2020); Chen et al. (2021) for a more comprehensive summary of related works.

7 EXPERIMENTS

7.1 SYNTHETIC EXPERIMENTS

In synthetic datasets, we consider sparse linear regression problems and sparse precision matrix
estimation problems for Gaussian graphical models. Specifically, we recover target vectors Î²[âˆ—] _âˆˆ_
R[d], where d = {256, 1024} in SLR, and estimate precision matrices Î˜[âˆ—] _âˆˆ_ R[d][Ã—][d], where d =
_{50, 100} in SPE. See Appendix I.2 for descriptions of the dataset and data preparation.dim=256_ dim=1024

7.1.1 SPARSE LINEAR REGRESSION (SLR) 30 apf 40

In this experiment, we compare PLISA with several rnn 30
baselines and also verify the theorems. 20 rnn_l1

**Performance comparison. We consider baselines** 10
including APF (Wang et al., 2014), ALISTA (Liu 5
et al., 2019a), RNN (Andrychowicz et al., 2016), and 0
RNN-â„“1. APF is the path-following algorithm that 0.0 0.1 0.2 0.3 0.4 0.5 0 0.0 0.2 0.4 0.6

|dim=256|Col2|Col3|
|---|---|---|
||apf||
||plisa alist|a|
||rnn||
||rnn_|l1|
||||
||||
||||
||||
||||


|Col1|dim=1024|Col3|
|---|---|---|
||||
||||
||||
||||
||||
||||

is used as the basis of our architecture. ALISTA is wall-clock time (sec) wall-clock time (sec)

dim=256 dim=1024

30 apfplisa 40

25 alista

rnn 30

20 rnn_l1

15 20

l2-error

10

10

5

0

0

0.0 0.1 0.2 0.3 0.4 0.5 0.0 0.2 0.4 0.6

wall-clock time (sec) wall-clock time (sec)

a representative of algorithm unrolling based archi- Figure 4: Convergence of recovery error. Since
tectures, which is an advanced variant of LISTA. We APF takes a long time to converge, its curve are
have tried the vanilla LISTA, but it performs worse outside the range of these plots. We use a dashthan ALISTA on our tasks so it is not reported. RNN line to represent the final â„“2 error it achieves.
refers to the LSTM-based model in Andrychowicz et al. (2016). Besides, we add a soft-thresholding
operator to this model to enforce sparsity, and include this variant as a baseline, called RNN-â„“1.
Except for APF, all methods are trained on the same set of training problems and selected by the
validation problems. For APF, we perform grid-search to choose its hyperparameters, which is also
selected by the validation set. The detailed specification of each model can be found in Appendix I.3.

Fig. 4 shows the convergence of **_Î²t_** **_Î²[âˆ—]_** 2 for 0.20 âˆ’0.1âˆ’0.2
problems in the test set. The x âˆ¥-axis indicates âˆ’ _âˆ¥_ 0.15 âˆ’0.3
the wall-clock time. In terms of the final re- 0.10 âˆ’0.4
covery accuracy, PLISA outperforms all base- 0.05 âˆ’0.5
line methods. In the more difficult setting (i.e, 0 50 100 150 200 250 300 0 50 100 150 200 250 300
_d = 1024), its advantage is obvious. Although_ KT KT

0.20 âˆ’0.1

âˆ’0.2

0.15

âˆ’0.3

0.10 âˆ’0.4

0.05 âˆ’0.5

Generalization Gap âˆ’0.6

0 50 100 150 200 250 300 0 50 100 150 200 250 300

KT KT

PLISA is slightly slower than other deep learn- Figure 5: Generalization gap of PLISA with varying
ing based models due to the computations of _KT_, for two different experimental settings.
MCP and SCAD, PLISA achieves a better accuracy and it has been converging much faster than the
classic algorithm APF. APF is very slow mainly due to the use of line-search for selecting step sizes.


-----

**Generalization gap. We are interested in the generalization behavior of PLISA. As this experiment**
is conducted for theoretical interest, we do not use the validation set to select the model. We vary
the number of layers (K) and blocks (T ) in PLISA to create a set of models with different depths.
For each depth, we train the model with 2000 training problems, and then test it on a separate set of
100 problems to approximate the generalization gap. In Fig. 5, we observe the interesting behavior
of the generalization gap, where the left one increases in KT at the beginning and then decrease to
a constant, and the right one increases fast and then decrease very slowly. This surprisingly matches
the two different visualizations in Fig. 3 of the predicted generalization gap given by Theorem 4.1.

7.1.2 SPARSE PRECISION MATRIX ESTIMATION (SPE)

We compare PLISA with APF, GLASSO (Friedman et al., 2008), GISTA (Guillot et al., 2012), and
GGM (Belilovsky et al., 2017) on sparse precision estimation tasks in Gaussian graphical models.
GLASSO estimates the precision matrix by block-coordinate decent methods. GISTA is a proximal
gradient method for precision matrix estimation. GGM utilizes convolutional neural network to
estimate the precision matrix. Details of each model and the training can be found in Appendix I.4.


Table 1 reports the Frobenius error âˆ¥Î˜ âˆ’
Î˜[âˆ—]âˆ¥F[2] [between the estimation][ Î˜][ and the]
true precision matrix Î˜[âˆ—], averaged over
100 test problems. PLISA achieves consistent improvements. Classic algorithm
are slower because they perform linesearch. GLASSO is faster than other classic algorithm because we use the sklearn
package (Pedregosa et al., 2011) in which
the implementations are optimized.


Table 1: Recovery error in SPE. The reported time is the av
|erage wall-clock time for solving each instance in seconds.|Col2|
|---|---|
|Sizes p = 50 p = 100 Methods âˆ¥Î˜ âˆ’Î˜âˆ—âˆ¥2 Time âˆ¥Î˜ âˆ’Î˜âˆ—âˆ¥2 Time F F||
|PLISA GLASSO GISTA APF GGM|119.47 Â± 12.23 0.117 142.70 Â± 13.38 0.132 169.63 Â± 17.99 1.66 237.95 Â± 27.49 3.12 186.96 Â± 25.48 53.47 373.66 Â± 41.72 36.02 269.51 Â± 32.28 46.02 485.94 Â± 60.33 86.82 194.26 Â± 10.73 0.007 445.00 Â± 58.89 0.008|


7.1.3 DISCUSSION ON TRAINING-TESTING TIME

**Test time. Fig. 4 and Table 1 shows the wall-clock time for solving test problems. Overall, classic**
algorithms are slower because they need to perform line-search. It is noteworthy that learning-based
methods can solve a batch of problems parallelly but most classic algorithms cannot. To allow more
advantages for classic algorithms, the test problems are solved without batching in all methods.

**Train time. As metioned earlier, we perform grid-search to select the hyperparameters in classic**
algorithms using validation sets. The training time comparison is summarized in Table 3 and Table 4
in Appendix I.4. We can see that training time is not a bottleneck of this problem. Moreover, In
SPE, classic algorithms even require a longer training time than learning-based methods.

7.2 UNSUPERVISED LEARNING ON REAL-WORLD DATASETS

We conduct experiments of unsupervised algorithm learning on 3 datasets: Gene expression
dataset (Kouno et al., 2013), Parkinsons patient dataset (Tsanas et al., 2009), and School exam
score dataset (Zhou et al., 2011). See Appendix I.6 for details of datasets and the configuration.

The goal of the algorithm is to estima- Table 2: Recovery accuracy on real-world datasets.
tion the sparse linear regression parame
ror on a set of held-out samples for each
problem. Table 2 shows the effectiveness

|Col1|PLISA|APF|RNN|RNN-â„“ 1|ALISTA|
|---|---|---|---|---|---|
|Gene Parkinsons School|1.177 11.63 296.6|1.289 11.86 367.9|1.639 11.91 561.5|1.349 13.05 310.3|1.289 34.843 884.2|

of PLISA. Note that these real-world datasets may not satisfy the assumptions in this paper. This
set of experiments are conducted only to demonstrate the robustness of the proposed method.

8 DISCUSSION

We proposed PLISA for learning to solve sparse parameter recovery problems. We analyze its
capacity and generalization ability. The techniques could be used to derive guarantees for other
algorithm-unrolling based architectures. The model PLISA can be improved by using a more flexible penalty function (e.g., a conventional neural network) as long as it satisfies Assumption B.1.


-----

REFERENCES

Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient
descent. In Advances in Neural Information Processing Systems, pp. 3981â€“3989, 2016.

Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and Ellen
Vitercik. How much data is sufficient to learn high-performing algorithms? generalization guarantees for data-driven algorithm design. In Proceedings of the 53rd Annual ACM SIGACT Sym_posium on Theory of Computing, pp. 919â€“932, 2021._

Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463â€“482, 2002.

Peter L Bartlett, Dylan J Foster, and Matus J Telgarsky. Spectrally-normalized margin bounds for
neural networks. In Advances in Neural Information Processing Systems, pp. 6240â€“6249, 2017.

Arash Behboodi, Holger Rauhut, and Ekkehard Schnoor. Compressive sensing and neural networks
from a statistical learning perspective. arXiv preprint arXiv:2010.15658, 2020.

Eugene Belilovsky, Kyle Kastner, GaÂ¨el Varoquaux, and Matthew B Blaschko. Learning to discover
sparse graphical models. In International Conference on Machine Learning, pp. 440â€“448. PMLR,
2017.

Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, and Francis
Bach. Learning with differentiable perturbed optimizers. arXiv preprint arXiv:2002.08676, 2020.

Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using generative models. In International Conference on Machine Learning, pp. 537â€“546. PMLR, 2017.

Mark Borgerding, Philip Schniter, and Sundeep Rangan. Amp-inspired deep networks for sparse
linear inverse problems. IEEE Transactions on Signal Processing, 65(16):4293â€“4308, 2017.

SÂ´ebastien Bubeck. Convex optimization: Algorithms and complexity. _arXiv preprint_
_arXiv:1405.4980, 2014._

Emmanuel J Candes and Terence Tao. Decoding by linear programming. IEEE transactions on
_information theory, 51(12):4203â€“4215, 2005._

Minshuo Chen, Xingguo Li, and Tuo Zhao. On generalization bounds of a family of recurrent neural
networks. arXiv preprint arXiv:1910.12947, 2019.

Tianlong Chen, Xiaohan Chen, Wuyang Chen, Howard Heaton, Jialin Liu, Zhangyang Wang, and
Wotao Yin. Learning to optimize: A primer and a benchmark. arXiv preprint arXiv:2103.12828,
2021.

Xiaohan Chen, Jialin Liu, Zhangyang Wang, and Wotao Yin. Theoretical linear convergence of unfolded ista and its practical weights and thresholds. In Advances in Neural Information Processing
_Systems, pp. 9061â€“9071, 2018._

Xinshi Chen, Yu Li, Ramzan Umarov, Xin Gao, and Le Song. Rna secondary structure prediction
by learning unrolled algorithms. arXiv preprint arXiv:2002.05810, 2020a.

Xinshi Chen, Yufei Zhang, Christoph Reisinger, and Le Song. Understanding deep architecture with
reasoning layer. Advances in Neural Information Processing Systems, 33, 2020b.

M-C Corbineau, Carla Bertocchi, Emilie Chouzenoux, Marco Prato, and J-C Pesquet. Learned
image deblurring by unfolding a proximal interior point algorithm. In 2019 IEEE International
_Conference on Image Processing (ICIP), pp. 4664â€“4668. IEEE, 2019._

Ingrid Daubechies, Michel Defrise, and Christine De Mol. An iterative thresholding algorithm
for linear inverse problems with a sparsity constraint. Communications on Pure and Applied
_Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences, 57(11):1413â€“_
1457, 2004.


-----

Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, and Massimiliano Pontil. Learning to learn around
a common mean. Advances in Neural Information Processing Systems, 31:10169â€“10179, 2018.

Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle
properties. Journal of the American statistical Association, 96(456):1348â€“1360, 2001.

Jianqing Fan, Yang Feng, and Yichao Wu. Network exploration via the adaptive lasso and scad
penalties. The annals of applied statistics, 3(2):521, 2009.

Luca Franceschi, Paolo Frasconi, Michele Donini, and Massimiliano Pontil. A bridge between
hyperparameter optimization and larning-to-learn. stat, 1050:18, 2017.

Jerome Friedman, Trevor Hastie, and Robert Tibshirani. Sparse inverse covariance estimation with
the graphical lasso. Biostatistics, 9(3):432â€“441, 2008.

Vikas K Garg, Stefanie Jegelka, and Tommi Jaakkola. Generalization and representational limits of
graph neural networks. arXiv preprint arXiv:2002.06157, 2020.

Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings of the
_27th International Conference on International Conference on Machine Learning, pp. 399â€“406._
Omnipress, 2010.

Aditya Grover, Eric Wang, Aaron Zweig, and Stefano Ermon. Stochastic optimization of sorting
networks via continuous relaxations. arXiv preprint arXiv:1903.08850, 2019.

Dominique Guillot, Bala Rajaratnam, Benjamin T Rolfs, Arian Maleki, and Ian Wong. Iterative
thresholding algorithm for sparse inverse covariance estimation. arXiv preprint arXiv:1211.2532,
2012.

Rishi Gupta and Tim Roughgarden. A pac approach to application-specific algorithm selection.
_SIAM Journal on Computing, 46(3):992â€“1017, 2017._

Piotr Indyk, Ali Vakilian, and Yang Yuan. Learning-based low-rank approximations. arXiv preprint
_arXiv:1910.13984, 2019._

Boris Joseph Joukovsky, Tanmoy Mukherjee, Nikos Deligiannis, et al. Generalization error bounds
for deep unfolding rnns. In Proceedings of Machine Learning Research. Journal of Machine
Learning Research, 2021.

Ulugbek S Kamilov and Hassan Mansour. Learning optimal nonlinearities for iterative thresholding
algorithms. IEEE Signal Processing Letters, 23(5):747â€“751, 2016.

Dohyun Kim and Daeyoung Park. Element-wise adaptive thresholds for learned iterative shrinkage
thresholding algorithms. IEEE Access, 8:45874â€“45886, 2020.

Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
_arXiv:1412.6980, 2014._

Tsukasa Kouno, Michiel de Hoon, Jessica C Mar, Yasuhiro Tomaru, Mitsuoki Kawano, Piero Carninci, Harukazu Suzuki, Yoshihide Hayashizaki, and Jay W Shin. Temporal dynamics and transcriptional control using single-cell gene expression analysis. _Genome biology, 14(10):1â€“12,_
2013.

Jialin Liu, Xiaohan Chen, Zhangyang Wang, and Wotao Yin. ALISTA: Analytic weights are as good
as learned weights in LISTA. In International Conference on Learning Representations, 2019a.
[URL https://openreview.net/forum?id=B1lnzn0ctQ.](https://openreview.net/forum?id=B1lnzn0ctQ)

Risheng Liu, Shichao Cheng, Yi He, Xin Fan, Zhouchen Lin, and Zhongxuan Luo. On the convergence of learning-based iterative methods for nonconvex inverse problems. IEEE transactions on
_pattern analysis and machine intelligence, 42(12):3027â€“3039, 2019b._

Po-Ling Loh and Martin J Wainwright. Regularized m-estimators with nonconvexity: Statistical and
algorithmic theory for local optima. The Journal of Machine Learning Research, 16(1):559â€“616,
2015.


-----

Vlad Niculae, Andre Martins, Mathieu Blondel, and Claire Cardie. Sparsemap: Differentiable sparse
structured inference. In International Conference on Machine Learning, pp. 3799â€“3808, 2018.

Edouard Ollier and Vivian Viallon. Regression modelling on stratified data with the lasso.
_Biometrika, 104(1):83â€“96, 2017._

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research,
12:2825â€“2830, 2011.

Marin Vlastelica PoganË‡ciÂ´c, Anselm Paulus, Vit Musil, Georg Martius, and Michal Rolinek. Differentiation of blackbox combinatorial solvers. In International Conference on Learning Represen_tations, 2019._

Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algo_rithms. Cambridge university press, 2014._

Nir Shlezinger, Jay Whang, Yonina C Eldar, and Alexandros G Dimakis. Model-based deep learning. arXiv preprint arXiv:2012.08405, 2020.

Harsh Shrivastava, Xinshi Chen, Binghong Chen, Guanghui Lan, Srinivas Aluru, Han Liu, and
Le Song. GLAD: Learning sparse graph recovery. In International Conference on Learning
_[Representations, 2020. URL https://openreview.net/forum?id=BkxpMTEtPB.](https://openreview.net/forum?id=BkxpMTEtPB)_

Athanasios Tsanas, Max Little, Patrick McSharry, and Lorraine Ramig. Accurate telemonitoring of
parkinsonâ€™s disease progression by non-invasive speech tests. Nature Precedings, pp. 1â€“1, 2009.

Xiang Wang, Shuai Yuan, Chenwei Wu, and Rong Ge. Guarantees for tuning the step size using a
learning-to-learn approach. In International Conference on Machine Learning, pp. 10981â€“10990.
PMLR, 2021.

Zhaoran Wang, Han Liu, and Tong Zhang. Optimal computational and statistical rates of convergence for sparse nonconvex learning problems. Annals of statistics, 42(6):2164, 2014.

Kaixuan Wei, Angelica Aviles-Rivero, Jingwei Liang, Ying Fu, Carola-Bibiane SchÂ¨onlieb, and Hua
Huang. Tuning-free plug-and-play proximal algorithm for inverse imaging problems. In Interna_tional Conference on Machine Learning, pp. 10158â€“10169. PMLR, 2020._

Kailun Wu, Yiwen Guo, Ziang Li, and Changshui Zhang. Sparse coding with gated learned ista. In
_[International Conference on Learning Representations, 2020. URL https://openreview.](https://openreview.net/forum?id=BygPO2VKPH)_
[net/forum?id=BygPO2VKPH.](https://openreview.net/forum?id=BygPO2VKPH)

Shanshan Wu, Alex Dimakis, Sujay Sanghavi, Felix Yu, Daniel Holtmann-Rice, Dmitry Storcheus,
Afshin Rostamizadeh, and Sanjiv Kumar. Learning a compressed sensing measurement matrix
via gradient unrolling. In International Conference on Machine Learning, pp. 6828â€“6839. PMLR,
2019.

Xingyu Xie, Jianlong Wu, Guangcan Liu, Zhisheng Zhong, and Zhouchen Lin. Differentiable linearized admm. In International Conference on Machine Learning, pp. 6902â€“6911. PMLR, 2019.

Y Yang, J Sun, H Li, and Z Xu. Admm-net: A deep learning approach for compressive sensing mri.
corr. arXiv preprint arXiv:1705.06869, 2017.

Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. The Annals of
_statistics, 38(2):894â€“942, 2010a._

Jian Zhang and Bernard Ghanem. Ista-net: Interpretable optimization-inspired deep network for
image compressive sensing. In Proceedings of the IEEE Conference on Computer Vision and
_Pattern Recognition, pp. 1828â€“1837, 2018._

Tong Zhang. Analysis of multi-stage convex relaxation for sparse regularization. Journal of Machine
_Learning Research, 11(3), 2010b._

Jiayu Zhou, Jianhui Chen, and Jieping Ye. Malsar: Multi-task learning via structural regularization.
_Arizona State University, 21, 2011._


-----

A LIST OF DEFINITIONS AND NOTATIONS

For the convenience of the reader, we summarize a list of notations blow.

1. âˆ¥Î²âˆ¥Î»,1 := _j=1_ _[Î»][j][ |][Î²][j][|][ denotes element-wise][ â„“][1][ norm.]_

2. (x)S is the sub-vector of x with entries in the index set S.

[P][d]

3. x _Ïµ = max_ **_x, Ïµ_** = [max _x1, Ïµ_ _,_ _, max_ _xd, Ïµ_ ][âŠ¤].
_âˆ¨_ _{_ _}_ _{_ _}_ _Â· Â· Â·_ _{_ _}_

4. Element-wise soft-threshold:


_sÎ»(Î²) = (_ **_Î²_** _sÎ»)+_ sign(Î²) (22)
_T_ _|_ _| âˆ’_ _â—¦_

(|Î²1| âˆ’ _sÎ»1)+ sign(Î²1)_
.

= . (23)

ï£® . ï£¹

ï£¯ (|Î²d| âˆ’ _sÎ»d)+ sign(Î²d)_ ï£º
ï£° ï£»

5. Denote a single iteration of the modified proximal gradient step as


**_Î²[k]_** = MPG(Î²[k][âˆ’][1]; Î», w, Î±)

:= TÎ±Â·Î» **_Î²[k][âˆ’][1]_** _âˆ’_ _Î±_ _âˆ‡LÎ»,w(Î²[k][âˆ’][1])_
    

B PENALTY FUNCTIONS

We provide detailed descriptions of the penalty functions used in PLISA. We focus on learning the
combination of three well-known penalty functions:

_P_ [(1)](Î», Î²) = âˆ¥Î» â—¦ **_Î²âˆ¥1, P_** [(2)](Î», Î²) = _j=1_ [MCP(][Î»][j][, Î²][j][)][, P][ (3)][(][Î»][,][ Î²][) =][ P]j[p]=1 [SCAD(][Î»][j][, Î²][j][)][,]

where MCP (Zhang, 2010a) and SCAD (Fan & Li, 2001) are nonconvex penalties whose analytical

[P][p]

forms are given below.

B.1 ANALYTICAL FORMS

The MCP penalty can be written as


MCP(Î», Î²) = _Î»_ _Î²_
_|_ _| âˆ’_ _[Î²]2b[2]_


where b > 0 is some hyperparameter.

The SCAD penalty can be written as


1 ( _Î²_ _bÎ») +_ _[bÎ»][2]_

_Â·_ _|_ _| â‰¤_ 2



_Â· 1 (|Î²| > bÎ»),_


SCAD(Î», Î²) = Î» _Î²_ 1 ( _Î²_ _Î»)_ 1 (Î» < _Î²_ _aÎ»)_
_|_ _| Â·_ _|_ _| â‰¤_ _âˆ’_ _[Î²][2][ âˆ’]2([2][aÎ»]a_ _[ |][Î²]1)[|][ +][ Î»][2]_ _Â·_ _|_ _| â‰¤_

_âˆ’_

+ [(][a][ + 1)][Î»][2] 1 ( _Î²_ _> aÎ»),_

2 _Â·_ _|_ _|_

where a > 2 is some hyperparameter.


PLISA uses the concave components of these penalty functions. Their analytical forms are as
follows.

_bÎ»2_

_q[(2)](Î», Î²) = MCP(Î», Î²)_ _Î»_ _Î²_ = _Î»_ _Î²_ 1 ( _Î²_ _> bÎ»)_
_âˆ’_ _|_ _|_ _âˆ’_ _[Î²]2b[2]_ 2 _âˆ’_ _|_ _|_ _Â·_ _|_ _|_

_[Â·][ 1][ (][|][Î²][| â‰¤]_ _[bÎ»][) +]_  

_q[(3)](Î», Î²) = SCAD(Î», Î²)_ _Î»_ _Î²_ = [2][Î»][ |][Î²][| âˆ’] _[Î²][2][ âˆ’]_ _[Î»][2]_ 1 (Î» < _Î²_ _aÎ»)_
_âˆ’_ _|_ _|_ 2(a 1) _Â·_ _|_ _| â‰¤_

_âˆ’_

+ [(][a][ + 1)][Î»][2][ âˆ’] [2][Î»][ |][Î²][|] 1 ( _Î²_ _> aÎ»)_

2 _Â·_ _|_ _|_


-----

B.2 IMPLICATIONS

Based on the definitions of these penalty functions, it is easy to check that their convex combination
satisfies a set of conditions as stated in the following Assumption B.1.


**Assumption B.1 (Regularization). Let P** (Î», Î²) = Q(Î», Î²)+ _âˆ¥Î²âˆ¥Î»,1 where Q is concave in Î², and_
_that Q(Î», Î²) =_ _j=1_ _[q][(][Î»][j][, Î²][j][)][. Denote the partial gradient of][ q][ as][ q]Î»[â€²]_ [(][Î²][) :=][ âˆ‚q][(]âˆ‚Î²[Î»,Î²][)] _. Assume the_

_following regularization conditions._

[P][d]

_(a) There exists constants Î¾ â‰¥_ 0 such that for any Î²[â€²] _> Î²,_

_Î»[(][Î²][â€²][)][ âˆ’]_ _[q]Î»[â€²]_ [(][Î²][)]
_Î¾_ 0.
_âˆ’_ _â‰¤_ _[q][â€²]_ _Î²[â€²]_ _Î²_ _â‰¤_

_âˆ’_

_(b) q(Î», âˆ’Î²) = q(Î», Î²)._

_(c) qÎ»[â€²]_ [(0) =][ q][(][Î»,][ 0) = 0][.]

_(d) |qÎ»[â€²]_ [(][Î²][)][| â‰¤] _[Î»][.]_

_(e) |qÎ»[â€²]_ 1 [(][Î²][)][ âˆ’] _[q]Î»[â€²]_ 2 [(][Î²][)][| â‰¤|][Î»][1][ âˆ’] _[Î»][2][|][.]_

_Note that the penalty function Pw(Î», Î²) in PLISAÎ¸ satisfies all these conditions, with the constant_
_Î¾ in condition (a) being_

1 1
_Î¾w =_ _w2_ _w3_
_b_ [+][ f] _a_ 1 _[,]_

_âˆ’_

_where a and b are the hyperparameters in SCAD and MCP._

f


Next, we present an important lemma which states the restricted strongly convexity and smoothness
of the modified loss

_LÎ»,w(Î²) := Ln(Z1:n, Î²) + Qw(Î», Î²)._

**Lemma B.1 (Restricted Strongly Convex and Restricted Strongly Smooth). Assume P satisfies**
_Assumption C.1 and (Zn, Î²[âˆ—])_ _. If Q(Î», Î²) satisfies the regularization conditions in Assump-_
_âˆˆP_
_tion B.1 with a constant Î¾ < Ï_ _. Then_
_âˆ’_

_LÎ»(Î²) := Ln(Z1:n, Î²) + Q(Î», Î²)_

_is strongly convex and smooth in the subspace_ **_Î²[â€²]_** **_Î²_** 0 _s[âˆ—]_ + 2Ëœs _. That is, for any Î², Î²[â€²]_ _such_
_that_ **_Î²[â€²]_** **_Î²_** 0 _s[âˆ—]_ + 2Ëœs, the following inequalities hold {âˆ¥ _âˆ’_ _âˆ¥_ _â‰¤_ _}_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_

_LÎ»(Î²[â€²]) â‰¥_ _LÎ»(Î²) + âˆ‡LÎ»(Î²)[âŠ¤](Î²[â€²]_ _âˆ’_ **_Î²) +_** _[Ï][âˆ’]2[âˆ’]_ _[Î¾]_ _âˆ¥Î²[â€²]_ _âˆ’_ **_Î²âˆ¥2[2]_** (24)

_LÎ»(Î²[â€²]) â‰¤_ _LÎ»(Î²) + âˆ‡LÎ»(Î²)[âŠ¤](Î²[â€²]_ _âˆ’_ **_Î²) +_** _[Ï]2[+]_ _[âˆ¥][Î²][â€²][ âˆ’]_ **_[Î²][âˆ¥]2[2]_** (25)

_Proof. The proof is straightforward by using the condition (a) in Assumption B.1 and the sparse-_
eigenvalue condition in Assumption C.1.


-----

C PROBLEM SPACE ASSUMPTIONS

We follow the notations in Wang et al. (2014); Loh & Wainwright (2015) to describe some classic
assumptions on the estimation problems.

**Assumption C.1 (Problem Space). Let s[âˆ—], Ëœs be positive integers and Ï** _, Ï+ be positive constants_
_âˆ’_
_such that Ëœs > (121(Ï+/Ïâˆ’) + 144(Ï+/Ïâˆ’)[2])s[âˆ—]. Assume for every estimation problem (Z1:n, Î²[âˆ—])_
_in the space P, the following conditions are satisfied._

_(a)(b) For any nonzero âˆ¥Î²[âˆ—]âˆ¥0 â‰¤_ _s[âˆ—]_ _and v âˆ¥ âˆˆÎ²[âˆ—]âˆ¥Râˆ[d]_ _with sparsityâ‰¤_ _B1;_ _âˆ¥vâˆ¥0 â‰¤_ _s[âˆ—]_ + 2Ëœs, it holds **_v[âŠ¤]âˆ‡Î²[2]_** _[L]âˆ¥[n]v[(]âˆ¥[Z]2[2][1:][n][,][Î²][)][v]_ _âˆˆ_ [Ïâˆ’, Ï+];

_(c) 8_ [ **_Î²Ln(Z1:n, Î²[âˆ—])]j_** [ **_Î²Ln(Z1:n, 0)]j_** _B2,_ _j = 1,_ _, d._
_|_ _âˆ‡_ _| â‰¤|_ _âˆ‡_ _| â‰¤_ _âˆ€_ _Â· Â· Â·_

Condition (a) assumes Î²[âˆ—] is s[âˆ—]-sparse and B1-bounded. Condition (b) is commonly referred to as
â€˜sparse eigenvalue conditionâ€™ (Zhang, 2010b; Wang et al., 2014), which is weaker than the wellknown restricted isometry property (RIP) in compressed sensing (Candes & Tao, 2005). Note that
the class of functions satisfying conditions of this type is much larger than the class of convex losses.
In the special case when Ln(Z1:n, Î²) is strongly convex in Î², condition (b) holds with Ëœs . The
_â†’âˆ_
last condition bounds the gradient of the empirical loss Ln at the true parameter Î²[âˆ—] and 0.


-----

D RECOVERY GUARANTEE FOR PARAMETERS IN CONSTRAINED SPACE

Our generalization analysis is conducted on a constrained parameter space. In this section, we
provide theoretical guarantees for the estimation error of PLISAÎ¸ when Î¸ is in the constrained
space. We first formally define the parameter space as follows.
**Definition D.1Given some positive values (Constrained parameter space) Î±min, Î·max, Î¾max., and Assume Î»max P. We definite the constrained parameter satisfies Assumption C.1 and Dm âŠ†P.**
_space Î˜(_ _m) as Î˜(_ _m) :=_ _Î¸ =_ **_Î·, Î»[âˆ—], w, Î±_** : conditions (i) (ii) (iii) (iv) are satisfied _, where_
_D_ _D_ _{_ _{_ _}_ _}_
_the conditions are:_


_(i) Î±_ [Î±min,
_âˆˆ_


1

_Ï+_ []][.]


_(ii) Î·j âˆˆ_ [Î·min := Ïƒ[âˆ’][1](0.9), Î·max], for all j = 1, Â· Â· Â·, d.

_(iii)_ _w2 [1]b_ [+][ f]w3 _a_ 1 1

_eter in SCADâˆ’._ _[â‰¤]_ _[Î¾][max][ < Ï][âˆ’][, where][ b][ is the hyperparameter in][ MCP][ and][ a][ is the hyperparam-]_

_(iv) Î» f[âˆ—]j_ (Z1:n,Î²âˆ— )âˆˆDm

_[âˆˆ]_ [[8 sup] _[|][[][âˆ‡][Î²][L][n][(][Z][1:][n][,][ Î²][âˆ—][)]][j][| âˆ¨]_ _[Îµ, Î»][max][]][, for all][ j][ = 1][,][ Â· Â· Â·][, d][.]_

For parameters in this constrained space, we can show the performance guarantee for the outputs of
PLISAÎ¸, as stated in the following Theorem D.1.
_be the constrained parameter space defined in DefinitionTheorem D.1 (Recovery guarantee). Assume P satisfies Assumption D.1 and assume C.1 and Î¸ D =m âŠ†P {Î·, Î». Let[âˆ—], w Î˜(, Î±D} âˆˆm)_
Î˜( _m). Assume_
_D_

29Ï+ 1

_K_ log 4 (1 + ) _[âˆ¥][(][B][2][ âˆ¨]_ **_[Î»][âˆ—][)][S][âˆ—]_** _[âˆ¥][2]_ _/ log_ _Î´[âˆ’][1][/][2][]_ + 1,
_â‰¥_ s _Ïâˆ’_ _âˆ’_ _Î¾max_ _Î±minÏ+_ _Îµ_ ! 

_where Î´ := 1 âˆ’_ _Î±min(Ïâˆ’_ _âˆ’_ _Î¾max). Then for any problem (Z1:n, Î²[âˆ—]) in the training set Dm, all_
_intermediate outputs of PLISAÎ¸ have the following error bounds for all t = 1, Â· Â· Â·, T_ _._

15/2
**_Î²t[k][(][Z][1:][n][;][ Î¸][)][ âˆ’]_** **_[Î²][âˆ—][âˆ¥][2]_** (Î»t(Z1:n; Î¸))Sâˆ— 2, _k = 1,_ _, K,_
_âˆ¥_ [e] _[â‰¤]_ _Ï_ _Î¾max_ _âˆ¥_ _âˆ¥_ _âˆ€_ _Â· Â· Â·_

_âˆ’_ _âˆ’_

19/8
**_Î²t(Z1:n; Î¸)_** **_Î²[âˆ—]_** 2 (Î»t(Z1:n; Î¸))Sâˆ— 2.
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _Ï_ _Î¾max_ _âˆ¥_ _âˆ¥_

_âˆ’_ _âˆ’_

_Proof. The proof of this theorem is based on a series of key lemmas for the properties of the modified_
proximal gradient steps in each cell of PLISA. We state these key lemmas and their proofs in
Section G. With these lemmas, the proof of this theorem is straightforward, and we state the proof
below.

Given a fixed problem (Z1:n, Î²[âˆ—]) âˆˆDm and a fixed set of parameters Î¸ = {Î·, Î»[âˆ—], w, Î±} âˆˆ Î˜(Dm),
we simplify some notations in this proof by removing the dependency on Z1:n and Î¸. For example,
we denote Î²t = Î²t(Z1:n; Î¸), **_Î²t[k]_** [=][ e]Î²t[k][(][Z][1:][n][;][ Î¸][)][,][ Î»][t] [=][ Î»][t][(][Z][1:][n][;][ Î¸][)][, etc.]

**Notations. Furthermore, we will use the following simplified notations and definitions.**

[e]

_empirical loss_ _Ln(Î²) := Ln(Z1:n, Î²)_
_modified loss_ _LÎ»(Î²) := Ln(Z1:n, Î²) + Qw(Î», Î²)_
_regularized loss_ _Ï†Î»(Î²) := Ln(Z1:n, Î²) + Pw(Î», Î²) = LÎ»(Î²) +_ **_Î²_** **_Î»,1_**
_âˆ¥_ _âˆ¥_

_local optimal_ **_Î²Î»_** arg min _Ï†Î»(Î²)_
_âˆˆ_ **_Î²âˆˆR[d]:âˆ¥Î²Sâˆ—_** _âˆ¥0â‰¤sËœ_
b (Î² **_Î²â€²)âŠ¤_**

_sub-optimality_ _Ï‰Î»(Î²) :=_ min _âˆ’_ ( _LÎ»(Î²) + Î»_ **_Î¾[â€²])_** _._
**_Î¾[â€²]_** _âˆ‚_ **_Î²_** 1 [max]Î²[â€²] **_Î²_** **_Î²[â€²]_** **_Î»,1_** _âˆ‡_ _â—¦_
_âˆˆ_ _âˆ¥_ _âˆ¥_  _âˆ¥_ _âˆ’_ _âˆ¥_ 

Now we are ready to state the proof. We first show the following statement holds true for all t â‰¤ _T_
by mathematical induction.

**Statement(t):** _Ï‰Î»t_ (Î²t[0][)][ â‰¤] [1] and (Î²t[k][)]S[âˆ—] _[âˆ¥][0]_ _s,_ _k = 1,_ _, K._

[e] 2 _[,]_ _âˆ¥_ [e] _[â‰¤]_ [Ëœ] _âˆ€_ _Â· Â· Â·_


-----

**Statement(1). First we verify that Statement(1) holds true. Recall that Î»0 = |âˆ‡Ln(0)|. In the**
following, we prove that **_Î²1[0]_** [is a local solution of][ Ï†][Î»]0 [(][Î²][) :=][ L][Î»]0 [(][Î²][) +][ âˆ¥][Î²][âˆ¥][Î»]0[,][1][.]

_LÎ»0_ (Î²1[0][) +][ Î»][0] **_Î²1[0][âˆ¥][1]_**
_âˆ‡[e]=_ _Ln(0) +_ **_Î²[â—¦]Q[âˆ‚]w[âˆ¥]_** ([e]Î»0, 0) + Î»0 _âˆ‚_ **0** 1
_âˆ‡_ _âˆ‡_ _â—¦_ _âˆ¥_ _âˆ¥_
= sign([e] _Ln(0))_ _Ln(0)_ + 0 + Î»0 _âˆ‚_ **0** 1
_âˆ‡_ _â—¦|âˆ‡_ _|_ _â—¦_ _âˆ¥_ _âˆ¥_
= sign(âˆ‡Ln(0)) â—¦ **_Î»0 + Î»0 â—¦_** _âˆ‚âˆ¥0âˆ¥1._

Since âˆ’ sign(âˆ‡Ln(0)) âˆˆ _âˆ‚âˆ¥0âˆ¥1, then we have 0 âˆˆâˆ‡LÎ»0_ (Î²1[0][) +][ Î»][0] _[â—¦]_ _[âˆ‚][âˆ¥]Î²[e]1[0][âˆ¥][1][.]_ Therefore,
_Ï‰Î»0_ (Î²1[0][) = 0][. Since][ Î»][1] [=][ Î»][0]

_[â—¦]_ **_[Î·][1][, by Lemma][ G.6][, we have]_**

**_Î²1[0][) + 0][.][2]_** [e]
_Ï‰Î»1_ (Î²1[0][)][ â‰¤] _[Ï‰][Î»][0]_ [(][ e] = [2]

[e] 0.9 9

_[â‰¤]_ [1][/][2][.]

By Lemma G.5, we have Ï†Î»1 (Î²1[0][)][e][ âˆ’] _[Ï†][Î»]1_ [(][Î²][âˆ—][)][ â‰¤] [21][/]Ï[2]âˆ’[âˆ¥]âˆ’[(][Î»]Î¾[1]max[)][S][âˆ—] _[âˆ¥]2[2]_, which implies that the conditions

in Lemma G.4 are satisfied. Therefore, we have proved that

[e] (Î²1[k][)]S[âˆ—] _[âˆ¥][0]_ _s_ _k = 1, . . ., K._

_âˆ¥_ _[â‰¤]_ [Ëœ] _âˆ€_
This finishes the proof of Statement(1).

**Statement(t). Now we assume Statement(t** _âˆ’_ 1) is true and prove Statement(t). First, we prove that
_Ï‰Î»tâˆ’1_ (Î²t[K]âˆ’1[)][ â‰¤] [1][/][4][. By Lemma][ G.2][ and Lemma][ G.5][,]

1

_âˆš2(1 +_ _Î±minÏ+_ [)][âˆš][Ï][+] 2

_Ï‰Î»tâˆ’[e]1_ (Î²t[K]âˆ’1[)][ â‰¤] min(Î»t 1) s(1 âˆ’ _Î±min(Ïâˆ’_ _âˆ’_ _Î¾max))[K][âˆ’][1][ 29][/]Ï[2][âˆ¥][(][Î»][t]Î¾[âˆ’]max[1][)][S][âˆ—]_ _[âˆ¥][2]_

_âˆ’_ _âˆ’_ _âˆ’_

[e] 29Ï+ 1 _Kâˆ’1_

_â‰¤_ s _Ïâˆ’_ _âˆ’_ _Î¾max_ (1 + _Î±minÏ+_ ) _[âˆ¥][(][Î»][0][ âˆ¨]_ _Îµ[Î»][âˆ—][)][S][âˆ—]_ _[âˆ¥][2]_ (1 âˆ’ _Î±min(Ïâˆ’_ _âˆ’_ _Î¾max))_ _._

p

Assume K â‰¥ log 4 _Ïâˆ’29âˆ’ÏÎ¾+max_ [(1 +] _Î±min1_ _Ï+_ [)][ âˆ¥][(][Î»][0][âˆ¨][Î»]Îµ[âˆ—][)][S][âˆ—] _[âˆ¥][2]_ _/ log_ _Î´[âˆ’][1][/][2][]_ + 1, where
 q _Î´ := 1_ _Î±min(Ï_ _Î¾max_ ).  

_âˆ’_ _âˆ’_ _âˆ’_
Then we have
_Ï‰Î»tâˆ’1_ (Î²t[K]âˆ’1[)][ â‰¤] [1][/][4][.] (26)

Since **_Î²t[0]_** [=][ e]Î²t[K] 1[, Lemma][ G.6][ implies that]
_âˆ’_

[e]

_Ï‰Î»t_ (Î²t[0][)][ â‰¤] [1][/][2][.]

[e]

Furthermore, by Lemma G.5, Ï‰Î»t (Î²t[0][)][ â‰¤] [1][/][2][ implies]

[e]

_Ï†Î»t_ (Î²t[0][)][ âˆ’] _[Ï†][Î»]t_ [(][Î²][âˆ—][)][ â‰¤] [21][/][2][âˆ¥][(][Î»][t][)][S][âˆ—] _[âˆ¥]2[2]_ _,_ (27)

[e] _Ïâˆ’_ _âˆ’_ _Î¾max_

which in turns implies that the conditions in Lemma G.4 are satisfied. Therefore, we have

[e]

_âˆ¥(Î²t[k][)]S[âˆ—]_ _[âˆ¥][0]_ _[â‰¤]_ _s[Ëœ]_ _âˆ€k = 1, . . ., K,_
which completes the proof of Statement(t).

[e]

Now we derive the error bounds. Similar to how we derive Eq. 26 and Eq. 27, it is easy to show that

_Ï‰Î»t_ (Î²t[K][)][ â‰¤] [1][/][4][,] _âˆ€t = 1, Â· Â· Â·, T,_

and Ï†Î»t (Î²[e]t[0][)][ âˆ’] _[Ï†][Î»]t_ [(][Î²][âˆ—][)][ â‰¤] [21]Ï[/]âˆ’[2][âˆ¥]âˆ’[(][Î»]Î¾[t]max[)][S][âˆ—] _[âˆ¥]2[2]_ _âˆ€t = 1, Â· Â· Â·, T._

Combining Ï†Î»t (Î²t[0][)][ âˆ’] _[Ï†][Î»]t_ [(][e][Î²][âˆ—][)][ â‰¤] [21][/]Ï[2][âˆ¥][(][Î»]Î¾[t]max[)][S][âˆ—] _[âˆ¥]2[2]_ with Lemma G.3, we have

_âˆ’âˆ’_

[e] **_Î²t[k]_** 2 _,_ _k = 1,_ _, K._ (28)

_âˆ¥_ [e] _[âˆ’]_ **_[Î²][âˆ—][âˆ¥][2]_** _[â‰¤]_ [15]Ï[/]âˆ’[2][âˆ¥]âˆ’[(][Î»]Î¾[t]max[)][S][âˆ—] _[âˆ¥][2]_ _âˆ€_ _Â· Â· Â·_

Combining Ï‰Î»t (Î²t[K][)][ â‰¤] [1][/][4][ with Lemma][ G.5][, we have]

**_Î²t[K]_** 1 _âˆ¥(Î»t)Sâˆ—_ _âˆ¥22_ = [19][/][8][âˆ¥][(][Î»][t][)][S][âˆ—] _[âˆ¥]2[2]_ _._

[e] _âˆ¥_ [e] _[âˆ’]_ **_[Î²][âˆ—][âˆ¥][2]_** _[â‰¤]_  4 [+ 17]8  _Ïâˆ’_ _âˆ’_ _Î¾max_ _Ïâˆ’_ _âˆ’_ _Î¾max_


-----

E CAPACITY ANALYSIS: PROOF OF THEOREM 3.1

_Proof. This theorem is a direct result of Theorem D.1, by taking a suitable set of parameters Î¸._
Similar to the proof of Theorem D.1, some notations are simplified. Please refer to the proof of
Theorem D.1 for detailed illustrations.

Denote the union support set of the true parameters Î²[âˆ—] by Sm[âˆ—] [:=][ {][j][ :][ j][ âˆˆ] [supp][(][Î²][âˆ—][)][,][ (][Z][1:][n][,][ Î²][âˆ—][)][ âˆˆ]
_Dm}. Then we specify a set of parameters Î¸ = {Î·, Î»[âˆ—], w, Î±} for PLISAÎ¸ as follows._

-  Î± = _Ï1+_ [.]

-  w: The weights w can take any values as long as they satisfy _w2 [1]b_ [+][ f]w3 _a_ 1 1 _[< Ï][âˆ’][. Since][ f]w2 and_

_âˆ’_
_w3 and be arbitrary close to 0, there must exists a set of weights w that satisfy this constraint. In_
particular, we denote this value by Î¾w := _w2 [1]b_ [+][ f]w3 _a_ 1 1 [.] f

_âˆ’_

-  Î»f[âˆ—]: For each j _Sm[âˆ—]_ [, we take][ Î»][âˆ—]j [:= 8 max][(][Z]n[,][Î²][âˆ—][)][âˆˆD]m
regularization parameter. For each âˆˆ _j /âˆˆ_ fSm[âˆ—] [, we take][ Î»][âˆ—]j [=][ B][|âˆ‡][L][2][, which is the upper bound of][n][(][Z][n][,][ Î²][âˆ—][)][j][| âˆ¨] _[Îµ][ as the target]_
_âˆ¥âˆ‡Î²Ln(Z1:n, 0)âˆ¥âˆ_ by Assumption C.1.

-  Î·: For all j, take Î·j = log 9 so that the decrease ratio is Ïƒ(Î·j) = 0.9.

Clearly, this set of parameters satisfy the conditions in Theorem D.1, so we can apply its result in
this proof.

In the following, we will show that, with this specification of the parameters, PLISAÎ¸ can achieve
the recovery accuracy stated in Theorem 3.1.

be the number of blocks after whichLet t0 = min {t : t â‰¥ 0, Î»[âˆ—] = max{0 Î».9t[t](|âˆ‡Z1:Î²nL; Î¸n) =(Z1: Î»n, 0[âˆ—]. We know)|, Î»[âˆ—]}, Z1: tn0 âˆˆD is a small number becausem, Î»[âˆ—] _âˆˆ_ _Î¸ âˆˆ_ Î˜(DM )}
the decrease rate is linear. To be more clear, it is easy to show that t0 log _BÎµ2_ _/ log(10/9)._

Therefore, after t0 cells, the regularization parameters do not change anymore. That is, â‰¤

  

**_Î»t(Z1:n; Î¸) = Î»[âˆ—],_** _t_ _t0._
_âˆ€_ _â‰¥_
Since the specified parameters satisfy the conditions in Theorem D.1, we can follow the same way
as how we derive Eq. 26 to obtain that
_Ï‰Î»tâˆ’1_ (Î²tâˆ’1) â‰¤ 1/4, _âˆ€t = 1, Â· Â· Â·, T._
Since we have Î»t = Î»[âˆ—] for t â‰¥ _t0. The last (T âˆ’_ _t0) cells can be viewed as a single cell with_
_K(T_ _t0) many steps. Therefore, we can apply Lemma G.2 and Lemma G.5 to obtain_
_âˆ’_

_Ï‰Î»t_ (Î²t[K][)][ â‰¤] [2][âˆš][2][Ï][+] (1 _Î±(Ï_ _Î¾w))[K][(][t][âˆ’][t][0][)][âˆ’][1][ 29][/][2][âˆ¥][(][Î»][t][âˆ’][1][)][S][âˆ—]_ _[âˆ¥]2[2]_

_Ïµ_ s _âˆ’_ _âˆ’_ _âˆ’_ _Ï_ _Î¾w_

_âˆ’_ _âˆ’_

[e] 29Ï+ 1 _K(tâˆ’t0)âˆ’1_

_â‰¤_ s _Ïâˆ’_ _âˆ’_ _Î¾w_ (1 + _Î±Ï+_ ) _[âˆ¥][(][Î»][0][ âˆ¨]_ _Îµ[Î»][âˆ—][)][S][âˆ—]_ _[âˆ¥][2]_ (1 âˆ’ _Î±(Ïâˆ’_ _âˆ’_ _Î¾w))_

p

29Ï+ 1 _âˆšs[âˆ—]B2_ _K(tâˆ’t0)âˆ’1_

_â‰¤_ s _Ïâˆ’_ _âˆ’_ _Î¾w_ (1 + _Î±Ï+_ ) _Îµ_ (1 âˆ’ _Î±(Ïâˆ’_ _âˆ’_ _Î¾w))_

p

= cÎ¸âˆšs[âˆ—]Îµ[âˆ’][1] exp( _CÎ¸K(t_ _t0)),_

_âˆ’_ _âˆ’_

where CÎ¸ = âˆ’ [1]2 [log (1][ âˆ’] _[Î±][(][Ï][âˆ’]_ _[âˆ’]_ _[Î¾][w][))][,][ c][Î¸][ =]_ _Ïâˆ’29âˆ’ÏÎ¾+w_ [(1 +] _Î±Ï1+_ [)] 1âˆ’Î±(ÏBâˆ’2âˆ’Î¾w) [. By Lemma][ G.5][,]

q


_Ï‰Î»t_ (Î²t[K][) +][ 17]8 **_Î»[âˆ—]S[âˆ—]_** _[âˆ¥][2]_

_âˆ¥_

**_Î²t_** **_Î²[âˆ—]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_  _Ï_ _Î¾w_

[e] _âˆ’_ _âˆ’_ 17

_S[âˆ—]_ _[âˆ¥][2]_ _cÎ¸Îµ[âˆ’][1][âˆš]s[âˆ—]_ exp( _CÎ¸K(t_ _t0)) +_ 8 _[âˆ¥][Î»]S[âˆ—]_ _[âˆ—]_ _[âˆ¥][2]_
_â‰¤_ _Ï[âˆ¥]âˆ’[Î»][âˆ—]âˆ’_ _Î¾w_ _âˆ’_ _âˆ’_ _Ïâˆ’_ _âˆ’_ _Î¾w_

_cËœÎ¸Îµ[âˆ’][1]s[âˆ—]_ exp( _CÎ¸K(t_ _t0)) + c[â€²]Î¸[âˆ¥][Î»][âˆ—]S[âˆ—]_ _[âˆ¥][2]_ (29)
_â‰¤_ _âˆ’_ _âˆ’_

where ËœcÎ¸ = _Ïâˆšâˆ’sâˆ’[âˆ—]BÎ¾w2_ _[c][Î¸][ and][ c]Î¸[â€²]_ [=] 8(Ïâˆ’17âˆ’Î¾w) [. What remains is bounding][ âˆ¥][Î»]S[âˆ—] _[âˆ—]_ _[âˆ¥][2][. First, we define a]_

condition number as

_Îºm = max_ 8 max(Zn,Î²âˆ—)âˆˆDm |âˆ‡Î²Ln(Zn, Î²[âˆ—])j| _._
_jâˆˆSm[âˆ—]_  8 min(Zn,Î²âˆ—)âˆˆDm |âˆ‡Î²Ln(Zn, Î²[âˆ—])j| âˆ¨ _Îµ_ 


-----

In fact, Îºm â‰¤ _[B]Îµ[2]_ [. Then recall the specification of][ Î»][âˆ—] [at the beginning of this proof. We have]


**_Î»[âˆ—]S[âˆ—]_** _[âˆ¥][2]_ 8Îºm **_Î²Ln(Zn, Î²[âˆ—])j_** _Îµ_
_âˆ¥_ _[â‰¤]_ _jXâˆˆS[âˆ—]_ _|âˆ‡_ _| âˆ¨_

8Îºm ( **_Î²Ln(Zn, Î²[âˆ—])_** _Îµ)Sâˆ—_ 2.
_â‰¤_ _âˆ¥_ _âˆ‡_ _âˆ¨_ _âˆ¥_

Plugging this back to Eq. 29, we have

_âˆ¥Î²t âˆ’_ **_Î²[âˆ—]âˆ¥2 â‰¤_** _cËœÎ¸Îµ[âˆ’][1]s[âˆ—]_ exp(âˆ’CÎ¸K(t âˆ’ _t0)) + c[â€²]Î¸[8][Îº][m][âˆ¥][(][âˆ‡][Î²][L][n][(][Z][n][,][ Î²][âˆ—][)][ âˆ¨]_ _[Îµ][)][S][âˆ—]_ _[âˆ¥][2][.]_

This is equivalent to the statement to be proved.


-----

F GENERALIZATION ANALYSIS: PROOF OF THEOREM 4.1

We first state a well-known inequality that bounds the generalization gap by empirical Rademacher
_complexity._

**Theorem F.1 (Adapted from Theorem 26.5 (Shalev-Shwartz & Ben-David, 2014)). Assume that for**
_all (Z1:n, Î²[âˆ—]) âˆˆP and all Î¸ âˆˆ_ Î˜ we have that â„“(Î²T (Z1:n; Î¸), Î²[âˆ—]) â‰¤ _c. Then with probability at_
_least 1 âˆ’_ _Ïµ, for all Î¸ âˆˆ_ Î˜,


2 log(4Ïµ[âˆ’][1])


_Lgen(P(P); Î¸) âˆ’Ltrain[Î³][=0]_ [(][D][m][;][ Î¸][)][ â‰¤] [2][R][m][(][â„“][Î˜][) + 4][c]


_where â„“Î˜ := {(Z1:n, Î²[âˆ—]) 7â†’âˆ¥Î²T (Z1:n; Î¸) âˆ’_ **_Î²[âˆ—]âˆ¥2[2]_** [:][ Î¸][ âˆˆ] [Î˜][}][ is the space of loss functions of our]
_model PLISAÎ¸, and Rm(â„“Î˜) is its empirical Rademacher complexity. It is defined as_

2

_Rm(â„“Î˜) := EÏƒ supÎ¸_ Î˜ _m1_ _mi=1_ _[Ïƒ][i]_ **_Î²T (Z1:[(][i]n[)]_** _i_ [;][ Î¸][)][ âˆ’] **_[Î²][âˆ—][(][i][)]_**
_âˆˆ_ 2 _[,]_

P

_where {Ïƒi}i[m]=1_ _[are][ m][ independent Rademacher random variables.]_


Therefore, it resorts to bound the empirical Rademacher complexity, which can be bounded via
Dudleyâ€™s integral. The following theorem states the bound for the empirical Rademacher complexity
and its proof follows.

**Theorem F.2 (Empirical Rademacher complexity bound). Assume the assumptions in Theorem 4.1.**
_Let Î˜ = Î˜(Dm) be the constrained space defined in Definition D.1. Let â„“Î˜ := {(Z1:n, Î²[âˆ—]) 7â†’_
_âˆ¥Î²T (Z1:n; Î¸) âˆ’_ **_Î²[âˆ—]âˆ¥2[2]_** [:][ Î¸][ âˆˆ] [Î˜][}][ be the space of loss functions of our model][ PLISA][Î¸][. Then the]
_empirical Rademacher complexity is bounded by Rmâ„“Î˜_
_â‰¤_

_c1_

log _c2âˆšmK(T_ _t0) exp(_ _CÎ˜K(T_ _t0))_ 1 + c3d log _c4âˆšm (1_ exp( _CÎ˜KT_ ))

_âˆšm_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ¨_ _âˆ’_ _âˆ’_

q

     

_where c1, c2, c3, c4 are some constants independent of d, m, K and T_ _._

_Proof. The classical Dudleyâ€™s entropy integral bound gives us an upper bound for the empirical_
Rademacher complexity in terms of the covering number.


_âˆ¥â„“Î˜âˆ¥Pm,âˆ_

inf 4Î± + [12] log (Ïµ, â„“Î˜, L2(Pm)) dÏµ
_Î±>0_ _âˆšm_ _Î±_ _N_

Z

4 _âˆ¥â„“Î˜âˆ¥Pm,âˆ_ p

log (Ïµ, â„“Î˜, L2(Pm)) dÏµ

_âˆšm + âˆš[12]m_ 1 _N_

Z _âˆšm_

p

4 1

log Î˜, L2(Pm) _._

_âˆšm + [12][âˆ¥][â„“]âˆš[Î˜][âˆ¥]m[P][m][,][âˆ]_ s _N_ _âˆšm, â„“_

 


4Î± + [12]
_âˆšm_


_Rmâ„“Î˜_ inf
_Î±>0_
_â‰¤_


The notation Pm means the empirical measure defined based on the samples in Dm, and

_âˆ¥â„“Î˜âˆ¥Pm,âˆ_ := supÎ¸âˆˆÎ˜ _Pm(â„“Î¸)_


**_Î²T (Z1:n; Î¸)_** **_Î²[âˆ—]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_
(Z1:nX,Î²[âˆ—])âˆˆDm

19/8

(Î»t(Z1:n; Î¸))Sâˆ— 2
_Ï_ _Î¾max_ _âˆ¥_ _âˆ¥_

(Z1:nX,Î²[âˆ—])âˆˆDm _âˆ’_ _âˆ’_

19/8 _âˆšs[âˆ—]_ max _B2, Î»max_ _C._

_Ï_ _Î¾max_ _{_ _} â‰¤_

(Z1:nX,Î²[âˆ—])âˆˆDm _âˆ’_ _âˆ’_


= sup
_Î¸âˆˆÎ˜_

by Theorem D.1 _â‰¤_ _Î¸supâˆˆÎ˜_

_â‰¤_ _Î¸supâˆˆÎ˜_


Here we use a constant C as the upper bound because we only care about the scales in d, m, K and
_T_ . Next, we bound the covering number _âˆš1m_ _, â„“Î˜, L2(Pm)_ . By the key result in Lemma 4.1, it
_N_
 


-----

is easy to derive that

_â„“Î¸_ _â„“Î¸â€²_ _L2(Pm)_ 2C _c1K(T_ _t0)_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ’_



_s[âˆ—]_ _Î±_ _Î±[â€²]_ exp( _CÎ˜K(T_ _t0))_
_|_ _âˆ’_ _|_ _âˆ’_ _âˆ’_


+ _c2âˆ¥Î· âˆ’_ **_Î·[â€²]âˆ¥2 + c3âˆ¥Î»[âˆ—]_** _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2 + c4âˆšdâˆ¥w âˆ’_** **_w[â€²]âˆ¥2_** (1 âˆ’ exp(âˆ’CÎ˜KT ))
cK(T _t0)_ _Î±_ _Î±[â€²]_ exp( _CÎ˜K(T_ _t0))_  

_â‰¤_ _âˆ’_ _|_ _âˆ’_ _|_ _âˆ’_ _âˆ’_

+ c _âˆ¥Î· âˆ’_ **_Î·[â€²]âˆ¥2 + âˆ¥Î»[âˆ—]_** _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2 +_** _âˆšdâˆ¥w âˆ’_ **_w[â€²]âˆ¥2_** (1 âˆ’ exp(âˆ’CÎ˜KT )) /
 

From now on, we abuse the symbol c to generally represent some constant that does not depend on
_d, m, K, T_ .


_Ïµ_

_Î±min,_ [1]
_cK(T_ _t0) exp(_ _CÎ˜K(T_ _t0))_ _[,]_ _Ï+_
_âˆ’_ _âˆ’_ _âˆ’_ 

_Ïµ_

_c (1_ exp( _CÎ˜KT_ )) _[,][ [][Î·][min][, Î·][max][]][d][, â„“][2]_
_âˆ’_ _âˆ’_ 


(Ïµ, â„“Î˜, L2(Pm))
_N_ _â‰¤N_

_Ã— N_

_Ã— N_

_Ã— N_


_, |Â·|_


_c (1_ exp( _CÎ˜KT_ )) _[,]_
_âˆ’_ _âˆ’_



[Î»j,min, Î»j,max], â„“2
_Ã—_
_j=1_

Y


_Ïµ_

_, [wmin, wmax][3], â„“2_ _._

_Ã— N_ _câˆšd (1_ exp( _CÎ˜KT_ ))
 _âˆ’_ _âˆ’_ 

For the covering number of athe Ïµ-packing number. That is, d-dimensional compact vector space(T, Ïµ, â„“2) (T, Ïµ, â„“2) _c_ _j=1 T âŠ†Tj,maxR[d]âˆ’Ïµ, we can bound it byTj,min_ + 1 for some
_N_ _â‰¤M_ _â‰¤_

constant c. Applying this fact, we have  

[Q][d]

_cK(T_ _t0) exp(_ _CÎ˜K(T_ _t0))_
(Ïµ, â„“Î˜, L2(Pm)) _âˆ’_ _âˆ’_ _âˆ’_ 1
_N_ _â‰¤_ _Ïµ_ _âˆ¨_
 

_d_

_c (1_ exp( _CÎ˜KT_ ))
_âˆ’_ _âˆ’_ + 1

_Ã—_ _Ïµ_

_j=1_  

Y

_d_

_c (1_ exp( _CÎ˜KT_ ))
_âˆ’_ _âˆ’_ + 1

_Ã—_ _Ïµ_

_j=1_  

Y

3câˆšd (1 exp( _CÎ˜KT_ )) 3

_âˆ’_ _âˆ’_

_Ã—_ _Ïµ_ !


which implies

1
log Î˜, L2(Pm)
_N_ _âˆšm, â„“_
 

log _c[âˆš]mK(T_ _t0) exp(_ _CÎ˜K(T_ _t0))_ 1
_â‰¤_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ¨_

+ (2d) log  _c[âˆš]m (1_ exp( _CÎ˜KT_ )) + 1 + 3 log _câˆšdm (1_ exp( _CÎ˜KT_ ))
_âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_

log _c[âˆš]mK _ (T _t0) exp(_ _CÎ˜K(T_ _t0))_ 1 + cd log _c[âˆš]m (1_ exp( _CÎ˜KT_ )) + 1
_â‰¤_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ¨_ _âˆ’_ _âˆ’_

Therefore,  _Rmâ„“Î˜_   
_â‰¤_

_c_

log _c[âˆš]mK(T_ _t0) exp(_ _CÎ˜K(T_ _t0))_ 1 + cd log _c[âˆš]m (1_ exp( _CÎ˜KT_ ))

_âˆšm_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ¨_ _âˆ’_ _âˆ’_

q

    


-----

F.1 ROBUSTNESS TO PARAMETER PERTURBATION: PROOF OF LEMMA 4.1

We split the parametersÎ¸2 = {Î»[âˆ—], w, Î·}. Clearly, the robustness can be bounded by Î¸ = {Î»[âˆ—], w, Î·, Î±} into two sets Î¸ = Î¸1 âˆª _Î¸2, where Î¸1 = {Î±} and_

_âˆ¥Î²T (Z1:n; Î¸1 âˆª_ _Î¸2) âˆ’_ **_Î²T (Z1:n; Î¸1[â€²]_** _[âˆª]_ _[Î¸][2][)][âˆ¥][2]_ [+][ âˆ¥][Î²][T] [(][Z][1:][n][;][ Î¸]1[â€²] _[âˆª]_ _[Î¸][2][)][ âˆ’]_ **_[Î²][T]_** [(][Z][1:][n][;][ Î¸]1[â€²] _[âˆª]_ _[Î¸]2[â€²]_ [)][âˆ¥][2][.]

We derive the upper bounds of these two terms in Lemma F.1 and Lemma F.2, which imply


_âˆ¥+Î²T (CZ11:Î·n; Î¸)Î· âˆ’[â€²]_ **_Î²2 +T ( CZ1:2nÎ»; Î¸[âˆ—][â€²])âˆ¥2Î» â‰¤[âˆ—â€²]_** _C2 +âˆšs C[âˆ—]K4âˆš (dT âˆ’w_ _t0)w Î´[K][â€²]_ [(]2[T][ âˆ’] 1[t][0] âˆ’[)] _|Î±Î´ âˆ’KTÎ±,[â€²]|_

_âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ 1 _Î´_
  _âˆ’_


where Î´ := 1 âˆ’ _Î±min(Ïâˆ’_ _âˆ’_ _Î¾max) < 1. Lemma 4.1 is equivalent to this inequality by taking_

_CÎ˜ = âˆ’_ log(pÎ´) > 0. Therefore, the key derivation steps are in the proof of Lemma F.1 and
Lemma F.2, as stated below.

**Lemma F.1. Assume the assumptions in Lemma 4.1 are satisfied. Let**

_Î¸ = {Î»[âˆ—], w, Î·, Î±}_ _and_ _Î¸[â€²]_ = {Î»[âˆ—], w, Î·, Î±[â€²]}

_be parameters in the constrained space Î˜._ _Let {Î²t}t[T]=1_ [=][ PLISA][Î¸][(][Z][1:][n][)][ and][ {][Î²][t][â€²][}]t[T]=1 [=]
_PLISAÎ¸[â€²]_ (Z1:n) be the intermediate outputs of PLISA with different parameters Î¸ and Î¸[â€²]. Assume


_/ log_ _Î´[âˆ’][1][]_ + 1,
 


_s[âˆ—](B2 + Î»max)_


29Ï+

(1 +
_Ïâˆ’_ _âˆ’_ _Î¾max_


_K â‰¥_ log


_Î±minÏ+_


_where Î´ :=_


1 âˆ’ _Î±min(Ïâˆ’_ _âˆ’_ _Î¾max) < 1. Then_


_s[âˆ—]K (T_ _t0) Î´[K][(][T][ âˆ’][t][0][)]_ _Î±_ _Î±[â€²]_ _._
_âˆ’_ _|_ _âˆ’_ _|_


**_Î²T_** **_Î²T_** _â€²_ 2 _C_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_

_Proof. By triangular inequality,_


**_Î²t[k]_** **_Î²t[k]â€²_** MPG(Î²t[k][âˆ’][1]; Î»t, w, Î±) MPG(Î²t[k][âˆ’][1]â€²; Î»t, w, Î±â€²)

_[âˆ’]_ [e] 2 [=] _âˆ’_ 2

_â‰¤_ MPG[e] (Î²t[k][âˆ’][1]; Î»t, w, Î±) âˆ’[e] MPG(Î²t[k][âˆ’][1]; Î»t, w, Î±[â€²]) [e]2

WLOG, assume Î± > Î±+ MPG[â€²][e]. Applying Lemma(Î²[e]t[k][âˆ’][1]; Î»t, w, Î±[â€²]) âˆ’ F.3MPG and Lemma[e] (Î²[e]t[k][âˆ’][1]â€²; Î» F.4t, w to the above two terms on the right, Î±â€²) 2
hand side, we obtain


_Î±_ _Î±[â€²]_

**_Î²t[k]_** **_Î²t[k]â€²_** **_Î²t[k][âˆ’][1]_** **_Î²t[k][âˆ’][1]â€²_** 2 + _|_ _âˆ’_ _|_ **_Î²t[k]_** **_Î²t[k][âˆ’][1]_**

_[âˆ’]_ [e] 2 _[â‰¤]_ _[Î´][âˆ¥]_ [e] _âˆ’_ [e] _âˆ¥_ r _Î± + Î±[â€²]_ _[âˆ’]_ [e] 2

[e] _â‰¤_ _Î´âˆ¥Î²[e]t[k][âˆ’][1]_ _âˆ’_ **_Î²[e]t[k][âˆ’][1]â€²âˆ¥2 + c |Î± âˆ’_** _Î±â€²|_ **_Î²t[k][e][âˆ’]_** **_Î²[e]t[k][âˆ’][1]_** 2 (30)

where c is the Lipschtiz constant. c is a finite number because Î± is bounded and positive. Applying[e]
it recursively, we have


_K_

_Î´[K][âˆ’][k]_ **_Î²t[k]_** **_Î²t[k][âˆ’][1]_** (31)
_k=1_ _[âˆ’]_ [e] 2 _[.]_

X

[e]


**_Î²t[K]_** **_Î²t[K]_** _â€²_ **_Î²t[0]_** **_Î²t[0]â€²_** 2 + c _Î±_ _Î±â€²_

[e] _[âˆ’]_ [e] 2 _[â‰¤]_ _[Î´][K][âˆ¥]_ [e] _[âˆ’]_ [e] _âˆ¥_ _|_ _âˆ’_ _|_


-----

Now we bound the term **_Î²t[k]_** **_Î²t[k][âˆ’][1]_**

_[âˆ’]_ [e] 2[. By Lemma][ G.1][ and Lemma][ G.2][,]

[e] 2Î±min

**_Î²t[k]_** **_Î²t[k][âˆ’][1]_** _Ï†Î»t,w(Î²t[k][âˆ’][1])_ _Ï†Î»t,w(Î²Î»t_ )

_[âˆ’]_ [e] 2 s 2 _Î±minÏ+_ _âˆ’_

_[â‰¤]_ _âˆ’_ 

[e] 2 [e] [b]

_Ï†Î»t,w(Î²t[0][)][ âˆ’]_ _[Ï†][Î»]t[,][w][(][ b]Î²Î»t_ ) _Î´[k][âˆ’][1]_

_â‰¤_ s _Ï+_

 

2 10[e]

(By Lemma G.6) (Î»t)Sâˆ— 2Î´[k][âˆ’][1]
_â‰¤_ s _Ï+_ s _Ïâˆ’_ _âˆ’_ _Î¾max_ _âˆ¥_ _âˆ¥_


2 10

_B2_

_â‰¤_ s _Ï+_ s _Ïâˆ’_ _âˆ’_ _Î¾max_

= c[â€²][âˆš]s[âˆ—]Î´[k],


_s[âˆ—]Î´[k][âˆ’][1]_


where c[â€²] :=


where c[â€²] := _Ï2+_ _Ïâˆ’âˆ’10Î¾max_ _[B][2][Î´][âˆ’][1][. However, we can have a tighter bound for this term if][ t][ is]_

larger than a certain integer. More precisely, recall the definition thatSince Ïƒ(Î·maxq) < 1q, the entries of Î»0 _Ïƒ(Î·)[t]_ will decrease exponentially to reach the entry values of Î»t = max {Î»0 â—¦ _Ïƒ(Î·)[t], Î»[âˆ—]}._
**_Î»of blocks after which[âˆ—]. Let t0 = min {t : Î» tt â‰¥ = Î»0, Î»[âˆ—]. We know[âˆ—]_** = max â—¦ _{ tÎ»00 is a small number because the decrease rate is linear. â—¦_ _Ïƒ(Î·max)[t], Î»[âˆ—]}, âˆ€Î»[âˆ—]_ _âˆˆ_ _Î¸ âˆˆ_ Î˜(DM )} be the number

Now, the regularization parameters satisfy Î»t = Î»[âˆ—], âˆ€t â‰¥ _t0. Therefore, we can apply Lemma G.1_
and Lemma G.2 again to obtain the following bound for all t _t0:_
_â‰¥_


_Ï+_


2Î±min

2 _Î±minÏ+_
_âˆ’_


**_Î²t[k]_** **_Î²t[k][âˆ’][1]_**
2

[e] _[âˆ’]_ [e] _[â‰¤]_

_â‰¤_

(By Lemma G.6) _â‰¤_


2Î±min

_Ï†Î»âˆ—,w(Î²t[k][âˆ’][1])_ _Ï†Î»âˆ—,w(Î²Î»âˆ—_ )

s 2 _Î±minÏ+_ _âˆ’_

_[â‰¤]_ _âˆ’_  

2 [e] [b]

_â‰¤_ s _Ï+_ _Ï†Î»[âˆ—],w(Î²t[k]0[âˆ’][1]) âˆ’_ _Ï†Î»âˆ—,w(Î²Î»âˆ—_ ) _Î´[K][(][t][âˆ’][t][0][)+][k][âˆ’][1]_

 

2 10[e] [b]

(Î»[âˆ—])Sâˆ— 2Î´[K][(][t][âˆ’][t][0][)+][k][âˆ’][1]

_â‰¤_ s _Ï+_ s _Ïâˆ’_ _âˆ’_ _Î¾max_ _âˆ¥_ _âˆ¥_

= c[â€²][âˆš]s[âˆ—]Î´[K][(][t][âˆ’][t][0][)+][k].


Combining the two different bounds for **_Î²t[k]_** **_Î²t[k][âˆ’][1]_**

_[âˆ’]_ [e] 2 [with Eq.][ 31][, we have]

[e] _C_ _Î±_ _Î±[â€²]_ _âˆšs[âˆ—]_ [P][K]k=1 _[Î´][K][âˆ’][k][Î´][k]_ if t < t0

**_Î²t_** **_Î²t[â€²][âˆ¥]2_** _t_ 1[âˆ¥][2] [+] _|_ _âˆ’_ _|_
_âˆ¥_ _âˆ’_ _[â‰¤]_ _[Î´][K][âˆ¥][Î²][t][âˆ’][1]_ _[âˆ’]_ **_[Î²][â€²]âˆ’_** (C |Î± âˆ’ _Î±[â€²]|_ _âˆšs[âˆ—]_ [P][K]k=1 _[Î´][K][âˆ’][k][Î´][K][(][t][âˆ’][t][0][)+][k]_ if t â‰¥ _t0_

= Î´[K]âˆ¥Î²tâˆ’1 âˆ’ **_Î²t[â€²]âˆ’1[âˆ¥][2]_** [+] _CC |Î±Î± âˆ’_ _Î±Î±â€²[â€²]|_ _âˆšâˆšss[âˆ—][âˆ—]KÎ´KÎ´[K][K][(][t][âˆ’][t][0][+1)]_ ifif t < t t _t00_
 _|_ _âˆ’_ _|_ _â‰¥_

where C = cc[â€²]. We apply the above inequality recursively and obtain that

**_Î²T_** **_Î²T_** _â€²_ 2 _Câˆšs[âˆ—]KÎ´[K]_ _t0âˆ’1_ _Î´[K][(][T][ âˆ’][t][)]_ _Î±_ _Î±[â€²]_ + _T_ _Î´[K][(][T][ âˆ’][t][)]Î´[K][(][t][âˆ’][t][0][)]_ _Î±_ _Î±[â€²]_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _t=1_ _|_ _âˆ’_ _|_ _t=t0_ _|_ _âˆ’_ _|!_

X X

= Câˆšs[âˆ—]KÎ´[K] _Î´[K][(][T][ âˆ’][t][0][+1)][ 1][ âˆ’]_ _[Î´][K][(][t][0][âˆ’][1)]_ + (T _t0)Î´[K][(][T][ âˆ’][t][0][)]_ _Î±_ _Î±[â€²]_

1 _Î´[K]_ _âˆ’_ _|_ _âˆ’_ _|_

 _âˆ’_ 

= Câˆšs[âˆ—]KÎ´[K] _Î´K(1 âˆ’_ _Î´K(t0âˆ’1))_ + (T _t0)_ _Î´[K][(][T][ âˆ’][t][0][)]_ _Î±_ _Î±[â€²]_

1 _Î´[K]_ _âˆ’_ _|_ _âˆ’_ _|_

 _âˆ’_  

_â‰¤_ _Câˆšs[âˆ—]K (T âˆ’_ _t0 + 1) Î´[K][(][T][ âˆ’][t][0][+1)]_ _|Î± âˆ’_ _Î±[â€²]|_

_Câˆšs[âˆ—]K (T_ _t0) Î´[K][(][T][ âˆ’][t][0][)]_ _Î±_ _Î±[â€²]_
_â‰¤_ _âˆ’_ _|_ _âˆ’_ _|_


-----

**Lemma F.2. Assume the assumptions in Lemma 4.1 are satisfied. Let**

_Î¸ = {Î»[âˆ—], w, Î·, Î±}_ _and_ _Î¸[â€²]_ = {Î»[âˆ—â€²], w[â€²], Î·[â€²], Î±}

_be parameters in the constrained space Î˜._ _Let {Î²t}t[T]=1_ [=][ PLISA][Î¸][(][Z][1:][n][)][ and][ {][Î²][t][â€²][}]t[T]=1 [=]
_PLISAÎ¸â€²_ (Z1:n) be the intermediate outputs of PLISA with different parameters Î¸ and Î¸[â€²]. Then
**_Î²T (Z1:n; Î¸)_** **_Î²T (Z1:n, Î¸[â€²])_** 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_

_C1_ **_Î·_** **_Î·[â€²]_** 2 + C2 **_Î»[âˆ—]_** **_Î»[âˆ—â€²]_** 2 + C4âˆšd **_w_** **_w[â€²]_** 2 1 âˆ’ _Î´KT_ _,_
_âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ 1 _Î´_
  _âˆ’_

_where Î´ :=_ 1 _Î±min(Ï_ _Î¾max) < 1 and C1,2,4 are some constants._

_âˆ’_ _âˆ’_ _âˆ’_

p

_Proof.PLISA LetÎ¸(Z {1:nÎ²)t and}t[T]=1 PLISA[âˆª{]Î²[ e]t[k]Î¸[}]â€²t[T](=1Z1:Kk=1n) respectively. By triangle inequality,[and][ {][Î²][t][â€²][}]t[T]=1_ _[âˆª{]Î²[ e]t[k]â€²}Tt=1Kk=1_ [be the intermediate outputs of]

**_Î²t[k]_** **_Î²t[k]â€²_** MPG(Î²t[k][âˆ’][1]; Î»t, w, Î±) MPG(Î²t[k][âˆ’][1]â€²; Î»tâ€², wâ€², Î±â€²)

_[âˆ’]_ [e] 2 [=] _âˆ’_ 2

_â‰¤[e]_ MPG(Î²t[k][âˆ’][1]; Î»t, w, Î±[e]) âˆ’ MPG(Î²t[k][âˆ’][1]â€²; Î»t, w, Î±[e]) 2

+ MPG(Î²[e]t[k][âˆ’][1]â€²; Î»t, w, Î±) âˆ’ MPG([e]Î²t[k][âˆ’][1]â€²; Î»tâ€², w, Î±) 2

+ MPG(Î²[e]t[k][âˆ’][1]â€²; Î»tâ€², w, Î±) âˆ’ MPG( eÎ²t[k][âˆ’][1]â€²; Î»tâ€², wâ€², Î±) 2 _[.]_

Applying Lemma F.3, Lemma F.5, and Lemma F.6 to the above 3 terms on the right hand side, we

[e] e

obtain
**_Î²t[k]_** **_Î²t[k]â€²_** **_Î²t[k][âˆ’][1]_** **_Î²t[k][âˆ’][1]â€²_** 2 + [2] **_Î»t_** **_Î»[â€²]t[âˆ¥][2]_** + C **_w_** **_w[â€²]_** 2 **_Î»t_** 2, (32)

_[âˆ’]_ [e] 2 _[â‰¤]_ _[Î´][âˆ¥]_ [e] _âˆ’_ [e] _âˆ¥_ _Ï+_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ’_ (ii)âˆ¥ _âˆ¥_ _âˆ¥_

(i)

[e]

| {z }

where C is some absolute constant. | {z }

Term (i). By definition and triangular inequality,


**_Î»t_** **_Î»tâ€²_** 2 max **_Î»0_** _Ïƒ(Î·)[t], Î»[âˆ—]_ max **_Î»0_** _Ïƒ(Î·[â€²])[t], Î»[âˆ—]_ 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤âˆ¥_ _â—¦_ _âˆ’_ _â—¦_ _âˆ¥_
+ max **_Î»0_** _Ïƒ(Î·[â€²])[t], Î»[âˆ—]_ max **_Î»0_** _Ïƒ(Î·[â€²])[t], Î»[âˆ—â€²]_ 2
_âˆ¥_ _â—¦_ _âˆ’_ _â—¦_ _âˆ¥_
_â‰¤âˆ¥Î»0âˆ¥âˆtÏƒ(Î·max)[t][âˆ’][1]tâˆ¥Ïƒ(Î·) âˆ’_ _Ïƒ(Î·[â€²])âˆ¥2 + âˆ¥Î»[âˆ—]_ _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2_**

_â‰¤_ _[B]4[2]_ _[Ïƒ][(][Î·][max][)][t][t][âˆ¥][Î·][ âˆ’]_ **_[Î·][â€²][âˆ¥][2][ +][ âˆ¥][Î»][âˆ—]_** _[âˆ’]_ **_[Î»][âˆ—â€²][âˆ¥][2]_**


The last inequality holds by Assumptionsome constants C2 = _Ï2+_ [and][ Ëœ]C1 = C2 _[B]4 C.1[2]_ [,] and the bounded first derivative of Ïƒ(Â·). Therefore, for

(i) = [2] **_Î»t_** **_Î»[â€²]t[âˆ¥][2]_** _C1Ïƒ(Î·max)[t]t_ **_Î·_** **_Î·[â€²]_** 2 + C2 **_Î»[âˆ—]_** **_Î»[âˆ—â€²]_** 2

_Ï+_ _âˆ¥_ _âˆ’_ _[â‰¤]_ [Ëœ] _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_


_â‰¤_ _C1âˆ¥Î· âˆ’_ **_Î·[â€²]âˆ¥2 + C2âˆ¥Î»[âˆ—]_** _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2._**

The last inequality holds because the value Ïƒ(Î·max)[t]t is bounded by some constant.

Term (ii). Since âˆ¥Î»tâˆ¥2 â‰¤âˆ¥ max {Ïƒ(Î·max)[t]Î»0, Î»[âˆ—â€²]} âˆ¥2 â‰¤âˆ¥ max {Ïƒ(Î·max)[t]Î»0, Î»0} âˆ¥2 = âˆ¥Î»0âˆ¥2 â‰¤
_Bâˆšd,_


(ii) = C **_w_** **_w[â€²]_** 2 **_Î»t_** 2 _C4_
_âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ¥_ _â‰¤_


_d_ **_w_** **_w[â€²]_** 2.
_âˆ¥_ _âˆ’_ _âˆ¥_


Plugging the bounds for (i)-(iii) into Eq. 32, we have

**_Î²t[k]_** **_Î²t[k]â€²_** **_Î²t[k][âˆ’][1]_** **_Î²t[k][âˆ’][1]â€²_** 2 + C1 **_Î·_** **_Î·â€²_** 2 + C2 **_Î»âˆ—_** **_Î»âˆ—â€²_** 2 + C4

[e] _[âˆ’]_ [e] 2 _[â‰¤]_ _[Î´][âˆ¥]_ [e] _âˆ’_ [e] _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_


_d_ **_w_** **_w[â€²]_** 2.
_âˆ¥_ _âˆ’_ _âˆ¥_


-----

By direct computation,
**_Î²t[K]_** **_Î²t[K]_** _â€²_
2

_[âˆ’]_ [e]

[e]Î´[K] **_Î²t[0]_** **_Î²t[0]â€²_** _C1_ **_Î·_** **_Î·[â€²]_** 2 + C2 **_Î»[âˆ—]_** **_Î»[âˆ—â€²]_** 2 + C4âˆšd **_w_** **_w[â€²]_** 2 _[K][âˆ’][1]_ _Î´[k]_

_â‰¤_ _[âˆ’]_ [e] 2 [+] _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _k=0_
  X

= Î´[K] **_Î²[e]t[0]_** **_Î²t[0]â€²_** _C1_ **_Î·_** **_Î·[â€²]_** 2 + C2 **_Î»[âˆ—]_** **_Î»[âˆ—â€²]_** 2 + C4âˆšd **_w_** **_w[â€²]_** 2 1 âˆ’ _Î´K_

_[âˆ’]_ [e] 2 [+] _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ 1 _Î´ [.]_
  _âˆ’_

Recall that **_Î²t[K]_** [=][ Î²][t] [and][ e]Î²t[0] [=][ Î²][t][âˆ’][1][. We can apply the above inequality recursively and obtain that]

[e]

**_Î²T_** **_Î²T_** _â€²_ 2
_âˆ¥â‰¤_ _Î´ âˆ’[K]_ _âˆ¥Î²[e]T âˆ’âˆ¥1 âˆ’_ **_Î²T âˆ’1â€²âˆ¥2 +_** _C1âˆ¥Î· âˆ’_ **_Î·[â€²]âˆ¥2 + C2âˆ¥Î»[âˆ—]_** _âˆ’_ **_Î»[âˆ—â€²]âˆ¥2 + C4âˆšdâˆ¥w âˆ’_** **_w[â€²]âˆ¥2_** 11 âˆ’ _Î´Î´K_

_C1_ **_Î·_** **_Î·[â€²]_** 2 + C2 **_Î»[âˆ—]_**  **_Î»[âˆ—â€²]_** 2 + C4âˆšd **_w_** **_w[â€²]_** 2 1 âˆ’ _Î´K_ _T âˆ’1(Î´[K])[t]_  _âˆ’_
_â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ 1 _Î´_

_t=0_

  _âˆ’_ X

= _C1_ **_Î·_** **_Î·[â€²]_** 2 + C2 **_Î»[âˆ—]_** **_Î»[âˆ—â€²]_** 2 + C4âˆšd **_w_** **_w[â€²]_** 2 1 âˆ’ _Î´KT_ _._
_âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ 1 _Î´_
  _âˆ’_

**Lemma F.3 (Robustness to Î²). Assume (Z1:n, Î²[âˆ—])** _and_ _satisfies Assumption C.1. Assume_
1 _âˆˆP_ _P_
**_Î², Î²[â€²]_** _satisfy âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥0 â‰¤_** _s = s[âˆ—]_ + 2Ëœs and Î± â‰¤ _Ï+_ _[. Then]_


1 2Î± [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][w][)][Ï][+]_ **_Î²_** **_Î²[â€²]_** 2 (33)
_âˆ’_ _Ï_ _Î¾w + Ï+_ _âˆ¥_ _âˆ’_ _âˆ¥_

_âˆ’_ _âˆ’_

1 âˆ’ _Î± (Ïâˆ’_ _âˆ’_ _Î¾w) âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥2_** (34)


_MPG(Î²; Î», w, Î±)_ _MPG(Î²[â€²]; Î», w, Î±)_ 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_


_Proof._

MPG(Î²; Î», w, Î±) MPG(Î²[â€²]; Î», w, Î±) 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_
= âˆ¥TÎ±Â·Î» (Î² âˆ’ _Î± (âˆ‡LÎ»,w(Î²))) âˆ’TÎ±Â·Î» (Î²[â€²]_ _âˆ’_ _Î± (âˆ‡LÎ»,w(Î²[â€²])))âˆ¥2[2]_
**_Î²_** _Î± (_ _LÎ»,w(Î²))_ **_Î²[â€²]_** + Î± ( _LÎ»,w(Î²[â€²]))_ 2
_â‰¤âˆ¥_ _âˆ’_ _âˆ‡_ _âˆ’_ _âˆ‡_ _âˆ¥[2]_
= **_Î²_** **_Î²[â€²]_** 2 [+][ Î±][2][ âˆ¥âˆ‡][L][Î»][,][w][(][Î²][)][ âˆ’âˆ‡][L][Î»][,][w][(][Î²][â€²][)][âˆ¥]2[2]
_âˆ¥_ _âˆ’_ _âˆ¥[2]_

_[âˆ’]_ [2][Î±][âŸ¨][Î²][ âˆ’] **_[Î²][â€²][,][ âˆ‡][L][Î»][,][w][(][Î²][)][ âˆ’âˆ‡][L][Î»][,][w][(][Î²][â€²][)][âŸ©](35)[.]_**
Since on the restricted subspace **_Î² :_** **_Î²_** **_Î²[âˆ—]_** 0 _s[âˆ—]_ + 2Ëœs, LÎ» is (Ï _Î¾w)-strongly convex and_
_Ï+-smooth, by Lemma G.7,_ _{_ _âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _}_ _âˆ’_ _âˆ’_
**_Î²_** **_Î²[â€²],_** _LÎ»,w(Î²)_ _LÎ»,w(Î²[â€²])_
_âŸ¨_ _âˆ’_ _âˆ‡_ _âˆ’âˆ‡_ _âŸ©_

**_Î²_** **_Î²[â€²]_** 2 [+][ âˆ¥âˆ‡][L][Î»][,][w][(][Î²][)][ âˆ’âˆ‡][L][Î»][,][w][(][Î²][â€²][)][âˆ¥]2[2] _._

_â‰¥_ _Ï[(][Ï][âˆ’]_ _[âˆ’]Î¾w[Î¾][w] +[)] Ï[Ï][+]+_ _âˆ¥_ _âˆ’_ _âˆ¥[2]_ _Ï_ _Î¾w + Ï+_

_âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_

Combining this inequality with Eq. 35, we have
MPG(Î²; Î», w, Î±) MPG(Î²[â€²]; Î», w, Î±) 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_

_â‰¤_ 1 âˆ’ 2Î± _Ï[(][Ï][âˆ’]_ _[âˆ’]Î¾w[Î¾][w] +[)] Ï[Ï][+]+_ _âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥2[2]_**
 _âˆ’_ _âˆ’_ 

2
+ Î± _Î± âˆ’_ _Ï_ _Î¾w + Ï+_ _âˆ¥âˆ‡LÎ»,w(Î²) âˆ’âˆ‡LÎ»,w(Î²[â€²])âˆ¥2[2]_
 _âˆ’_ _âˆ’_ 

By the assumption that Î± â‰¤ _Ï1+_ [, the second term in the above inequality is non-positive. Further-]

more, this assumption also implies that 1 âˆ’ 2Î± [(]Ï[Ï]âˆ’[âˆ’]âˆ’[âˆ’]Î¾[Î¾]w[w]+[)]Ï[Ï]+[+]

_[â‰¥]_ [0][. Therefore,]

MPG(Î²; Î», w, Î±) MPG(Î²[â€²]; Î», w, Î±) 2 1 2Î± [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][w][)][Ï][+]_ **_Î²_** **_Î²[â€²]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ s _âˆ’_ _Ï_ _Î¾w + Ï+_ _âˆ¥_ _âˆ’_ _âˆ¥_

_âˆ’_ _âˆ’_


-----

**Lemma F.4 (Robustness to Î±). With out loss of generalization, assume Î± â‰¥** _Î±[â€²]. Denote_

**_Î²[+]_** := MPG(Î²; Î», w, Î±) _and_ **_Î²[+][â€²]_** := MPG(Î²; Î», w, Î±[â€²]).

_Then_


_Î±_ _Î±[â€²]_

**_Î²[+][â€²]_** **_Î²[+]_** 2 _âˆ’_ **_Î²[+]_** **_Î²_**
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _Î± + Î±[â€²]_ _âˆ’_

r

_Proof. Define the quadratic approximation function as_


_ÏˆÎ±,Î»,w(z, Î²) := LÎ»,w(Î²) +_ _LÎ»,w(Î²), z_ **_Î²_** + [1] 2 [+][ âˆ¥][z][âˆ¥]Î»,1 _[.]_ (36)
_âŸ¨âˆ‡_ _âˆ’_ _âŸ©_ 2Î± _[âˆ¥][z][ âˆ’]_ **_[Î²][âˆ¥][2]_**


Clearly,


MPG(Î²; Î», w, Î±) = arg min _ÏˆÎ±,Î»,w(z, Î²)._
**_z_**

Since ÏˆÎ±,Î»,w(z, Î²) is _Î±[1]_ [-strongly convex in][ z][, and that][ Î²][+][ :=][ MPG][(][Î²][;][ Î»][,][ w][, Î±][)][ is its optimal point,]

_ÏˆÎ±,Î»,w(z, Î²) â‰¥_ _ÏˆÎ±,Î»,w(Î²[+], Î²) + 2[1]Î±_ **_z âˆ’_** **_Î²[+]_** 2 _âˆ€z._ (37)

Similarly,

[2]

1
_ÏˆÎ±â€²,Î»,w(z, Î²) â‰¥_ _ÏˆÎ±â€²,Î»,w(Î²[+][â€²], Î²) +_ 2Î±[â€²] **_z âˆ’_** **_Î²[+][â€²]_** 2 _âˆ€z._ (38)

Taking z = Î²[+][â€²] in Eq. 37 and z = Î²[+] in Eq. 38 yields [2]

1

**_Î²[+]_** **_Î²[+][â€²]_**

2Î± _âˆ’_ 2 _[â‰¤]_ _[Ïˆ][Î±,][Î»][,][w][(][Î²][+][â€²][,][ Î²][)][ âˆ’]_ _[Ïˆ][Î±,][Î»][,][w][(][Î²][+][,][ Î²][)][,]_

1

2Î±[â€²] **_Î²[+]_** _âˆ’_ **_Î²[+][â€²]_** 2 [2][â‰¤] _[Ïˆ][Î±][â€²][,][Î»][,][w][(][Î²][+][,][ Î²][)][ âˆ’]_ _[Ïˆ][Î±][â€²][,][Î»][,][w][(][Î²][+][â€²][,][ Î²][)][.]_

Summing the above two inequalities, we have

[2]

1 1
2  _Î±_ [+ 1]Î±[â€²]  Î²[+] _âˆ’_ **_Î²[+][â€²]_** 2[2] _[â‰¤]_ + ÏˆÎ±,ÏˆÎ»Î±,â€²w,Î»(,Î²w[+](Î²[â€²],[+] Î²,) Î² âˆ’) _ÏˆÎ±Ïˆâ€²,Î±,Î»,Î»w,w(Î²(Î²[+][+][â€²], Î², Î²))_

_âˆ’_

(by Î± _Î±[â€²])_ _ÏˆÎ± â€²,Î»,w(Î²[+], Î²)_ _ÏˆÎ±,Î»,w(Î²[+], Î²)_ 
_â‰¥_ _â‰¤_ _âˆ’_

1

= [1] **_Î²[+]_** **_Î²_**

2 _Î±[â€²][ âˆ’]_ _Î±[1]_ _âˆ’_ 2 _[.]_

 

[2]


**Lemma F.5 (Robustness to Î»). Let Î²[+]** = MPG(Î²; Î», w, Î±) and Î²[+][â€²] = MPG(Î²; Î»[â€²], w, Î±). Then

**_Î²[+]_** **_Î²[+][â€²]_** 2 2Î± (Î» **_Î»[â€²])S_** 2, (39)
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_

_where S := supp(Î²[+]) âˆª_ supp(Î²[+][â€²]).

_Proof. Recall the quadratic approximation in Eq. 51 and the definition that MPG(Î²; Î», w, Î±) =_
arg minz ÏˆÎ±,Î»,w(z, Î²). By the _Î±[1]_ [-strongly convexity of][ Ïˆ][Î±,][Î»][,][w][ in][ z][, it holds true for all][ z][ that]

1

**_z_** **_Î²[+]_**

2Î± _âˆ’_ 2 _[â‰¤]_ _[Ïˆ][Î±,][Î»][,][w][(][z][,][ Î²][)][ âˆ’]_ _[Ïˆ][Î±,][Î»][,][w][(][Î²][+][,][ Î²][)]_

= _LÎ»,w(Î²)[2], z_ **_Î²[+]_** + [1] **_z_** **_Î²_** 2 **_Î²[+]_** **_Î²_** 2 + ( **_z_** **_Î»,1_** **_Î²[+]_** **_Î»,1[)]_** (40)
_âŸ¨âˆ‡_ _âˆ’_ _âŸ©_ 2Î± _âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[âˆ’]_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_

 

Similarly,

[2]

1

2Î± **_z âˆ’_** **_Î²[+][â€²]_** 2 (41)

_LÎ»â€²,w(Î²)[2], z_ **_Î²[+][â€²]_** + [1] **_z_** **_Î²_** 2 **_Î²[+][â€²]_** **_Î²_** 2 + ( **_z_** **_Î»â€²,1_** **_Î²[+][â€²]_** **_Î»[â€²],1[)][.]_** (42)
_â‰¤âŸ¨âˆ‡_ _âˆ’_ _âŸ©_ 2Î± _âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[âˆ’]_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_

 

[2]


-----

Taking z = Î²[+][â€²] in Eq. 40, taking z = Î²[+] in Eq. 42, and summing up the two inequalities, we have

1

**_Î²[+]_** **_Î²[+][â€²]_**

_Î±_ _âˆ’_ 2 _[â‰¤âŸ¨âˆ‡][L][Î»][,][w][(][Î²][)][ âˆ’âˆ‡][L][Î»][â€²][,][w][(][Î²][)][,][ Î²][+][â€²][ âˆ’]_ **_[Î²][+][âŸ©]_**

+ **_Î²[+]_** (Î»[â€²] **_Î»)_** 1 **_Î²[+][â€²]_** (Î»[â€²] **_Î»)_** 1

[2] _âˆ¥_ _â—¦_ _âˆ’_ _âˆ¥_ _âˆ’âˆ¥_ _â—¦_ _âˆ’_ _âˆ¥_

= âŸ¨âˆ‡QÎ»,w(Î²) âˆ’âˆ‡QÎ»â€²,w(Î²), Î²[+][â€²] _âˆ’_ **_Î²[+]âŸ©_** + âˆ¥Î²[+] _âˆ’_ **_Î²[+][â€²]âˆ¥|Î»âˆ’Î»â€²|,1_**

_d_

_qw[â€²]_ [(][Î»][j][, Î²][j][)][ âˆ’] _[q]w[â€²]_ [(][Î»][â€²]j[, Î²][j][)][||][Î²]j[+]â€² _Î²j+_

_â‰¤_ _j=1_ _|_ _âˆ’_ _[|][ +][ âˆ¥][Î²][+][ âˆ’]_ **_[Î²][+][â€²][âˆ¥][|][Î»][âˆ’][Î»][â€²][|][,][1]_**

X


_Î»j_ _Î»[â€²]j[||][Î²]j[+]â€²_ _Î²j+_
_j=1_ _|_ _âˆ’_ _âˆ’_ _[|][ +][ âˆ¥][Î²][+][ âˆ’]_ **_[Î²][+][â€²][âˆ¥][|][Î»][âˆ’][Î»][â€²][|][,][1]_**

X


(by Assumption B.1) â‰¤


= 2âˆ¥Î²[+] _âˆ’_ **_Î²[+][â€²]âˆ¥|Î»âˆ’Î»â€²|,1_**
2 (Î» **_Î»[â€²])S_** 2 **_Î²[+][â€²]_** **_Î²[+]_** 2
_â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ’_

where S := supp(Î²[+])âˆªsupp(Î²[+][â€²]). Dividing both side by âˆ¥Î²[+][â€²] _âˆ’_ **_Î²[+]âˆ¥2 draws the conclusion._**

**Lemma F.6 (Robustness to w). Let Î²[+]** = MPG(Î²; Î», w, Î±) and Î²[+][â€²] = MPG(Î²; Î», w[â€²], Î±). Then

**_Î²[+]_** **_Î²[+][â€²]_** 2 _C_ **_w_** **_w[â€²]_** 2 (Î»)S 2, (43)
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ¥_

_where S := supp(Î²[+]) âˆª_ supp(Î²[+][â€²]) and C is some absolute constant.

_Proof. Recall the quadratic approximation in Eq. 51 and the definition that MPG(Î²; Î», w, Î±) =_
arg minz ÏˆÎ±,Î»,w(z, Î²). By the _Î±[1]_ [-strongly convexity of][ Ïˆ][Î±,][Î»][,][w][ in][ Î²][, it holds true for all][ z][ in the]

restricted subspace that


1

**_z_** **_Î²[+]_**

2Î± _âˆ’_ 2 _[â‰¤]_ _[Ïˆ][Î±,][Î»][,][w][(][z][,][ Î²][)][ âˆ’]_ _[Ïˆ][Î±,][Î»][,][w][(][Î²][+][,][ Î²][)]_

= âŸ¨âˆ‡LÎ»,w(Î²)[2], z âˆ’ **_Î²[+]âŸ©_** + 2[1]Î± _âˆ¥z âˆ’_ **_Î²âˆ¥2[2]_** _[âˆ’]_ **_Î²[+]_** _âˆ’_ **_Î²_**



Similarly,


+ (âˆ¥zâˆ¥Î»,1 âˆ’ **_Î²[+]_** **_Î»,1[)]_** (44)


1

**_z_** **_Î²[+][â€²]_**

2Î± _âˆ’_ 2

_LÎ»,w[â€²]_ (Î²)[2], z **_Î²[+][â€²]_** + [1] **_z_** **_Î²_** 2 **_Î²[+][â€²]_** **_Î²_** 2 + ( **_z_** **_Î»,1_** **_Î²[+][â€²]_** **_Î»,1[)][.]_** (45)
_â‰¤âŸ¨âˆ‡_ _âˆ’_ _âŸ©_ 2Î± _âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[âˆ’]_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_

 

Taking z = Î²[+][â€²] in Eq. 44, taking z = Î²[+] in Eq. 45, and summing up the two inequalities, we have[2]


**_Î²[+]_** **_Î²[+][â€²]_**
2
_âˆ’_ _[â‰¤âŸ¨âˆ‡][L][Î»][,][w][(][Î²][)][ âˆ’âˆ‡][L][Î»][,][w][â€²]_ [(][Î²][)][,][ Î²][+][â€²][ âˆ’] **_[Î²][+][âŸ©]_**

= **_Î»,w(Î²)_** **_Î»,wâ€²_** (Î²), Î²[+][â€²] **_Î²[+]_**

[2] _âŸ¨âˆ‡Q_ _âˆ’âˆ‡Q_ _âˆ’_ _âŸ©_


_qw[â€²]_ [(][Î»][j][, Î²][j][)][ âˆ’] _[q]w[â€²]_ _[â€²]_ [(][Î»][j][, Î²][j][)][||][Î²]j[+]â€² _Î²j+_

_â‰¤_ _j=1_ _|_ _âˆ’_ _[|][.]_

X

Note that qw[â€²] [(][Î»][j][, Î²][j][) =][ P][3]i=1 exp(Z(ww)i) _[q][(][i][)][â€²][(][Î»][j][,][ Î²][j][)][ where][ Z][(][w][) =][ P]i[3]=1_ [exp(][w][i][)][. Then]

3

exp(wi) _i[)]_

_qw[â€²]_ [(][Î»][j][, Î²][j][)][ âˆ’] _[q]w[â€²]_ _[â€²]_ [(][Î»][j][, Î²][j][)][| â‰¤] _q[(][i][)][â€²](Î»j, Î²j)_
_|_ _Z(w)_ _âˆ’_ [exp(]Z(w[w][â€²])[â€²]

_i=1_

X

3

exp(wi) _i[)]_

(by Assumption B.1) _[Î»][j][.]_
_â‰¤_ _Z(w)_ _âˆ’_ [exp(]Z(w[w][â€²])[â€²]

_i=1_

X


-----

Therefore,


**_Î²[+]_** **_Î²[+][â€²]_**
2
_âˆ’_ _[â‰¤]_

[2]


exp(wi) _i[)]_

_Z(w)_ _âˆ’_ [exp(]Z(w[w][â€²])[â€²]


_Î»j_ _Î²j[+]â€²_ _Î²j+_
_j=1_ _|_ _âˆ’_ _[|]_

X


_i=1_


3

exp(wi) _i[)]_

**_Î²[+][â€²]_** **_Î²[+]_**

_â‰¤_ _i=1_ _Z(w)_ _âˆ’_ [exp(]Z(w[w][â€²])[â€²] _[âˆ¥][(][Î»][)][S][âˆ¥][2]_ _âˆ’_

X

(By Lipschitz continuity) _â‰¤_ _Câˆ¥w âˆ’_ **_w[â€²]âˆ¥2âˆ¥(Î»)Sâˆ¥2_** **_Î²[+][â€²]_** _âˆ’_ **_Î²[+]_** 2 _[,]_

for some constant C.


-----

G KEY LEMMAS

This section supplies some fundamental results for the modified proximal gradient algorithm. All
the results in this section are based on the following assumption and notations.
**Assumption G.1. Assume P satisfies Assumption C.1 and consider a problem (Zn, Î²[âˆ—]) âˆˆP. As-**
_sume we have a penalty function P_ (Î», Î²) whose concave component Q(Î», Î²) = P (Î», Î²) **_Î»_** **_Î²_** 1
_âˆ’âˆ¥_ _â—¦_ _âˆ¥_
_satisfies the regularization conditions in Assumption B.1 with a Lipschitz constant Î¾ for the condition_
_(a). We adopt the following notations for the statements in this sections._

_empirical loss_ _Ln(Î²) := Ln(Z1:n, Î²)_
_modified loss_ _LÎ»(Î²) := Ln(Z1:n, Î²) + Q(Î», Î²)_
_regularized loss_ _Ï†Î»(Î²) := Ln(Z1:n, Î²) + P_ (Î», Î²) = LÎ»(Î²) + **_Î²_** **_Î»,1_**
_âˆ¥_ _âˆ¥_

_local optimal_ **_Î²Î»_** arg min _Ï†Î»(Î²)_
_âˆˆ_ **_Î²âˆˆR[d]:âˆ¥Î²Sâˆ—_** _âˆ¥0â‰¤sËœ_
b

_quadratic approximation_ _ÏˆÎ±,Î»(z, Î²) := LÎ»(Î²) +_ _LÎ»(Î²), z_ **_Î²_** + [1] 2 [+][ âˆ¥][z][âˆ¥]Î»,1
_âŸ¨âˆ‡_ _âˆ’_ _âŸ©_ 2Î± _[âˆ¥][z][ âˆ’]_ **_[Î²][âˆ¥][2]_**

(Î² **_Î²â€²)âŠ¤_**

_sub-optimality_ _Ï‰Î»(Î²) :=_ min _âˆ’_ ( _LÎ»(Î²) + Î»_ **_Î¾[â€²])_** _._
**_Î¾[â€²]_** _âˆ‚_ **_Î²_** 1 [max]Î²[â€²] **_Î²_** **_Î²[â€²]_** **_Î»,1_** _âˆ‡_ _â—¦_
_âˆˆ_ _âˆ¥_ _âˆ¥_  _âˆ¥_ _âˆ’_ _âˆ¥_ 

**Lemma G.1 (Contraction of MPG). Assume Assumption G.1. Let Î²[0], Â· Â· Â·, Î²[k]** _be a sequence of_
_vectors obtained by the modified proximal gradient updates:_

**_Î²[k]_** = MPG(Î²[k][âˆ’][1]; Î», w, Î±)

:= TÎ±Â·Î» **_Î²[k][âˆ’][1]_** _âˆ’_ _Î±_ _âˆ‡Ln(Î²[k][âˆ’][1]) + âˆ‡Î²Q(Î», Î²[k][âˆ’][1])_ _._

_Assume_ (Î²[k])Sâˆ— 0 _sËœ. Then_     
_âˆ¥_ _âˆ¥_ _â‰¤_
1
 _Î±_ _[âˆ’]_ _[Ï]2[+]_ **_Î²[k]_** _âˆ’_ **_Î²[k][âˆ’][1]_** 2 _[â‰¤]_ _[Ï†][Î»][(][Î²][k][âˆ’][1][)][ âˆ’]_ _[Ï†][Î»][(][Î²][k][)][.]_ (46)



[2]

_Proof. Note that_

**_Î²[k]_** = Î²[k][âˆ’][1] _âˆ’_ _Î±Î´Î±(Î²[k][âˆ’][1]),_ where Î´Î±(Î²) := Î±[âˆ’][1] (Î² âˆ’TÎ±Î» (Î² âˆ’ _Î±âˆ‡LÎ»(Î²))) ._

It is easy to observe that Î´Î±(Î²) _LÎ»(Î²) + Î»_ _âˆ‚_ **_Î²_** _Î±Î´Î±(Î²)_ 1. By RSS in Lemma B.1, it
_âˆˆâˆ‡_ _â—¦_ _âˆ¥_ _âˆ’_ _âˆ¥_
holds that

_LÎ»_ **_Î²[k][]_** _â‰¤_ _LÎ»(Î²[k][âˆ’][1]) âˆ’_ _Î±âˆ‡LÎ»(Î²[k][âˆ’][1])[âŠ¤]Î´Î±(Î²[k][âˆ’][1]) +_ _[Ï]2[+]_ _[Î±][2]_ **_Î´Î±(Î²[k][âˆ’][1])_** 2 _[.]_

Furthermore, by RSC in Lemma  B.1, for any z in the space **_z_** **_Î²[k][âˆ’][1]_** 0 _s[2]_,
_{_ _âˆ’_ _[â‰¤]_ _[s][âˆ—]_ [+ 2Ëœ]}

_LÎ»_ **_Î²[k][]_** _LÎ»(z) +_ _LÎ»(Î²[k][âˆ’][1])[âŠ¤](Î²_ **_z)_** _Î±_ _LÎ»(Î²[k][âˆ’][1])[âŠ¤]Î´Î±(Î²[k][âˆ’][1])_ (47)
_â‰¤_ _âˆ‡_ _âˆ’_ _âˆ’_ _âˆ‡_
  + _[Ï]2[+]_ _[Î±][2]_ **_Î´Î±(Î²[k][âˆ’][1])_** 2 _[âˆ’]_ _[Ï][âˆ’]2[âˆ’]_ _[Î¾]_ **_Î²[k][âˆ’][1]_** _âˆ’_ **_z_** 2 _[.]_ (48)

Denote v = Î´Î±(Î²[k][âˆ’][1]) âˆ’âˆ‡LÎ»(Î²[k][âˆ’][1]). [2]We have v âˆˆ **_Î» â—¦_** _âˆ‚_ [2]Î²[k][âˆ’][1] _âˆ’_ _Î±Î´Î±(Î²[k][âˆ’][1])_ 1 [since]
**_Î´Î±(Î²[k][âˆ’][1]) âˆˆâˆ‡LÎ»(Î²[k][âˆ’][1]) + Î» â—¦_** _âˆ‚_ **_Î²[k][âˆ’][1]_** _âˆ’_ _Î±Î´Î±(Î²[k][âˆ’][1])_ 1[. By the convexity of][ âˆ¥Â·âˆ¥][Î»][,][1][,]
**_Î²[k][âˆ’][1]_** _Î±Î´Î±(Î²[k][âˆ’][1])_ **_Î»,1_** [+][ v][âŠ¤] [ ]Î²[k][âˆ’][1] _Î±Î´Î±(Î²[k][âˆ’][1])_ **_z_** _._
_âˆ’_ _[â‰¤âˆ¥][z][âˆ¥][Î»][,][1]_ _âˆ’_ _âˆ’_

Combining this inequality with Eq. 48, we have 

_LÎ»(Î²[k]) + âˆ¥Î²[k]âˆ¥Î»,1 â‰¤_ _LÎ»(z) + Î» âˆ¥zâˆ¥Î»,1 + Î´Î±(Î²[k][âˆ’][1])[âŠ¤](Î²[k][âˆ’][1]_ _âˆ’_ **_z)_** (49)

_âˆ’_ _Î±_ 1 âˆ’ _[Î±][(][Ï]2[+][)]_ **_Î´Î±(Î²[k][âˆ’][1])_** 2 2 **_Î²[k][âˆ’][1]_** _âˆ’_ **_z_** 2 _[.]_ (50)
  _[âˆ’]_ _[Ï][âˆ’]_ _[âˆ’]_ _[Î¾]_

Taking z = Î²[k][âˆ’][1] in Eq. 50 implies that [2] [2]


_LÎ»(Î²[k]) + âˆ¥Î²[k]âˆ¥Î»,1 â‰¤_ _LÎ»(Î²[k][âˆ’][1]) +_ **_Î²[k][âˆ’][1]_** **_Î»,1_** _[âˆ’]_ _Î±[1]_


**_Î²[k]_** **_Î²[k][âˆ’][1]_**
_âˆ’_ 2 _[.]_

[2]


1
_âˆ’_ _[Î±][(][Ï]2[+][)]_


-----

Therefore,
1

_Î±_ 2

 _[âˆ’]_ _[Ï][+]_


**_Î²[k]_** **_Î²[k][âˆ’][1]_**

2

_âˆ’_ _[â‰¤]_ _[Ï†][Î»][(][Î²][k][âˆ’][1][)][ âˆ’]_ _[Ï†][Î»][(][Î²][k][)][.]_

[2]


**Lemma G.2 (Convergence of modified proximal gradient). Assume Assumption G.1.** _Let_
**_Î²[0], Â· Â· Â·, Î²[k]_** _be a sequence of vectors obtained by the modified proximal gradient updates:_

**_Î²[k]_** = MPG(Î²[k][âˆ’][1]; Î», w, Î±)

:= TÎ±Â·Î» **_Î²[k][âˆ’][1]_** _âˆ’_ _Î±_ _âˆ‡Ln(Î²[k][âˆ’][1]) + âˆ‡Î²Q(Î», Î²[k][âˆ’][1])_

_with a step size Î± in (0,_ _Ï1+_ []][. Assume]  _[ âˆ¥][(][Î²][k][)]S [âˆ—]_ _[âˆ¥][0][ â‰¤]_ _s[Ëœ]. Then_ 

_Ï†Î»(Î²[k]) âˆ’_ _Ï†Î»(Î²Î») â‰¤_ (1 âˆ’ _Î±(Ïâˆ’_ _âˆ’_ _Î¾w))[k][ ]Ï†Î»(Î²[0]) âˆ’_ _Ï†Î»(Î²Î»)_ _,_


**_Î²[k]_** **_Î²Î»_** 2 **_Î²Î»_** 2[,]
_âˆ¥_ _âˆ’_ [b][b]âˆ¥[2] _[â‰¤]_ [(1][ âˆ’] _[Î±][(][Ï][âˆ’]1[âˆ’]_ _[Î¾][w][))][k][ âˆ¥][Î²][0][ âˆ’]_ [b] _âˆ¥[2]_ [b]

_âˆš2(1 +_ _Î±Ï+_ [)][âˆš][Ï][+]

_Ï‰Î»(Î²[k]) â‰¤_ min(Î») (1 âˆ’ _Î±(Ïâˆ’_ _âˆ’_ _Î¾w))[k][âˆ’][1][ ]Ï†Î»(Î²[0]) âˆ’_ _Ï†Î»(Î²Î»)_ _._

r



[b]

_Proof. Consider the quadratic approximation function_


_ÏˆÎ±,Î»(z, Î²) := LÎ»(Î²) +_ _LÎ»(Î²), z_ **_Î²_** + [1] 2 [+][ âˆ¥][z][âˆ¥]Î»,1 _[.]_ (51)
_âŸ¨âˆ‡_ _âˆ’_ _âŸ©_ 2Î± _[âˆ¥][z][ âˆ’]_ **_[Î²][âˆ¥][2]_**


By definition,


MPG(Î²[k][âˆ’][1]; Î», w, Î±) = arg min _ÏˆÎ±,Î»(z, Î²[k][âˆ’][1])._
**_z_**

Since ÏˆÎ±,Î»(z, Î²[k][âˆ’][1]) is _Î±[1]_ [-strongly convex with respect to][ z][, and that][ Î²][k][ is its optimal point, we]

can obtain

_ÏˆÎ±,Î»(z, Î²[k][âˆ’][1]) â‰¥_ _ÏˆÎ±,Î»(Î²[k], Î²[k][âˆ’][1]) + 2[1]Î±_ **_z âˆ’_** **_Î²[k]_** 2 _[,]_ _âˆ€z._ (52)

Note that by Lemma B.1,

[2]

_ÏˆÎ±,Î»(Î²[k], Î²[k][âˆ’][1]) = LÎ»(Î²[k][âˆ’][1]) + âˆ‡LÎ»(Î²[k][âˆ’][1])[âŠ¤]_ [ ]Î²[k] _âˆ’_ **_Î²[k][âˆ’][1][]_** + 2[1]Î± _[âˆ¥][Î²][k][ âˆ’]_ **_[Î²][k][âˆ’][1][âˆ¥]2[2]_**

+ **_Î²[k]_** **_Î»,1_**
_âˆ¥_ _âˆ¥_

1

_LÎ»(Î²[k]) +_ _Î±_ _[âˆ’]_ _[Ï][+]_ **_Î²[k]_** **_Î²[k][âˆ’][1]_** 2 [+][ âˆ¥][Î²][k][âˆ¥][Î»][,][1]
_â‰¥_ 2 _âˆ¥_ _âˆ’_ _âˆ¥[2]_

1

= Ï†Î»(Î²[k]) + _Î±_ _[âˆ’]_ _[Ï][+]_ **_Î²[k]_** **_Î²[k][âˆ’][1]_** 2[.]

2 _âˆ¥_ _âˆ’_ _âˆ¥[2]_

Similarly, by Lemma B.1,


_ÏˆÎ±,Î»(z, Î²[k][âˆ’][1]) = LÎ»(Î²[k][âˆ’][1]) + âˆ‡LÎ»(Î²[k][âˆ’][1])[âŠ¤]_ [ ]z âˆ’ **_Î²[k][âˆ’][1][]_** + 2[1]Î± _[âˆ¥][z][ âˆ’]_ **_[Î²][k][âˆ’][1][âˆ¥]2[2]_**

+ **_z_** **_Î»,1_**
_âˆ¥_ _âˆ¥_

1

_Ï†Î»(z) +_ _Î±_ _[âˆ’]_ [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][)]_ **_z_** **_Î²[k][âˆ’][1]_** 2[.]
_â‰¤_ 2 _âˆ¥_ _âˆ’_ _âˆ¥[2]_

Combining the above two results with Eq. 52, we have


1

_Ï†Î»(Î²[k])_ _Ï†Î»(z) +_ _Î±_ _[âˆ’]_ [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][)]_
_â‰¤_ 2

**_z_** **_Î²[k]_**

_âˆ’_ 2[1]Î± _âˆ’_ 2

1

_Ï†Î»(z) +_ _Î±_ _[âˆ’]_ [(][Ï][2][âˆ’] _[âˆ’]_ _[Î¾][)]_
_â‰¤_ 2


1

_Î±_

_[âˆ’]_ _[Ï][+]_

2

1

_Î±_

_[âˆ’]_ _[Ï][+]_

2


**_Î²[k]_** **_Î²[k][âˆ’][1]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_

_âˆ¥Î²[k]_ _âˆ’_ **_Î²[k][âˆ’][1]âˆ¥2[2][.]_**


**_z_** **_Î²[k][âˆ’][1]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[âˆ’]_

**_z_** **_Î²[k][âˆ’][1]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[âˆ’]_


(53)


-----

Taking z = cÎ²Î» + (1 âˆ’ _c)Î²[k][âˆ’][1]_ for some c âˆˆ [0, 1], then

_Ï†Î»(Î²[k])_

[b]

1

_cÏ†Î»(Î²Î») + (1_ _c)Ï†Î»(Î²[k][âˆ’][1]) +_ _Î±_ _[âˆ’]_ [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][)]_ _c[2]_ **_Î²[k][âˆ’][1]_** **_Î²Î»_** 2
_â‰¤_ _âˆ’_   2  _âˆ¥_ _âˆ’_ [b] _âˆ¥[2]_ _[âˆ’]_

_cÏ†Î»(Î²[b]Î») + (1_ _c)Ï†Î»(Î²[k][âˆ’][1]) +_ _[c]_ _c_ _Î±[1]_ _[âˆ’]_ [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][)]_ **_Î²[k][âˆ’][1]_** **_Î²Î»_** 2
_â‰¤_ _âˆ’_   2  _âˆ¥_ _âˆ’_ [b] _âˆ¥[2]_ _[âˆ’]_

Taking c = Î± (Ï _Î¾), it implies_

[b] _âˆ’_ _âˆ’_


1

_Î±_

_[âˆ’]_ _[Ï][+]_

2

1

_Î±_

_[âˆ’]_ _[Ï][+]_

2


**_Î²[k]_** **_Î²[k][âˆ’][1]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_

**_Î²[k]_** **_Î²[k][âˆ’][1]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_


1

_Î±_

_[âˆ’]_ _[Ï][+]_

2


_âˆ¥Î²[k]_ _âˆ’_ **_Î²[k][âˆ’][1]âˆ¥2[2][.]_**


_Ï†Î»(Î²[k]) âˆ’_ _Ï†Î»(Î²Î») â‰¤_ (1 âˆ’ _Î± (Ïâˆ’_ _âˆ’_ _Î¾))_ _Ï†Î»(Î²[k][âˆ’][1]) âˆ’_ _Ï†Î»(Î²Î»)_


Assume Î± â‰¤ _Ï1+_ [. Then][b] [b]


_Ï†Î»(Î²[k]) âˆ’_ _Ï†Î»(Î²Î») â‰¤_ (1 âˆ’ _Î± (Ïâˆ’_ _âˆ’_ _Î¾))_ _Ï†Î»(Î²[k][âˆ’][1]) âˆ’_ _Ï†Î»(Î²Î»)_ _._
 

Taking z = **_Î²Î» in Eq. 53 implies[b]_** [b]

1

[b]Ï†Î»(Î²[k]) _Ï†Î»(Î²Î») +_ _Î±_ _[âˆ’]_ [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][)]_ **_Î²Î»_** **_Î²[k][âˆ’][1]_** 2 **_Î²Î»_** **_Î²[k]_** 2[.]

_â‰¤_ 2 _âˆ¥_ [b] _âˆ’_ _âˆ¥[2]_ _[âˆ’]_ 2[1]Î± _[âˆ¥]_ [b] _âˆ’_ _âˆ¥[2]_

By the optimality of **_Î²Î», we have[b]_**

1

[b] _Î±_ _[âˆ’]_ [(][Ï][âˆ’] _[âˆ’]_ _[Î¾][)]_ **_Î²Î»_** **_Î²[k][âˆ’][1]_** 2 **_Î²Î»_** **_Î²[k]_** 2

2 _âˆ¥_ [b] _âˆ’_ _âˆ¥[2]_ _[âˆ’]_ 2[1]Î± _[âˆ¥]_ [b] _âˆ’_ _âˆ¥[2]_ _[â‰¥]_ [0][,]

which implies

**_Î²Î»_** **_Î²[k]_** 2 **_Î²Î»_** **_Î²[k][âˆ’][1]_** 2[.]
_âˆ¥_ [b] _âˆ’_ _âˆ¥[2]_ _[â‰¤]_ [(1][ âˆ’] _[Î±][ (][Ï][âˆ’]_ _[âˆ’]_ _[Î¾][))][ âˆ¥]_ [b] _âˆ’_ _âˆ¥[2]_

Finally, we derive the upper bound for Ï‰Î»(Î²[k]). Since Î²[k] = arg minz ÏˆÎ±,Î»(z, Î²[k][âˆ’][1]), by the
optimality condition, for each j = 1, _, d, there exists a subgradient Î¾j_ _âˆ‚_ _Î²j[k]_ such that
_Â· Â· Â·_ _âˆˆ_

_LÎ»(Î²[k][âˆ’][1]) + [1]_
_âˆ‡_ _Î±_ [(][Î²][k][ âˆ’] **_[Î²][k][âˆ’][1][) +][ Î»][ â—¦]_** **_[Î¾][ = 0][.]_**


By the definition of Ï‰Î» and combining it with the above equality,

_k_
(Î² **_Î²â€²)âŠ¤_**

_Ï‰Î»(Î²[k]) =_ min max _âˆ’_ ( _LÎ»(Î²[k]) + Î»_ **_Î¾[â€²])_**
**_Î¾[â€²]âˆˆâˆ‚âˆ¥Î²[k]âˆ¥1_** **_Î²[â€²]âˆˆâ„¦_**  _âˆ¥Î²[k]_ _âˆ’_ **_Î²[â€²]âˆ¥Î»,1_** _âˆ‡_ _â—¦_ 

_k_
(Î² **_Î²â€²)âŠ¤_**

max _âˆ’_ ( _LÎ»(Î²[k]) + Î»_ **_Î¾)_**
_â‰¤_ **_Î²[â€²]âˆˆâ„¦_**  _âˆ¥Î²[k]_ _âˆ’_ **_Î²[â€²]âˆ¥Î»,1_** _âˆ‡_ _â—¦_ 

_k_
(Î² **_Î²â€²)âŠ¤_**

= max _âˆ’_ _LÎ»(Î²[k])_ _LÎ»(Î²[k][âˆ’][1]) + [1]_
**_Î²[â€²]âˆˆâ„¦_**  _âˆ¥Î²[k]_ _âˆ’_ **_Î²[â€²]âˆ¥Î»,1_** âˆ‡ _âˆ’âˆ‡_ _Î±_ [(][Î²][k][âˆ’][1][ âˆ’] **_[Î²][k][)]_**

_d_ (Î²j[k] _j[)][Î»][j]_ _LÎ»(Î²[k])_ _LÎ»(Î²[k][âˆ’][1]) +_ _Î±[1]_ [(][Î²][k][âˆ’][1][ âˆ’] **_[Î²][k][)]_**

= max _[âˆ’]_ _[Î²][â€²]_ _âˆ‡_ _âˆ’âˆ‡_
**_Î²[â€²]âˆˆâ„¦_** ï£±ï£²Xj=1 _âˆ¥Î²[k]_ _âˆ’_ **_Î²[â€²]âˆ¥Î»,1_**   _Î»j_

1

ï£³

_â‰¤_ min(Î») _[âˆ¥âˆ‡][L][Î»][(][Î²][k][)][ âˆ’âˆ‡][L][Î»][(][Î²][k][âˆ’][1][) + 1]Î±_ [(][Î²][k][âˆ’][1][ âˆ’] **_[Î²][k][)][âˆ¥][âˆ]_**


1

min(Î») _[âˆ¥âˆ‡][L][Î»][(][Î²][k][)][ âˆ’âˆ‡][L][Î»][(][Î²][k][âˆ’][1][) + 1]Î±_ [(][Î²][k][âˆ’][1][ âˆ’] **_[Î²][k][)][âˆ¥][2]_**

1

min(Î») _[âˆ¥âˆ‡][L][Î»][(][Î²][k][)][ âˆ’âˆ‡][L][Î»][(][Î²][k][âˆ’][1][)][âˆ¥][2][ + 1]Î±_ _[âˆ¥][(][Î²][k][âˆ’][1][ âˆ’]_ **_[Î²][k][)][âˆ¥][2]_**


1

min(Î») [(][Ï][+][ + 1]Î± [)][âˆ¥][(][Î²][k][âˆ’][1][ âˆ’] **_[Î²][k][)][âˆ¥][2][.]_**


(by RSS) â‰¤


-----

By Lemma G.1, (Î²[k][âˆ’][1] **_Î²[k])_** 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_


2

2 _Î±[1]_

_[âˆ’][(][Ï][+][)][ (][Ï†][Î»][(][Î²][k][âˆ’][1][)][ âˆ’]_ _[Ï†][Î»][(][Î²][k][))][. Therefore,]_

2

s 2 _Î±[1]_

_[âˆ’]_ [(][Ï][+][) (][Ï†][Î»][(][Î²][k][âˆ’][1][)][ âˆ’] _[Ï†][Î»][(][Î²][k][))]_


1

min(Î») [(][Ï][+][ + 1]Î± [)]

1

min(Î») [(][Ï][+][ + 1]Î± [)]

1

min(Î») [(][Ï][+][ + 1]Î± [)]

1

min(Î») [(][Ï][+][ + 1]Î± [)]


_Ï‰Î»(Î²[k])_
_â‰¤_


(Ï†Î»(Î²[k][âˆ’][1]) _Ï†Î»(Î²[k]))_
_Ï+_ _âˆ’_

2

_Ï†Î»(Î²[k][âˆ’][1])_ _Ï†Î»(Î²Î»)_

_Ï+_ _âˆ’_

 

2 [b]

_Ï+_ (1 âˆ’ _Î± (Ïâˆ’_ _âˆ’_ _Î¾))[k][âˆ’][1][ ]Ï†Î»(Î²[0]) âˆ’_ _Ï†Î»(Î²Î»)_

[b]


**Lemma G.3 (Statistical â„“2 error). Assume Assumption G.1. If the following conditions are satisfied**

**_Î²_** **_Î²[âˆ—]_** 0 _s[âˆ—]_ + 2Ëœs, (54)
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_

21/2
_Ï†Î»(Î²)_ _Ï†Î»(Î²[âˆ—])_ 2[,] (55)
_âˆ’_ _â‰¤_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_

_Î»j_ 8 [ _Ln(Î²[âˆ—])]j_ _,_ (56)
_â‰¥_ _âˆ‡_

_then âˆ¥Î² âˆ’_ **_Î²[âˆ—]âˆ¥2 â‰¤_** minaâ‰¥0 max 21 + [17]4 _[a,][ 21]a_ [+][ 17]4 _âˆ¥ÏÎ»âˆ’Sâˆ’âˆ—_ _âˆ¥Î¾2_ _[â‰¤]_ [15][/]Ï[2]âˆ’[âˆ¥][Î»]âˆ’[S]Î¾[âˆ—] _[âˆ¥][2]_ _._
nq o

_Proof. By the restricted strong convexity of LÎ» in Lemma B.1,_


_Ï_ _Î¾_
_âˆ’2âˆ’_ _âˆ¥Î² âˆ’_ **_Î²[âˆ—]âˆ¥2[2]_**

_LÎ»(Î²)_ _LÎ»(Î²[âˆ—])_ _LÎ»(Î²[âˆ—])[âŠ¤](Î²_ **_Î²[âˆ—])_**
_â‰¤_ _âˆ’_ _âˆ’âˆ‡_ _âˆ’_

= Ï†Î»(Î²) _Ï†Î»(Î²[âˆ—]) + (_ **_Î²[âˆ—]_** **_Î»,1_** **_Î²_** **_Î»,1)_** _LÎ»(Î²[âˆ—])[âŠ¤](Î²_ **_Î²[âˆ—])_**
_âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’âˆ¥_ _âˆ¥_ _âˆ’âˆ‡_ _âˆ’_

21/2

2 [+ (][âˆ¥][Î²][âˆ—][âˆ¥][Î»][,][1] _LÎ»(Î²[âˆ—])[âŠ¤](Î²_ **_Î²[âˆ—])_** _._

_â‰¤_ _Ï_ _Î¾_ _[âˆ’âˆ¥][Î²][âˆ¥][Î»][,][1][)]_ _âˆ’âˆ‡_ _âˆ’_

_âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_ (i) (ii)

For the term (i), | {z } | {z }


(57)


**_Î²[âˆ—]_** **_Î»,1_** **_Î²_** **_Î»,1 =_** **_Î²S[âˆ—]_** _[âˆ—]_ _[âˆ¥][Î»]S[âˆ—]_ _[,][1]_ _S[âˆ—]_ _[,][1]_ [+ (][âˆ¥][Î²]S[âˆ—] _[âˆ—]_ _[âˆ¥][Î»]S[âˆ—]_ _[,][1][ âˆ’âˆ¥][Î²][S][âˆ—]_ _[âˆ¥][Î»]S[âˆ—]_ _[,][1][)]_
_âˆ¥_ _âˆ¥_ _âˆ’âˆ¥_ _âˆ¥_ _âˆ¥_ _[âˆ’âˆ¥][Î²][S][âˆ—]_ _[âˆ¥][Î»]_

= âˆ¥Î²S[âˆ—] _[âˆ—]_ _[âˆ¥][Î»]S[âˆ—]_ _[,][1]_ _[âˆ’âˆ¥][Î²][S][âˆ—]_ _[âˆ¥][Î»]S[âˆ—]_ _[,][1]_ _[âˆ’âˆ¥][Î²]S[âˆ—]_ _[âˆ¥][Î»]Sâˆ—_ _[,][1]_
_â‰¤âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 âˆ’âˆ¥Î²Sâˆ—_ _âˆ¥Î»Sâˆ—_ _,1_
= âˆ¥(Î² âˆ’ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 âˆ’âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1._

For the term (ii),

_LÎ»(Î²[âˆ—])[âŠ¤](Î²_ **_Î²[âˆ—]) =_** _Ln(Î²[âˆ—])[âŠ¤](Î²_ **_Î²[âˆ—])_** _QÎ»(Î²[âˆ—])[âŠ¤](Î²_ **_Î²[âˆ—])_**
_âˆ’âˆ‡_ _âˆ’_ _âˆ’âˆ‡_ _âˆ’_ _âˆ’âˆ‡_ _âˆ’_

(By Eq. 56)
_â‰¤_ [1]8 _[âˆ¥][Î²][ âˆ’]_ **_[Î²][âˆ—][âˆ¥][Î»][,][1][ âˆ’âˆ‡][Q][Î»][(][Î²][âˆ—][)][âŠ¤][(][Î²][ âˆ’]_** **_[Î²][âˆ—][)]_**

(since qÎ»[â€²] _j_ [(0) = 0][)][ = 1] _S[âˆ—]_ [)][âŠ¤][(][Î²][ âˆ’] **_[Î²][âˆ—][)][S][âˆ—]_**

8 _[âˆ¥][Î²][ âˆ’]_ **_[Î²][âˆ—][âˆ¥][Î»][,][1][ âˆ’âˆ‡][Q][Î»][(][Î²][âˆ—]_**

(since _qÎ»[â€²]_ _j_ [(][Î²][)] _Î»j)_
_â‰¤_ _â‰¤_ 8[1] _[âˆ¥][Î²][ âˆ’]_ **_[Î²][âˆ—][âˆ¥][Î»][,][1][ +][ âˆ¥][(][Î²][ âˆ’]_** **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1]_

= [9]8 _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1][ + 1]8_ _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][S]âˆ—_** _âˆ¥Î»Sâˆ—_ _,1._


-----

Combining the upper bounds of term (i) and term (ii) with Eq. 57, we have

**_Î²_** **_Î²[âˆ—]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥[2]_

21 17 7
_â‰¤_ (Ï _Î¾)[2][ âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2]_ [+] 4(Ï _Î¾)_ _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1][ âˆ’]_ 4(Ï _Î¾)_ _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][S]âˆ—_** _âˆ¥Î»Sâˆ—_ _,1,_ (58)

_âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_

1 21

2 [+ 17] _._

_â‰¤_ _Ï_ _Î¾_ _Ï_ _Î¾_ 4

_âˆ’_ _âˆ’_  _âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_ _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1]_

Let a 0 be a constant. If (Î² **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1_ _Ï_ _a_ _Î¾_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2][, then]_
_â‰¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ’âˆ’_


21 + [17]

4 _[a]_ _[âˆ¥]Ï[Î»][S][âˆ—]_ _[âˆ¥]Î¾ [2]_ _[.]_

_âˆ’_ _âˆ’_


**_Î²_** **_Î²[âˆ—]_** 2
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_


If (Î² **_Î²[âˆ—])S[âˆ—]_** **_Î»Sâˆ—_** _,1 >_ _Ï_ _a_ _Î¾_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2][, then]_
_âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ’âˆ’_

1 21 21 **_Î»Sâˆ—_** 2
_âˆ¥Î² âˆ’_ **_Î²[âˆ—]âˆ¥2[2]_** _[â‰¤]_ _Ïâˆ’_ _âˆ’_ _Î¾_  _a_ [+ 17]4  _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_  _a_ [+ 17]4  âˆ¥Ïâˆ’ _âˆ’âˆ¥Î¾_ _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][âˆ¥][2][,]_**

which implies âˆ¥Î² âˆ’ **_Î²[âˆ—]âˆ¥2 â‰¤_** 21a [+][ 17]4 _âˆ¥ÏÎ»âˆ’Sâˆ’âˆ—_ _âˆ¥Î¾2_ [. Combining the two cases, we know that]
  

**_Î»Sâˆ—_** 2

**_Î²_** **_Î²[âˆ—]_** 2 min 21 + [17] _âˆ¥_ _âˆ¥_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _aâ‰¥0_ [max] (r 4 _[a,][ 21]a_ [+ 17]4 ) _Ïâˆ’_ _âˆ’_ _Î¾ [.]_


Taking a = 7 it is easy to derive that

**_Î²_** **_Î²[âˆ—]_** 2 _._
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ [15][/]Ï[2][âˆ¥][Î»][S]Î¾[âˆ—] _[âˆ¥][2]_

_âˆ’_ _âˆ’_

**Lemma G.4 (Retain in the restricted space). Assume Assumption G.1. Let Î²[0], Â· Â· Â·, Î²[k]** _be a se-_
_quence of vectors obtained by the following update:_

**_Î²[k]_** = MPG(Î²[k][âˆ’][1]; Î», w, Î±)


_with a step sizes Î± in [Î±min,_


1

_Ï+_ []][. Assume the following conditions:]


(Î²[0])Sâˆ— 0 _s,Ëœ_
_âˆ¥_ _âˆ¥_ _â‰¤_

21/2
_Ï†Î»(Î²[0])_ _Ï†Î»(Î²[âˆ—])_ 2[,]
_âˆ’_ _â‰¤_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_

_Î»j_ 8 [ _Ln(Î²[âˆ—])]j_
_â‰¥_ _âˆ‡_

2[! ] 2

121 _Ï+_ **_Î»Sâˆ—_** 2

_âˆ¥_ _âˆ¥_ _s,Ëœ_

_Î±min(Ïâˆ’_ _âˆ’_ _Î¾) [+ 144]_  _Ïâˆ’_ _âˆ’_ _Î¾_   min(Î»Sâˆ— )  _â‰¤_

_where Îº :=_ _Ï_ _Ï+_ _Î¾_ _[. Then for all][ k][ = 1][,][ Â· Â· Â·][, K][,]_

_âˆ’âˆ’_


(Î²[k])Sâˆ— 0 _s,Ëœ_
_âˆ¥_ _âˆ¥_ _â‰¤_


_and_


21/2
_Ï†Î»(Î²[k])_ _Ï†Î»(Î²[âˆ—])_ 2[.]
_âˆ’_ _â‰¤_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_

_Proof. Recall that Î²[k]_ = _Î±Î»_ Â¯Î²[k][] where
_T_

**_Î²Â¯[k]_** = Î²[k][âˆ’] [1] _Î±_ _LÎ»(Î²[k][âˆ’][1])_
_âˆ’_ _âˆ‡_

= Î²[k][âˆ’][1] _Î±_ _LÎ»(Î²[âˆ—]) + Î±_ _LÎ»(Î²[âˆ—])_ _LÎ»(Î²[k][âˆ’][1])_
_âˆ’_ _âˆ‡_ _âˆ‡_ _âˆ’âˆ‡_
 


-----

To show (Î²[k])Sâˆ— 0 _s, we need to prove that, for j_ _S[âˆ—], the number of jâ€™s such that_ **_Î²[Â¯]j[k]_**
is no more than Ëœs. Note that[â‰¤] [Ëœ] _âˆˆ_ _|_ _[|][ > Î±Î»][j]_

**_Î²[Â¯]j[k]_** _j_ + Î± _LÎ»(Î²[âˆ—])_ _LÎ»(Î²[k][âˆ’][1])_ _j_ + Î± [ _Ln(Î²[âˆ—])]j_
_|_ _[| â‰¤|][Î²][k][âˆ’][1]|_ _âˆ‡_ _âˆ’âˆ‡_ _âˆ‡_
  

_â‰¤|Î²j[k][âˆ’][1]| + Î±_ _âˆ‡LÎ»(Î²[âˆ—]) âˆ’âˆ‡LÎ»(Î²[k][âˆ’][1])_ _j_ + [1]8 _[Â·][ Î±Î»][j][.]_
  

Therefore, âˆ€c âˆˆ [0, 1],

(Î²[k])Sâˆ— 0 _[â‰¤]_ [Card] {j âˆˆ _S[âˆ—]_ : |Î²j[k][âˆ’][1]| > c [7]8 _[Î±Î»][j][}]_ (59)

+ Card _{j âˆˆ_ _S[âˆ—]_ : _âˆ‡LÎ»(Î²[âˆ—]) âˆ’âˆ‡LÎ»(Î²[k][âˆ’][1])_ _j_ _> (1 âˆ’_ _c) Â·_ [7]8 _[Î»][j][}]_ _,_ (60)
 
  

where Card () represents the size of the set. For the term in Eq. 59,


**_Î²j[k][âˆ’][1]_**
_|_

_c_ [7]8 _[Î±Î»][j]_


**_Î²j[k][âˆ’][1]_**
_|_

_Î»j_


Card _{j âˆˆ_ _S[âˆ—]_ : |Î²j[k][âˆ’][1]| > c 8[7] _[Î±Î»][j][}]_



_c Â· 7Î±_


_jâˆˆS[âˆ—]_


_jâˆˆS[âˆ—]_


8
_â‰¤_ _c_ 7Î± min(Î»Sâˆ— )[2][ âˆ¥][(][Î²][k][âˆ’][1][)][S][âˆ—] _[âˆ¥][Î»][S][âˆ—]_ _[,][1]_

_Â·_

8
=

_c_ 7Î± min(Î»Sâˆ— )[2][ âˆ¥][(][Î²][k][âˆ’][1][ âˆ’] **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1]_
_Â·_

**Bounding** (Î²[k][âˆ’][1] **_Î²[âˆ—])Sâˆ—_** 1. Following the derivation of Eq. 58, we can obtain
_âˆ¥_ _âˆ’_ _âˆ¥_

(Ïâˆ’ _âˆ’_ _Î¾)âˆ¥Î²[k][âˆ’][1]_ _âˆ’_ **_Î²[âˆ—]âˆ¥2[2]_**

21
_â‰¤_ (Ï _Î¾)_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2]_ [+ 17]4 4 _[âˆ¥][(][Î²][k][âˆ’][1][ âˆ’]_ **_[Î²][âˆ—][)][S]âˆ—_** _âˆ¥Î»Sâˆ—_ _,1,_

_âˆ’_ _âˆ’_ _[âˆ¥][(][Î²][k][âˆ’][1][ âˆ’]_ **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1][ âˆ’]_ [7]


which implies

12
_âˆ¥(Î²[k][âˆ’][1]_ _âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_ _Ï_ _Î¾_ 2 [+ 17]7

_âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_ _[âˆ¥][(][Î²][k][âˆ’][1][ âˆ’]_ **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1][.]_

Let a 0 be a constant. If (Î²[k][âˆ’][1] **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1_ _Ï_ _a_ _Î¾_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2][, then]_
_â‰¥_ _âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ’âˆ’_

_âˆ¥(Î²[k][âˆ’][1]_ _âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_ 12 + [17]7[a] _âˆ¥ÏÎ»Sâˆ—_ _âˆ¥Î¾ 22_ _[.]_
  _âˆ’_ _âˆ’_

If (Î²[k][âˆ’][1] **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1 >_ _Ï_ _a_ _Î¾_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2][, then]_
_âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ’âˆ’_

12
_âˆ¥(Î²[k][âˆ’][1]_ _âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_ _a_ [+ 17]7 _âˆ¥(Î²[k][âˆ’][1]_ _âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1_
 

12

**_Î»Sâˆ—_** 2 (Î²[k][âˆ’][1] **_Î²[âˆ—])_** 2

_â‰¤_ _a_ [+ 17]7 _âˆ¥_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_
 

(Lemma G.3) 12 _âˆ¥Î»Sâˆ—_ _âˆ¥22_
_â‰¤_ [15]2 _a_ [+ 17]7 _Ï_ _Î¾ [.]_

  _âˆ’_ _âˆ’_

Combining the above two cases yields


12

_a_ [+ 17]7




**_Î»Sâˆ—_** 22
_âˆ¥_ _âˆ¥_

_Ï_ _Î¾_

 _âˆ’_ _âˆ’_


_âˆ¥(Î²[k][âˆ’][1]_ _âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_ minaâ‰¥0 [max] 12 + [17]7[a] _[,][ 15]2_

423 **_Î»Sâˆ—_** 22

_âˆ¥_ _âˆ¥_

_â‰¤_ 14 _Ï_ _Î¾ [,]_
  _âˆ’_ _âˆ’_


-----

where the last inequality is obtained by taking a = 25534 [. Therefore, the term in Eq.][ 59][ can be]

bounded by

Card {j âˆˆ _S[âˆ—]_ : |Î²j[k][âˆ’][1]| > c [7]8 _[Î±Î»][j][}]_ _â‰¤_ 8âˆ¥(Î²c Â·[k] 7[âˆ’]Î±[1] min(âˆ’ **_Î²[âˆ—])Î»SSâˆ—âˆ—âˆ¥)Î»[2]Sâˆ—_** _,1_

1692 **_Î»Sâˆ—_** 22

_âˆ¥_ _âˆ¥_

_â‰¤_  49cÎ± min(Î»Sâˆ— )[2]  _Ïâˆ’_ _âˆ’_ _Î¾_

2

1692 **_Î»Sâˆ—_** 2)

_âˆ¥_ _âˆ¥_ _._

_â‰¤_ 49cÎ±(Ïâˆ’ _âˆ’_ _Î¾)_  min(Î»Sâˆ— ) 

Now we bound the term in Eq. 60 as follows. Denote the set as S[â€²] := _{j_ _âˆˆ_ _S[âˆ—]_ :
_LÎ»(Î²[âˆ—])_ _LÎ»(Î²[k][âˆ’][1])_ _j_ _> (1_ _c)_ 8[7] _[Î»][j][}][ and its size as][ s][â€²][ :=][ |][S][â€²][|][. Then]_
_âˆ‡_ _âˆ’âˆ‡_ _âˆ’_ _Â·_
  

_s[â€²]_ = Card _j âˆˆ_ _S[âˆ—]_ : _âˆ‡LÎ»(Î²[âˆ—]) âˆ’âˆ‡LÎ»(Î²[k][âˆ’][1])_ _j_ _> (1 âˆ’_ _c) Â·_ [7]8 _[Î»][j]_
 
  

1 _LÎ»(Î²[âˆ—])_ _LÎ»(Î²[k][âˆ’][1])_ _j_

_âˆ‡_ _âˆ’âˆ‡_

_â‰¤_ (1 _c)_ [7]8 _j_ _S[â€²]_   _Î»j_ 

_âˆ’_ _Â·_ Xâˆˆ

1 _LÎ»(Î²[âˆ—])_ _LÎ»(Î²[k][âˆ’][1])_ _j_

_âˆ‡_ _âˆ’âˆ‡_

_â‰¤_ (1 _c)_ [7]8 _j_ _S[â€²]_   min(Î»Sâˆ— ) 

_âˆ’_ _Â·_ Xâˆˆ

1 _âˆšs[â€²]_
_â‰¤_ (1 _c)_ [7]8 min(Î»Sâˆ— ) _âˆ‡LÎ»(Î²[âˆ—]) âˆ’âˆ‡LÎ»(Î²[k][âˆ’][1])_ 2

_âˆ’_ _Â·_

1 _âˆšs[â€²]_
_â‰¤_ (1 _c)_ [7]8 min(Î»Sâˆ— ) [(][Ï][+][)][âˆ¥][Î²][âˆ—] _[âˆ’]_ **_[Î²][k][âˆ’][1][âˆ¥][2][.]_**

_âˆ’_ _Â·_

The last inequality holds because LÎ» is (Ï+)-smooth in the restricted subspace by Lemma B.1.
Applying Lemma G.3, we have

64(Ï+)[2]
_s[â€²]_ _â‰¤_ 49(1 _c)[2]_ min(Î»Sâˆ— )[2][ âˆ¥][Î²][âˆ—] _[âˆ’]_ **_[Î²][k][âˆ’][1][âˆ¥]2[2]_**

_âˆ’_

2 2 2

64(Ï+)[2] 15/2 **_Î»Sâˆ—_** 2 3600 _Ï+_ **_Î»Sâˆ—_** 2

_âˆ¥_ _âˆ¥_ _âˆ¥_ _âˆ¥_ _._

_â‰¤_ 49(1 âˆ’ _c)[2]_ min(Î»Sâˆ— )[2]  _Ïâˆ’_ _âˆ’_ _Î¾_  _â‰¤_ 49(1 âˆ’ _c)[2]_  _Ïâˆ’_ _âˆ’_ _Î¾_   min(Î»Sâˆ— ) 

Combining the above bounds for the terms in Eq. 59 and Eq. 60, we have

2[! ] 2

1692 1 3600 _Ï+_ **_Î»Sâˆ—_** 2

(Î²[k])Sâˆ— 0 _[â‰¤]_ _câˆˆ[min](0,1)_  49cÎ±  _Ïâˆ’_ _âˆ’_ _Î¾_ [+] 49(1 âˆ’ _c)[2]_  _Ïâˆ’_ _âˆ’_ _Î¾_   âˆ¥min(Î»âˆ¥Sâˆ— ) 

2[! ] 2

121 _Ï+_ **_Î»Sâˆ—_** 2

_âˆ¥_ _âˆ¥_

_â‰¤_ _Î±min(Ïâˆ’_ _âˆ’_ _Î¾) [+ 144]_  _Ïâˆ’_ _âˆ’_ _Î¾_   min(Î»Sâˆ— ) 

_â‰¤_ _sËœ_

The second last inequality is obtained by taking c = 7[5] [.]


Finally, if we can show Ï†Î»(Î²[k]) _Ï†Î»(Î²[âˆ—])_ _Ï21/2Î¾_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥]2[2][, then we can show by math induction]_
_âˆ’_ _â‰¤_ _âˆ’âˆ’_

that (Î²[k])Sâˆ— 0 _s for all k._

_[â‰¤]_ [Ëœ]

Taking z = Î²[k][âˆ’][1] in Eq. 53, we have

_Ï†Î»(Î²[k]) â‰¤_ _Ï†Î»(Î²[k][âˆ’][1]) âˆ’_ [2][ 1]s _[âˆ’]2_ _[Ï][+]_ **_Î²[k]_** _âˆ’_ **_Î²[k][âˆ’][1]_** 2 _[â‰¤]_ _[Ï†][Î»][(][Î²][k][âˆ’][1][)][.]_

Therefore,

[2]

21/2
_Ï†Î»(Î²[k])_ _Ï†Î»(Î²[âˆ—])_ _Ï†Î»(Î²[k][âˆ’][1])_ _Ï†Î»(Î²[âˆ—])_ 2[.]
_âˆ’_ _â‰¤_ _âˆ’_ _â‰¤_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_


-----

**Lemma G.5 (Statistical error). Assume Assumption G.1. If**

_Ï‰Î»(Î²)_ _Ïµ,_ _with Ïµ_ 1/2,
_â‰¤_ _â‰¤_
**_Î²_** **_Î²[âˆ—]_** 0 _s[âˆ—]_ + 2Ëœs,
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_
_Î»j_ 8 [Ln(Î²[âˆ—])]j _,_
_â‰¥_ _|_ _|_

_then the following relations hold true._


_Ïµ +_ [17]8 **_Î»Sâˆ—_** 2 21/8

**_Î²_** **_Î²[âˆ—]_** 2 _âˆ¥_ _âˆ¥_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_   _Ïâˆ’âˆ’_ _Î¾_ _â‰¤_ _Ïâˆ’_ _âˆ’_ _Î¾_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2][,]_

_Ï†Î»(Î²)_ _Ï†Î»(Î²[âˆ—])_ _âˆ¥Î»Sâˆ—_ _âˆ¥2[2]_ 21/2 2[.]
_âˆ’_ _â‰¤_ [3][Ïµ][(]7[Ïµ]/[ + 17]8 _Ïµ[/][8)]_ _Ï_ _Î¾_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_ _âˆ’_ _[â‰¤]_ _âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_

_Ï†Î»(Î²)_ _Ï†Î»(Î²Î»)_ _Ïµ_ 3 (Ïµ + 17/8) + 51/7 _âˆ¥Î»Sâˆ—_ _âˆ¥22_ 29/2 2[.]
_âˆ’_ _â‰¤_ 7/8 _Ïµ_ _Ï_ _Î¾_ _Ï_ _Î¾_

[b]  _âˆ’_  _âˆ’_ _âˆ’_ _[â‰¤]_ _âˆ’_ _âˆ’_ _[âˆ¥][Î»][S][âˆ—]_ _[âˆ¥][2]_

_Proof. Since_ **_Î²_** **_Î²[âˆ—]_** 0 _s[âˆ—]_ + 2Ëœs, then by the RSC and RSS in Lemma B.1,
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_

(Ïâˆ’ _âˆ’_ _Î¾)âˆ¥Î²[âˆ—]_ _âˆ’_ **_Î²âˆ¥2[2]_** _[â‰¤]_ [(][Î²][ âˆ’] **_[Î²][âˆ—][)][âŠ¤][âˆ‡][L][Î»][(][Î²][)][ âˆ’]_** [(][Î²][ âˆ’] **_[Î²][âˆ—][)][âŠ¤][âˆ‡][L][Î»][(][Î²][âˆ—][)][.]_** (61)

Let Î¾ âˆˆ _âˆ‚âˆ¥Î²âˆ¥1 be the subgradient that attains the minimum in Ï‰Î»(Î²). Adding and subtracting_
(Î² âˆ’ **_Î²[âˆ—])[âŠ¤](Î» â—¦_** **_Î¾) to the right-hand side of Eq. 61 yields_**

(Ïâˆ’ _âˆ’_ _Î¾)âˆ¥Î²[âˆ—]_ _âˆ’_ **_Î²âˆ¥2[2]_** _[â‰¤]_ [(][Î²][ âˆ’] **_[Î²][âˆ—][)][âŠ¤][(][âˆ‡][L][Î»][(][Î²][) +][ Î»][ â—¦]_** **_[Î¾][)]_** _âˆ’_ (Î² âˆ’ **_Î²[âˆ—])[âŠ¤]âˆ‡LÎ»(Î²[âˆ—])_**
(i) (ii)
| (Î² **_Î²[âˆ—])[âŠ¤]({zÎ»_** **_Î¾)_** _._ } | {z }

_âˆ’_ _âˆ’_ _â—¦_
(iii)

Now we bound the terms (i)-(iii). | {z }

**Bound (i) using Ï‰Î»(Î²). Since Î¾ attains the minimum in Ï‰Î»(Î²), by definition,**

(Î² **_Î²â€²)âŠ¤_**

_Ï‰Î»(Î²) = max_ _âˆ’_ ( _LÎ»(Î²) + Î»Î¾)_ _._
**_Î²[â€²]âˆˆâ„¦_**  _âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥Î»,1_** _âˆ‡_ 

Therefore,


(i) = (Î² **_Î²[âˆ—])[âŠ¤](_** _LÎ»(Î²) + Î»Î¾)_ _Ï‰Î»(Î²)_ **_Î²_** **_Î²[âˆ—]_** **_Î»,1_** _Ïµ_ **_Î²_** **_Î²[âˆ—]_** **_Î»,1._**
_âˆ’_ _âˆ‡_ _â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_

**Bound (ii). Note that LÎ» = Ln + QÎ». Thus,**

(ii) = (Î² **_Î²[âˆ—])[âŠ¤]_** _Ln(Î²[âˆ—]) + (Î²_ **_Î²[âˆ—])[âŠ¤]_** _QÎ»(Î²[âˆ—])_
_|_ _|_ _âˆ’_ _âˆ‡_ _âˆ’_ _âˆ‡_

(Î² **_Î²[âˆ—])[âŠ¤]_** _Ln(Î²[âˆ—])_ + (Î² **_Î²[âˆ—])[âŠ¤]_** _QÎ»(Î²[âˆ—])_
_â‰¤_ _âˆ’_ _âˆ‡_ _âˆ’_ _âˆ‡_

Since Î»j 8 [Ln(Î²[âˆ—])]j, we have
_â‰¥_ _|_ _|_

(Î² **_Î²[âˆ—])[âŠ¤]_** _Ln(Î²[âˆ—])_
_|_ _âˆ’_ _âˆ‡_ _| â‰¤_ [1]8 _[âˆ¥][Î²][ âˆ’]_ **_[Î²][âˆ—][âˆ¥][Î»][,][1][.]_**


Since qÎ»[â€²] _j_ [(0) = 0][ and][ q]Î»[â€²] _j_ [(][Î²][)][ â‰¤] _[Î»][j][ (Assumption][ B.1][), it holds true that]_


_|(Î² âˆ’_ **_Î²[âˆ—])[âŠ¤]âˆ‡QÎ»(Î²[âˆ—])| = |(Î² âˆ’_** **_Î²[âˆ—])[âŠ¤]S[âˆ—]_** [(][âˆ‡][Q][Î»][(][Î²][âˆ—][))][S][âˆ—] _[|]_
(Î² **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1._
_â‰¤âˆ¥_ _âˆ’_ _âˆ¥_


Therefore,


(ii)
_|_ _| â‰¤_ [1]8 _[âˆ¥][Î²][ âˆ’]_ **_[Î²][âˆ—][âˆ¥][Î»][,][1][ +][ âˆ¥][(][Î²][ âˆ’]_** **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1][.]_

**Bound (iii) by the definition of subgradient.**

(iii) = (Î² âˆ’ **_Î²[âˆ—])[âŠ¤](Î» â—¦_** **_Î¾)_**
= **_Î»Sâˆ—_** (Î² **_Î²[âˆ—])Sâˆ—_** _, Î¾Sâˆ—_ + **_Î»Sâˆ—_** (Î² **_Î²[âˆ—])Sâˆ—_** _, Î¾Sâˆ—_ _._
_âŸ¨_ _â—¦_ _âˆ’_ _âŸ©_ _âŸ¨_ _â—¦_ _âˆ’_ _âŸ©_


-----

By Holderâ€™s inequality and the fact **_Î¾_** 1,
_âˆ¥_ _âˆ¥âˆ_ _â‰¤_

**_Î»Sâˆ—_** (Î² **_Î²[âˆ—])Sâˆ—_** _, Î¾Sâˆ—_ (Î² **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1._
_âŸ¨_ _â—¦_ _âˆ’_ _âŸ©â‰¥âˆ’âˆ¥_ _âˆ’_ _âˆ¥_

Since Î¾ âˆˆ _âˆ‚âˆ¥Î²âˆ¥1 and that Î²S[âˆ—]_ _[âˆ—]_ [=][ 0][,]

_âŸ¨Î»Sâˆ—_ _â—¦_ (Î² âˆ’ **_Î²[âˆ—])Sâˆ—_** _, Î¾Sâˆ—_ _âŸ©_ = âŸ¨Î»Sâˆ— _â—¦_ **_Î²Sâˆ—_** _, Î¾Sâˆ—_ _âŸ©_ = âˆ¥Î²Sâˆ— _âˆ¥Î»Sâˆ—_ _,1 = âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1._ (62)

Combining the above three equations, it holds true that

(iii) â‰¥âˆ’âˆ¥(Î² âˆ’ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 + âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1._

**Combine (i)-(iii). Combining the bounds for (i)-(iii), it holds true that**


(Ïâˆ’ _âˆ’_ _Î¾)âˆ¥Î²[âˆ—]_ _âˆ’_ **_Î²âˆ¥2[2]_**

_â‰¤_ _Ïµ + 8 [1]_ [+ 1 + 1] _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 âˆ’_ 1 âˆ’ _Ïµ âˆ’_ 8[1] _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1_
   

7

= _Ïµ + [17]8_ _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 âˆ’_ 8 _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1_ (63)
   _[âˆ’]_ _[Ïµ]_

_â‰¥0_

_â‰¤_ _Ïµ + [17]8_ _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1._ | {z }
 

Using the fact that (Î² **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1_ **_Î»Sâˆ—_** 2 (Î² **_Î²[âˆ—])Sâˆ—_** 2, it implies the first conclusion:
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤âˆ¥_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_

_Ïµ +_ [17]8 **_Î»Sâˆ—_** 2

**_Î²[âˆ—]_** **_Î²_** 2 _âˆ¥_ _âˆ¥_ _._ (64)
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_   _Ïâˆ’âˆ’_ _Î¾_

Now we prove the objective value. Since LÎ» is convex on Î², Î²[âˆ—] and âˆ¥Â·âˆ¥1 is convex,

_Ï†Î»(Î²[âˆ—])_ _Ï†Î»(Î²) + (Î²[âˆ—]_ **_Î²)[âŠ¤](_** _LÎ»(Î²) + Î»_ **_Î¾),_**
_â‰¥_ _âˆ’_ _âˆ‡_ _â—¦_

which implies

_Ï†Î»(Î²)_ _Ï†Î»(Î²[âˆ—])_ (Î² **_Î²[âˆ—])[âŠ¤](_** _LÎ»(Î²) + Î»_ **_Î¾)_**
_âˆ’_ _â‰¤_ _âˆ’_ _âˆ‡_ _â—¦_
**_Î²_** **_Î²[âˆ—]_** **_Î»,1Ï‰Î»(Î²)_** _Ïµ_ **_Î²_** **_Î²[âˆ—]_** **_Î»,1_** (65)
_â‰¤âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ _âˆ¥_ _âˆ’_ _âˆ¥_

Now we bound the norm âˆ¥Î² âˆ’ **_Î²[âˆ—]âˆ¥Î»,1 as follows. By triangle inequality,_**

_âˆ¥Î² âˆ’_ **_Î²[âˆ—]âˆ¥Î»,1 â‰¤âˆ¥(Î² âˆ’_** **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 + âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1._ (66)

To bound âˆ¥(Î² âˆ’ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1, moving the term âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 in Eq. 63 to the left hand side_
yields


(7/8 âˆ’ _Ïµ)âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_ (Ïµ + 17/8)âˆ¥(Î² âˆ’ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1,_


which implies


_âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥Î»Sâˆ—_ _,1 â‰¤_ _[Ïµ]7[ + 17]/8_ _[/]Ïµ[8]_ (67)

_âˆ’_ _[âˆ¥][(][Î²][ âˆ’]_ **_[Î²][âˆ—][)][S][âˆ—]_** _[âˆ¥][Î»][S][âˆ—]_ _[,][1][.]_

Plugging it into Eq. 66, we have


**_Î²_** **_Î²[âˆ—]_** **_Î»,1_** 1 + _[Ïµ][ + 17][/][8]_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_ 7/8 _Ïµ_
 _âˆ’_


(Î² **_Î²[âˆ—])Sâˆ—_** **_Î»Sâˆ—_** _,1_
_âˆ¥_ _âˆ’_ _âˆ¥_ _â‰¤_


**_Î»Sâˆ—_** 2 **_Î²_** **_Î²[âˆ—]_** 2
_âˆ¥_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_


7/8 âˆ’ _Ïµ_


_Ïµ +_ [17]8



[17]8 **_Î»Sâˆ—_** 2

_âˆ¥_ _âˆ¥_

_Ï_ _Î¾_
_âˆ’âˆ’_


(by Eq. 64) â‰¤


**_Î»Sâˆ—_** 2
_âˆ¥_ _âˆ¥_


_Sâˆ—_ 2

_â‰¤_ 7/8 _Ïµ_ _âˆ¥_ _âˆ¥_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_ _âˆ’_

**_Î»Sâˆ—_** 2

= [3(][Ïµ][ + 17][/][8)] _âˆ¥_ _âˆ¥[2]_ (68)

7/8 _Ïµ_ _Ï_ _Î¾ [.]_
_âˆ’_ _âˆ’_ _âˆ’_

Combining it with Eq. 65, we have


_Ï†Î»(Î²)_ _Ï†Î»(Î²[âˆ—])_ _âˆ¥Î»Sâˆ—_ _âˆ¥2[2]_
_âˆ’_ _â‰¤_ [3][Ïµ][(]7[Ïµ]/[ + 17]8 _Ïµ[/][8)]_ _Ï_ _Î¾ [.]_

_âˆ’_ _âˆ’_ _âˆ’_


-----

convex on the restricted space, thenFinally, we derive the bound for the term Ï†Î»(Î²) âˆ’ _Ï†Î»(Î²Î»). Since âˆ¥Î² âˆ’_ **_Î²[b]Î»âˆ¥0 â‰¤_** _s[âˆ—]_ + 2Ëœs and Ï†Î» is

[b]

_Ï†Î»(Î²)_ _Ï†Î»(Î²Î»)_ ( _LÎ»(Î²) + Î»_ **_Î¾)[âŠ¤](Î²_** **_Î²Î»)_**
_âˆ’_ _â‰¤_ _âˆ‡_ _â—¦_ _âˆ’_ [b]

_Ï‰Î»(Î²)_ **_Î²_** **_Î²Î»_** **_Î»,1_**
_â‰¤_ _âˆ¥_ _âˆ’[b]_ [b] _âˆ¥_

_â‰¤_ _Ïµ_ _âˆ¥Î² âˆ’_ **_Î²[âˆ—]âˆ¥Î»,1 + âˆ¥Î²[âˆ—]_** _âˆ’_ **_Î²[b]Î»âˆ¥Î»,1_**

(by Eq. 68) _Ïµ_  3(Ïµ + 17/8) _âˆ¥Î»Sâˆ—_ _âˆ¥2[2]_ Î²Î» **_Î»,1_** _._ (69)
_â‰¤_ 7/8 _Ïµ_ _Ï_ _Î¾_ [+][ âˆ¥][Î²][âˆ—] _[âˆ’]_ [b] _âˆ¥_
 _âˆ’_ _âˆ’_ _âˆ’_ 

Now we only need to bound the term **_Î²[âˆ—]_** **_Î²Î»_** **_Î»,1. We can derive its bound following the same_**
_âˆ¥_ _âˆ’_ [b] _âˆ¥_
steps as we derive Eq. 68 and using the fact that Ï‰Î»(Î²Î») = 0, which will imply that

**_Î²Î»_** **_Î²[âˆ—]_** 1 _âˆ¥[b]Î»Sâˆ—_ _âˆ¥2[2]_ 2 _._
_âˆ¥_ [b] _âˆ’_ _âˆ¥_ _â‰¤_ [3 (0 + 17]7/8 0[/][8)] _Ï_ _Î¾_ [= 51][/]Ï[7][âˆ¥][Î»][S]Î¾[âˆ—] _[âˆ¥][2]_

_âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_ _âˆ’_

Plugging it into Eq. 69, we have

_Ï†Î»(Î²)_ _Ï†Î»(Î²Î»)_
_âˆ’_

_Ïµ_ 3 (Ïµ + 17/8) + 51/7 _âˆ¥Î»Sâˆ—_ _âˆ¥22_
_â‰¤_ 7/8 [b] _Ïµ_ _Ï_ _Î¾ [.]_
 _âˆ’_  _âˆ’_ _âˆ’_


Assuming Ïµ â‰¤ 1/2, then

_Ï†Î»(Î²)_ _Ï†Î»(Î²Î»)_ 2 _._
_âˆ’_ _â‰¤_ [29][/]Ï[2][âˆ¥][Î»][S]Î¾[âˆ—] _[âˆ¥][2]_

_âˆ’_ _âˆ’_

[b]

**Lemma G.6 (Optimality when Î» decreases). Assume Assumption G.1. If**


_Ï‰Î»tâˆ’1_ (Î²) â‰¤ _Ïµtâˆ’1,_ (70)

**_Î»t = Î·_** **_Î»t_** 1 _with_ _Î·j_ [0.9, 1], (71)
_â—¦_ _âˆ’_ _âˆˆ_
**_Î²_** 0 _s,Ëœ_ (72)
_âˆ¥_ _âˆ¥_ _â‰¤_


_then_


_Ï‰Î»t_ (Î²) â‰¤ _[Ïµ][t][âˆ’][1]0[ + 0].9_ _[.][2]_

_Ï†Î»t_ (Î²) âˆ’ _Ï†Î»t_ (Î²Î»t ) â‰¤  3 (0.9(7Ïµtâˆ’/18 + 17 âˆ’ _Ïµtâˆ’/8)1) [+ 51][/][7] Ïµtâˆ’10 + 0.9_ _.2_ _âˆ¥(ÏÎ»âˆ’t)âˆ’Sâˆ—Î¾âˆ¥2[2]_

_If Ïµt_ 1 1/4, then [b]
_âˆ’_ _â‰¤_

_Ï‰Î»t_ (Î²) â‰¤ [1]2

_Ï†Î»t_ (Î²) âˆ’ _Ï†Î»t_ (Î²Î»t ) â‰¤ [10][âˆ¥]Ï[(][Î»][t][)][S]Î¾[âˆ—] _[âˆ¥]2[2]_ _._

_âˆ’_ _âˆ’_

[b]

_Proof. Recall the definition of Ï‰Î»tâˆ’1_ (Î²).


(Î² **_Î²[â€²])[âŠ¤]_**

_âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»tâˆ’1,1_ (âˆ‡LÎ»tâˆ’1 (Î²) + Î»tâˆ’1Î¾[â€²])


_Ï‰Î»tâˆ’1_ (Î²) = **_Î¾[â€²]âˆˆminâˆ‚âˆ¥Î²âˆ¥1_** **_Î²[max][â€²]âˆˆâ„¦_**


Let Î¾ âˆˆ _âˆ‚âˆ¥Î²âˆ¥1 be the subgradient that attains the minimum in Ï‰Î»tâˆ’1_ (Î²). Then


(Î² **_Î²[â€²])[âŠ¤]_**

_âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»tâˆ’1,1_ (âˆ‡LÎ»tâˆ’1 (Î²) + Î»tâˆ’1Î¾)


_Ï‰Î»tâˆ’1_ (Î²) = maxÎ²[â€²]âˆˆâ„¦


-----

Now we consider Î»t = Î· **_Î»t_** 1. By definition,
_â—¦_ _âˆ’_

(Î² **_Î²â€²)âŠ¤_**

_Ï‰Î»t_ (Î²) = **_Î¾[â€²]âˆˆminâˆ‚âˆ¥Î²âˆ¥1_** **_Î²[max][â€²]âˆˆâ„¦_**  _âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»t,1_ (âˆ‡LÎ»t (Î²) + Î»tÎ¾[â€²])

(Î² **_Î²â€²)âŠ¤_**

_â‰¤_ **_Î²max[â€²]âˆˆâ„¦_**  _âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»t,1_ (âˆ‡LÎ»t (Î²) + Î»tÎ¾) _._

Note that

_âˆ‡LÎ»t_ (Î²) + Î»tÎ¾ = _âˆ‡LÎ»tâˆ’1_ (Î²) + Î»tâˆ’1Î¾

+ (Î»t **_Î»t_** 1) **_Î¾_**

  _âˆ’_ _âˆ’_ _â—¦_ 

+ _âˆ‡QÎ»t_ (Î²) âˆ’âˆ‡QÎ»tâˆ’1 (Î²) _,_

which implies   


(Î² **_Î²â€²)âŠ¤_**

_Ï‰Î»t_ (Î²) â‰¤ **_Î²max[â€²]âˆˆâ„¦_**  _âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»t,1_ _âˆ‡LÎ»tâˆ’1_ (Î²) + Î»tâˆ’1Î¾

  []

(i)
| (Î² **_Î²â€²)âŠ¤_** {z }

+ maxÎ²[â€²]âˆˆâ„¦  _âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»t,1_ (Î»t âˆ’ **_Î»tâˆ’1) â—¦_** **_Î¾_**

(ii)
| (Î² **_Î²â€²)âŠ¤_** {z }

+ maxÎ²[â€²]âˆˆâ„¦  _âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»t,1_ _âˆ‡QÎ»t_ (Î²) âˆ’âˆ‡QÎ»tâˆ’1 (Î²) _._

  []

(iii)

Using the fact that âˆ¥Î² âˆ’ **_Î²[â€²]âˆ¥Î»t,1 â‰¥|_** 0.9âˆ¥Î² âˆ’ **_Î²[â€²]âˆ¥Î»tâˆ’1,1, term (i) can be bounded as follows.{z_** }

(Î² **_Î²[â€²])[âŠ¤]_**

(i) â‰¤ 0[1].9 _âˆ¥Î² âˆ’ âˆ’Î²[â€²]âˆ¥Î»tâˆ’1,1_ _âˆ‡LÎ»tâˆ’1_ (Î²) + Î»tâˆ’1Î¾ _â‰¤_ 0[1].9 _[Ï‰][Î»][t][âˆ’][1]_ [(][Î²][)][ â‰¤] _[Ïµ]0[t][âˆ’].9[1]_ _[.]_

  

1 1
Using the fact |Î¾j| â‰¤ 1 and the fact that [Î»tâˆ’1 âˆ’ **_Î»t]j =_** _Î·j_ _[âˆ’]_ [1] [Î»t]j â‰¤ 0.9 _[âˆ’]_ [1] [Î»t]j, term (ii)

can be bounded as follows.     

(ii) _d_ **_Î²j âˆ’_** **_Î²j[â€²]_** 1 [Î»t]j = 1 = [1]
_â‰¤_ _j=1_ _âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥Î»t,1_**  0.9 _[âˆ’]_ [1] _[âˆ¥]âˆ¥[Î²]Î²[ âˆ’] âˆ’_ **_[Î²]Î²[â€²][â€²][âˆ¥]âˆ¥[Î»]Î»[t]t[,],[1]1_**  0.9 _[âˆ’]_ [1] 0.9 _[âˆ’]_ [1][.]

X

Term (iii) is bounded similarly as term (ii). Since _qÎ»j_ (Î²) âˆ’ _qÎ»[â€²]j_ [(][Î²][)] _â‰¤_ _Î»j âˆ’_ _Î»[â€²]j_, we have

(iii) _d_ **_Î²j âˆ’_** **_Î²j[â€²]_** [Î»t 1 **_Î»t]j_** _d_ **_Î²j âˆ’_** **_Î²j[â€²]_** 1 [Î»t]j = [1]
_â‰¤_ _j=1_ _âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥Î»t,1_** _âˆ’_ _âˆ’_ _â‰¤_ _j=1_ _âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥Î»t,1_**  0.9 _[âˆ’]_ [1] 0.9 _[âˆ’]_ [1][.]

X X


Combining the bounds for (i)-(iii), we have

_Ï‰Î»t_ (Î²) â‰¤ _[Ïµ][t][âˆ’]0[1].[ + 2]9_ _âˆ’_ 2 = _[Ïµ][t][âˆ’][1]0[ + 0].9_ _[.][2]_


The first part of the proof is finished. Now we bound the term Ï†Î»t (Î²) _Ï†Î»t_ (Î²Î»t ). Since **_Î²_**
_âˆ’_ _âˆ¥_ _âˆ’_
**_Î²Î»âˆ¥0 â‰¤_** _s[âˆ—]_ + 2Ëœs and Ï†Î» is convex on the restricted space, then

[b]
b _Ï†Î»t_ (Î²) _Ï†Î»t_ (Î²Î»t )

_âˆ’_

( _LÎ»t_ (Î²) + Î»t **_Î¾)[âŠ¤](Î²_** **_Î²Î»t_** )
_â‰¤_ _âˆ‡_ [b] _â—¦_ _âˆ’_ [b]

_Ï‰Î»t_ (Î²) **_Î²_** **_Î²Î»t_** **_Î»t,1_**
_â‰¤_ _âˆ¥_ _âˆ’_ [b] _âˆ¥_

**_Î²_** **_Î²[âˆ—]_** **_Î»t,1 +_** **_Î²[âˆ—]_** **_Î²Î»t_** **_Î»t,1_** (73)

_â‰¤_ _[Ïµ][t][âˆ’][1]0[ + 0].9_ _[.][2]_ _âˆ¥_ _âˆ’_ _âˆ¥_ _âˆ¥_ _âˆ’_ [b] _âˆ¥_

 


-----

Following the same way we derive Eq. 67, we can obtain that


_âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥(Î»t)Sâˆ—_ _,1 â‰¤_ _[Ïµ]7[t][âˆ’]/8[1][ + 17]Ïµt_ _[/]1[8]_ _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥(Î»t)Sâˆ—_ _,1._

_âˆ’_ _âˆ’_

_âˆ¥Î² âˆ’_ **_Î²[âˆ—]âˆ¥Î»t,1 = âˆ¥(Î² âˆ’_** **_Î²[âˆ—])Sâˆ—_** _âˆ¥(Î»t)Sâˆ—_ _,1 + âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥(Î»t)Sâˆ—_ _,1_ (74)


Therefore,


3
_â‰¤_ 7/8 âˆ’ _Ïµtâˆ’1_ _âˆ¥(Î² âˆ’_ **_Î²[âˆ—])Sâˆ—_** _âˆ¥(Î»t)Sâˆ—_ _,1_

**_Î²_** **_Î²[âˆ—]_** 2

_â‰¤_ [3]7[âˆ¥]/[(]8[Î»] âˆ’[t][)][S]Ïµt[âˆ—]âˆ’[âˆ¥]1[2] _âˆ¥_ _âˆ’_ _âˆ¥_

(By Lemma G.5) _Ïµtâˆ’1 +_ [17]8 _âˆ¥(Î»tâˆ’1)Sâˆ—_ _âˆ¥2_
_â‰¤_ [3]7[âˆ¥]/[(]8[Î»][t][)][S]Ïµt[âˆ—] _[âˆ¥]1[2]_ _Ï_ _Î¾_

_âˆ’_ _âˆ’_   _âˆ’_ _âˆ’_

(Î»t)Sâˆ— 2

= [3 (][Ïµ][t][âˆ’][1][ + 17][/][8)] _âˆ¥_ _âˆ¥[2]_ _._ (75)

0.9(7/8 âˆ’ _Ïµtâˆ’1)_ _Ïâˆ’_ _âˆ’_ _Î¾_

Using the same arguments for the term âˆ¥Î²[âˆ—] _âˆ’_ **_Î²[b]Î»t_** _âˆ¥Î»t,1 and using the fact that Ï‰Î»t_ (Î²Î»t ) â‰¤ 0 Â· Î»t,
we obtain that

(Î»t)S[âˆ—] 2 2 [b]

_âˆ¥Î²[b]Î»t âˆ’_ **_Î²[âˆ—]âˆ¥1 â‰¤_** [3 (0 + 17]7/8 âˆ’ 0[/][8)] _âˆ¥_ _Ïâˆ’_ _âˆ’_ _Î¾âˆ¥[2]_ = [51][/][7]Ï[âˆ¥]âˆ’[(][Î»]âˆ’[t][)]Î¾[S][âˆ—] _[âˆ¥][2]_ _._

Combining this inequality with Eq. 73 and Eq. 75, we have


_Ï†Î»t_ (Î²) _Ï†Î»t_ (Î²Î»t )
_âˆ’_

3 (Ïµtâˆ’1 + 17/8) _Ïµtâˆ’1 + 0.2_ _âˆ¥(Î»t)Sâˆ—_ _âˆ¥2[2]_ _._
_â‰¤_  0.9(7/8 âˆ’[b]Ïµtâˆ’1) [+ 51][/][7] 0.9 _Ïâˆ’_ _âˆ’_ _Î¾_

Assuming Ïµtâˆ’1 â‰¤ 1/4, then

_Ï†Î»t_ (Î²) âˆ’ _Ï†Î»t_ (Î²Î»t ) â‰¤ [10][âˆ¥]Ï[(][Î»][t][)][S]Î¾[âˆ—] _[âˆ¥]2[2]_ _._

_âˆ’_ _âˆ’_

[b]

**Lemma G.7 (Coercivity of the gradient). [Lemma 3.11 in Bubeck (2014)] Let f be a-strongly convex**
_b-smooth and on B âŠ†_ R[d]. Then for all Î², Î²[â€²] _âˆˆB, one has_

_ab_ 1
_f_ (Î²) _f_ (Î²[â€²]), Î² **_Î²_** 2 [+] 2 _[.]_
_âŸ¨âˆ‡_ _âˆ’âˆ‡_ _âˆ’_ _âŸ©â‰¥_ _a + b_ _[âˆ¥][Î²][ âˆ’]_ **_[Î²][â€²][âˆ¥][2]_** _a + b_ _[âˆ¥âˆ‡][f]_ [(][Î²][)][ âˆ’âˆ‡][f] [(][Î²][â€²][)][âˆ¥][2]


-----

H DETAILS OF SECTION 5: EXTENSION TO UNSUPERVISED
LEARNING-TO-LEARN SETTING

In addition to the assumptions in the supervised setting, in this unsupervised setting, we assume
for each estimation problem, both Ln1 (Z1:n1 ) and Ln2 (Z1:n2 ) satisfy condition (b) and (c) in Assumption C.1. Similar to the supervised setting, the generalization error of the optimizer Î¸U[âˆ—] [can be]
bounded by


_m_

2

_Lgen(P(P); Î¸U[âˆ—]_ [)][ â‰¤] [E](Z1:n,Î²[âˆ—])âˆ¼P(P) _[âˆ¥][Î²][T]_ [(][Z][1:][n]1 [;][ Î¸]U[âˆ—] [)][ âˆ’] **_[Î²][âˆ—][âˆ¥][2]2_** _[âˆ’]_ _m[1]_ _i=1_ **_Î²T (Z1:[(][i]n[)]_** 1 [;][ Î¸]U[âˆ—] [)][ âˆ’] **_[Î²][âˆ—][(][i][)]_** 2

X

generalization gap: Theorem 4.1

(76)

| {z }

_m_

+ [1] **_Î²T (Z1:[(][i]n[)]_** 1 [;][ Î¸]U[âˆ—] [)][ âˆ’] **_[Î²][âˆ—][(][i][)]_** 2 _._ (77)

_m_ 2

_i=1_

X

supervised training error
| {z }

However, in the unsupervised setting, the minimizer Î¸U[âˆ—] [only guarantees that unsupervised training]

loss function _m[1]_ _mi=1_ _[L][n][2]_ _Z1:[(][i]n[)]_ 2 _[,][ Î²][T][ (][Z]1:[(][i]n[)]_ 1 [;][ Î¸]U[âˆ—] [)] is small. It requires further derivations to show

that the corresponding supervised training loss in Eq.  77 is small, too.
P

Therefore, in the following, we bridge the gap between the supervised training loss and the unsupervised training loss. Based on the proof of Theorem D.1, we know that âˆ¥Î²T (Z1:[(][i]n[)] 1 [;][ Î¸]U[âˆ—] [)][|]S[âˆ—] _[âˆ¥][0][ â‰¤]_ _s[Ëœ]._
Therefore, we can apply the restricted strong convexity of Ln2 to obtain the following inequality for
**_Î²T = Î²T (Z1:[(][i]n[)]_** 1 [;][ Î¸]U[âˆ—] [)][,][ Î²][âˆ—] [=][ Î²][âˆ—][(][i][)][, and][ Z][ =][ Z]1:[(][i]n[)] 2 [for each][ i][ = 1][,][ Â· Â· Â·][, m][.]


**_Î²T_** **_Î²[âˆ—]_** 2 _Ln2 (Z, Î²T )_ _Ln2 (Z, Î²[âˆ—]) +_ _Ln2 (Z, Î²[âˆ—])[âŠ¤]_ (Î²[âˆ—] **_Î²T )_**
_âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[â‰¤]_ _Ï[2]âˆ’_ _âˆ’_ _âˆ‡_ _âˆ’_

 

(Ln2 (Z, Î²T ) _Ln2 (Z, Î²[âˆ—]) +_ _Ln2 (Z, Î²[âˆ—])_ 2 (Î²[âˆ—] **_Î²T )_** 2)

_â‰¤_ _Ï[2]_ _âˆ’_ _âˆ¥âˆ‡_ _âˆ¥_ _âˆ¥_ _âˆ’_ _âˆ¥_

_âˆ’_

**_Î²T_** **_Î²[âˆ—]_** 2 (Ln2 (Z, Î²T ) _Ln2 (Z, Î²[âˆ—])) + [16]_ _Ln2 (Z, Î²[âˆ—])_ 2
_â‡’âˆ¥_ _âˆ’_ _âˆ¥[2]_ _[â‰¤]_ _Ï[4]âˆ’_ _âˆ’_ _Ï[2]âˆ’_ _âˆ¥âˆ‡_ _âˆ¥[2]_

Aggregating this inequality for i = 1, Â· Â· Â·, m, we can obtain the following inequality that bounds
the supervised training loss using the unsupervised loss.


_m_ _m_

1 2 16

**_Î²T (Z1:[(][i]n[)]_** 1 [;][ Î¸]U[âˆ—] [)][ âˆ’] **_[Î²][âˆ—][(][i][)]_** _Ln2_ (Z1:[(][i]n[)] 2 _[,][ Î²][âˆ—][(][i][)][)][âˆ¥]2[2]_

_m_ 2 _Ï[2]_ _âˆ¥âˆ‡_

_i=1_ _[â‰¤]_ _âˆ’[m]_ _i=1_

X X

statistical error

_m_

4

| {z }

+ _Ln2_ (Z1:[(][i]n[)] 2 _[,][ Î²][T][ (][Z]1:[(][i]n[)]_ 1 [;][ Î¸]U[âˆ—] [))][ âˆ’] _[L][n]2_ [(][Z]1:[(][i]n[)] 2 _[,][ Î²][âˆ—][(][i][)][)]_

_Ï_ _m_
_âˆ’_ _i=1_

X  

unsupervised training error

The right-hand-side of this inequality consists of a statistical error and the unsupervised training| {z }
error. Finally, to characterize how small the unsupervised training error can be, we can combine the
following inequality (by restricted strongly smooth) with the result of Theorem 3.1.


_Ln2 (Z1:n2_ _, Î²T (Z1:n1_ ; Î¸U[âˆ—] [))][ âˆ’] _[L][n]2_ [(][Z][1:][n]2 _[,][ Î²][âˆ—][)]_
_â‰¤_ _Ln2 (Z1:n2_ _, Î²T (Z1:n1_ ; Î¸[âˆ—])) âˆ’ _Ln2 (Z1:n2_ _, Î²[âˆ—])_

_â‰¤âˆ¥âˆ‡Î²Ln2_ (Z1:n2 _, Î²[âˆ—])âˆ¥2 âˆ¥Î²T (Z1:n1_ ; Î¸[âˆ—]) âˆ’ **_Î²[âˆ—]âˆ¥2_**
bounded by Theorem 3.1
| {z }


+ _[Ï]2[+]_ 2

_[âˆ¥][Î²][T][ (][Z][1:][n][1]_ [;][ Î¸][âˆ—][)][ âˆ’] **_[Î²][âˆ—][âˆ¥][2]_**
bounded by Theorem 3.1
| {z }


(78)


-----

Overall, the generalization error can be bounded by

_Lgen(P(P); Î¸U[âˆ—]_ [)]

_m_

2

_â‰¤_ E(Z1:n,Î²âˆ—)âˆ¼P(P) âˆ¥Î²T (Z1:n1 ; Î¸U[âˆ—] [)][ âˆ’] **_[Î²][âˆ—][âˆ¥][2]2_** _[âˆ’]_ _m[1]_ _i=1_ **_Î²T (Z1:[(][i]n[)]_** 1 [;][ Î¸]U[âˆ—] [)][ âˆ’] **_[Î²][âˆ—][(][i][)]_** 2 _âˆ—_

X

generalization gap: Theorem 4.1
| _m_ {z }

4
+ _Ïâˆ’m_ _i=1_ ï£«âˆ¥âˆ‡Î²Ln2 (Z1:[(][i]n[)] 2 _[,][ Î²][âˆ—][(][i][)][)][âˆ¥][2]_ _âˆ¥Î²T (Z1:[(][i]n[)]_ 1 [;][ Î¸][âˆ—][)][ âˆ’] **_[Î²][âˆ—][(][i][)][âˆ¥][2]_** + _[Ï]2[+]_ _[âˆ¥][Î²][T][ (][Z]1:[(][i]n[)]_ 1 [;][ Î¸][âˆ—][)][ âˆ’] **_[Î²][âˆ—][(][i][)][âˆ¥]2[2]_**

X statistical error bounded by Theorem 3.1 bounded by Theorem 3.1

ï£¬

_m_ ï£­

16 | {z } | {z } | {z }
+ _Ln2_ (Z1:[(][i]n[)] 2 _[,][ Î²][âˆ—][(][i][)][)][âˆ¥]2[2]_ _._

_Ï[2]_ _âˆ¥âˆ‡_
_âˆ’[m]_ _i=1_

X

statistical error
| {z }


-----

I DETAILS OF SYNTHETIC EXPERIMENTS

I.1 A GENTLE REVIEW OF LINEAR REGRESSION AND PRECISION ESTIMATION

I.1.1 SPARSE LINEAR REGRESSION

A sparse linear regression model reads

_y = x[âŠ¤]Î²[âˆ—]_ + Ïµ

where Î²[âˆ—] is a sparse vector and Ïµ is Gaussian noise. Given n observations Z1:n :=
(x1, y1), _, (xn, yn)_, the goal is to estimate the vector Î²[âˆ—].
_{_ _Â· Â· Â·_ _}_

In our method, we use the the least-square error to define the empirical loss function.


_Ln(Z1:n, Î²) = [1]_

2n

I.1.2 SPARSE PRECISION ESTIMATION


**_x[âŠ¤]j_** **_[Î²][ âˆ’]_** _[y][j]_


_j=1_


The sparse precision matrix estimation problem in Gaussian graphical models assumes the observation of n samples from a distribution N (0, Î£). Given the n samples, X1:n := {x1, Â· Â· Â·, xn} from
_N_ (0, Î£), the goal is to estimate the precision matrix Î˜[âˆ—] := Î£[âˆ’][1] which is the inverse covariance
matrix. This precision matrix represents the conditional independency among random variables.

A commonly used objective for estimating the precision matrix is the â„“1-penalized log determinant
divergence:

log det(Î˜) + Î˜, Î£[Ë†] _n_ + Î» Î˜ 1
_âˆ’_ _âŸ¨_ _âŸ©_ _âˆ¥_ _âˆ¥_

where Î£[Ë†] _n is the sample covariance matrix. In our method, we use the likelihood term as the empiri-_
cal loss.

_Ln(X1:n, Î˜) =_ log det(Î˜) + Î˜, Î£[Ë†] _n_
_âˆ’_ _âŸ¨_ _âŸ©_

I.2 DATA PREPARATION

For the sparse linear recovery problem, we follow the setting in Wang et al. (2014). We create the
synthetic data by sampling a set of estimation problems {((X [(][i][)], Y [(][i][)]), Î²[âˆ—][(][i][)])}. In each problem,
the design matrix X [(][i][)] _âˆˆ_ R[n][Ã—][d] contains n = 64 independent realizations of a random vector
**x âˆˆ** R[p] with p = 256, 1024 in easy or difficult setting, respectively. x follows a zero mean Gaussian
distribution with covariance matrix (Î£)i,j = 0.9 1 _i=j_ + 1 1 _i=j_ . The true parameter vector
_Â·_ _{_ _Ì¸_ _}_ _Â·_ _{_ _}_
**_Î²[âˆ—][(][i][)]_** has a sparsity s[âˆ—] = âˆ¥Î²[âˆ—][(][i][)]âˆ¥0 = 16 and its nonzero entries take values uniformly sampled
from ( 2, 2 [)][ âˆª] [(][ 1]2 _[,][ 2)][. The support set of each][ Î²][âˆ—][(][i][)][ is independently sampled from a union]_
_âˆ’_ _âˆ’_ [1]

support set S, with |S| = 128 to allow some similarity among the problems. The observation Y [(][i][)] is
sampled such that Y [(][i][)] _âˆ’_ _X_ [(][i][)]Î²[âˆ—][(][i][)] is a n-dimensional Gaussian random vector with zero mean and
covariance matrix In. In all the experiments, 2000 such problems are used for training, 200 such
problems are used for validation, and 100 such problems are used for test.

In sparse precision matrix estimation problem, we follow the setting in Guillot et al. (2012). We
create the synthetic data by sampling a set of estimation problems {(Î£[Ë†] [(]n[i][)][,][ Î˜][(][i][)][)][}][. In each problem,]
the ground truth precision matrix is generated in the following ways: the lower diagonal part (lower
triangular parting, exluding diagonal) of true precision matrix Î˜ has a sparsity s[âˆ—], that are uniformly
selected from a union support with size S. After selecting the nonzero entries, we assign them values
uniformly from (âˆ’2, âˆ’ [1]2 [)][ âˆª] [(][ 1]2 _[,][ 2)][ and let the upper diagonal part has the same value as lower di-]_

agonal part. Finally, a multiple of the identity was added to the resulting matrix so that the smallest
eigenvalue was equal to 1. In this way, Î˜ was insured to be sparse, positive definite, and wellconditioned. After the precision matrix is generated, we generate the observational samples for each
precision matrix, by generating n independent samples of the random vector x âˆ¼N (0, (Î˜[(][i][)])[âˆ’][1]).
ance matrixThe samples are denoted byÎ£[Ë†] [(]n[i][)] [=][ 1]n _ni=1 X[(][X][(][(][i][i][)][)][)]âˆˆ[T][ X]R[n][(][i][Ã—][)][.][d]. Using the samples, we can compute the sample covari-_

P


-----

In all the experiments, 2000 such problems are used for training, 200 such problems are used for validation, and 100 such problems are used for test. We use (n, S, s[âˆ—]) = (100, 375, 75), (200, 600, 150)
for d = 50, 200, respectively.

I.3 BASELINE IMPLEMENTATION

**ALISTA: We follow the implementation in Liu et al. (2019a).**

**RNN: The RNN is designed following Andrychowicz et al. (2016). Initialize the Î²0 as 0. At every**
step, we compute the gradient _Î²L(Î²t) w.r.t. to objective as the input to a LSTM with hidden_
_âˆ‡_
dimension equals to 128. Then we use the output of the LSTM as the increment:

_Î²t+1 = Î²t + LSTM(âˆ‡Î²L(Î²t))_ (79)

We repeat this iteration 20 steps and use Î²20 as our final output.

**RNN-â„“1: RNN-â„“1 use the same architecture as RNN. The only difference is we add an extra learn-**
able parameter Î»t for soft thresholding at each step:

_Î²t+1 = Î²t + LSTM(âˆ‡Î²L(Î²t))_ (80)
_Î²t+1 = Î·Î»t_ (Î²t+1) (81)

where the softthresholding Î·Î» is an elementwise operator maps Î·Î»(x) = 0 is |x| < Î» and Î·Î»(x) =
sign(x)(|x| âˆ’ _Î»)._

**[GLASSO: we use the implementation in the sklearn package.](https://scikit-learn.org/stable/auto_examples/covariance/plot_sparse_cov.html#sphx-glr-auto-examples-covariance-plot-sparse-cov-py)**

**GGM: We follow the implementation in Belilovsky et al. (2017).**

**APF: We follow the implementation in Wang et al. (2014). The specific algorithm steps are sum-**
marized in Algorithm 3.

**Algorithm 3: The Approximate Path Following Method**
**Input: Î»tgt > 0, Ïµopt > 0 (Here we assume Ïµopt â‰ª** _Î»tgt/4), Î· âˆˆ_ [0.9, 1)

**1 Initialize** _Î²[Ëœ]0_ **0, L0** _Lmin, Î»0 =_ (0) _, N_ (Î»0/Î»tgt)/ log(Î·[âˆ’][1]).

**2 for t = 1, ..., N â†** _âˆ’_ 1 do â† _âˆ¥âˆ‡L_ _âˆ¥âˆ_ _â†_

**3** _Î»t_ _Î·[t]Î»0_

**4** _Ïµt_ _â†_ _Î»t/4_
_â†_

**5** _{Î²[Ëœ]t, Lt} â†_ Proximal-Gradient(Î»t, Ïµt, _Î²[Ëœ]tâˆ’1, Ltâˆ’1, R) as in Algorithm 4._

**6 end**

**87 Ïµ Î»NN â† â†** _ÏµÎ»opttgt_

**9 {Î²[Ëœ]N** _, LN_ _} â†_ Proximal-Gradient(Î»N _, ÏµN_ _,_ _Î²[Ëœ]N_ _âˆ’1, LN_ _âˆ’1, R)._

**10 return {Î²[Ëœ]t}t[N]=1[.]**


**Algorithm 4: The Proximal Gradient Method**

**1 InitializeInput: Î» kt > â† 0, Ïµ0.t > 0, Î²t[0]** _[âˆˆ]_ [R][p][, L]t[0] _[>][ 0]_

**2 repeat**

**3** _k â†_ _k + 1_

**4** _Linit_ max _Lmin, L[k]t_ _[âˆ’][1]/2_
_â†_ _{_ _}_

**65 untilÎ² Ï‰t[k][, L]Î»t** (t[k]Î²[â†]t[k][)][ â‰¤][Line-Search][Ïµ][t] _[as defined in Equation][(][Î»][t][, Î²]t[k][âˆ’][1], Linit)[ 82] as in Algorithm[;]_ 5.

**7** _Î²[Ëœ]t_ _Î²t[k]_
_â†_

**8 Lt** _L[k]t_
_â†_

**9 return** _Î²t, Lt_ .
_{_ [Ëœ] _}_


-----

**Algorithm 5: The Line Search Method**


**Input: Î»t > 0, Î²t[k][âˆ’][1]** R[d], Linit > 0, R > 0
_âˆˆ_

**1 repeat**

**2** **_Î²t[k]_** _L[k],Î»t_ **_Î²t[k][âˆ’][1]_** as defined in Equation 83

**3** **if Ï†Î»[â†T]t** **_Î²t[k]_** _> Ïˆ _ _Lkt_ _[,Î»][t]_ **_Î²t[k][;][ Î²]t[k][âˆ’][1]_** **then**

**4** _L[k]t_ _t_ [.]

     

**5** **end** _[â†]_ _[L][k]_

**6 until Ï†Î»t** (Î²t[k][)][ â‰¤] _[Ïˆ]L[k]t_ _[,Î»][t]_ [(][Î²]t[k][, Î²]t[k][âˆ’][1]) as defined in Equations 84 and 85;

**7** _Î²[Ëœ]t_ _Î²t[k]_
_â†_

**8 Lt** _L[k]t_
_â†_

**9 return** _Î²t, Lt_ .
_{_ [Ëœ] _}_

(Î² **_Î²[â€²])[T]_**

_Ï‰Î»(Î²) =_ min _âˆ’_ _Î»(Î²) + Î»Î¾[â€²][)]_ (82)
**_Î¾[â€²]âˆˆâˆ‚âˆ¥Î²âˆ¥1_** **_Î²[max][â€²]âˆˆâ„¦_** ( _âˆ¥Î² âˆ’_ **_Î²[â€²]âˆ¥1_** âˆ‡L[e]

0 if _Î²Â¯j_ _Î»t/L[k]t_

_TLkt_ _[,Î»][t]_ **_Î²t[k][âˆ’][1]_** _j_ [=] sign _Î²Â¯j_ _Î²Â¯j_ _Î»t/L[k]t_ if _Î²Â¯j_ _â‰¤ > Î»t/L[k]t_ (83)
   []  _âˆ’_

_Ï†Î»(Î²) = _   Î»(Î²) + Î» **_Î²_** 1  (84)
_L[e]_ _âˆ¥_ _âˆ¥_

_T_ _t_
_ÏˆLkt_ _[,Î»][t]_ **_Î²; Î²t[k][âˆ’][1]_** = L **_Î²t[k][âˆ’][1]_** + âˆ‡L **_Î²t[k][âˆ’][1]_** **_Î² âˆ’_** **_Î²t[k][âˆ’][1]_** + _[L]2[k]_ **_Î² âˆ’_** **_Î²t[k][âˆ’][1]_** 2 [+][ P][Î»][t] [(][Î²][)][ (85)]
           

[2]

I.4 TRAINING AND EVALUATION

We trained the learning-based methods to minimize the weighted loss. Thatâ€™s to say, for each sparse
linear recovery problem, given the sequence of outputs (Î²1, ..., Î²T ), the loss is computed as:


_Î³[T][ âˆ’][i]_ **_Î²i_** **_Î²[âˆ—]_** 2 (86)
_i=1_ _âˆ¥_ _âˆ’_ _âˆ¥[2]_

X


_L =_


where Î³ decreasing from 0.9 to 0.1 during the training process. The procedure is similar in the
sparse precision matrix estimation problem. We use optimizer Adam (Kingma & Ba, 2014). For
sparse linear recovery problem, we use batch size 10, we train 500 epochs with learning rate 1e4 and select the model based on the l2 loss on valid data. For sparse precision matrix estimation
problem, we use batch size 40, we train 200 epochs with learning rate 1e-3 and select the model
based on Frobenius loss on valid data.

For classical algorithms, we select their parameters, Î» for APF and Ï for GISTA, based on their
performance on the validation set. Specifically, we evaluate APF or GISTA with Ï or Î» from
_{0.01, 0.025, 0.05, 0.1, 0.2} and use one with the best recovery error in test._


Table 3: Training time for SLR (minutes)


Table 4: Training time for SPE (minutes)

|Sizes|d = 256 d = 1024|
|---|---|

|Sizes|d = 50 d = 100|
|---|---|

|PLISA ALISTA RNN RNN â„“1 APF|393 462 176 271 96 99 101 106 214 426|
|---|---|

|PLISA GGM GISTA APF GLASSO|35 39 14 43 176 116 316 331 42 57|
|---|---|


We report the total training time for learning based methods as well as the parameter tuning time for
classical algorithms. From Table 3 and Table 4, we can see that training a learning-based method is


-----

cheap in our experiments, as 1) A single forward for PLISA or GGM is very fast as stated in Table 1.
2) We can easily parallel the computations to handle a batch of problems during the training time,
as the learning-based methods do not require line-search.

The evaluation is performed on a server with CPU: Intel(R) Xeon(R) Silver 4116 CPU @ 2.10GHz,
GPU: Nvidia GTX 2080TI, Memory 264G, in single thread.

I.5 ABLATION STUDY

Table 5:is the true positive rate of recovering the nonzero en- Ablation study of PLISA (p = 1024). TPR 30 plisaplisa_l1 30
tries of Î²[âˆ—]. FPS is the cardinality of false positive 25 plisa_single 25
entries. Note that the true sparsity level is s[âˆ—] = 20 20
16. Standard deviations over 100 test problems are 15 15

|Col1|plisa|
|---|---|
||plisa_l1|
||plisa_single|
|||
|||
|||
|||
|||
|||


dim=256 dim=1024

30 plisaplisa_l1 30

25 plisa_single 25

20 20

15 15

l2-error

10 10

5 5

0 0

# iterations # iterations


Figure 6: Ablation study.

|present in the parantheses.|Col2|Col3|Col4|
|---|---|---|---|
|PLISA PLISA-single PLISA-â„“ 1||||
|â„“ error 2 TPR FPS|1.34 (2.28) 0.99 (0.01) 16.65 (13.60)|18.25 (6.06) 0.62 (0.19) 51.07 (6.67)|2.20 (2.76) 0.99 (0.02) 25.11 (13.30)|



We consider two variants of PLISA to perform the ablation study. One is PLISA-single which
employs a single regularization parameter across different entries, i.e., Î·1 = Â· Â· Â· = Î·d and Î»[âˆ—]1 [=]

_Â· Â· Â· = Î»[âˆ—]d[. The other is][ PLISA][-][â„“][1][ which does not learn the penalty function but uses the][ â„“][1][ norm,]_
i.e., Pw(Î», Î²) = **_Î»_** **_Î²_** 1. Fig. 6 and Table 5 show the vanilla PLISA performs better than
_âˆ¥_ _â—¦_ _âˆ¥_
alternatives. Especially, it has a much better accuracy than PLISA-single. Therefore, this ablation
study has validated the effectiveness of using entry-wise regularization parameters and learning the
penalty function.

I.6 REAL-WORLD EXPERIMENTS

We use the following 3 real-world datasets.

(1) Gene - a single-cell gene expression dataset that contains expression levels of 45 transcription
factors measured at different time-points. We follow Ollier & Viallon (2017) to pick the transcription
factor, EGR2, as the response variable and the other 44 factors as the covariates. In this dataset, each
time-point is considered as an estimation problem. In each estimation problem, the goal is learning
the regression weights Î²[âˆ—] on the 44 factors to predict the expression level of the target transcription
factor, EGR2. Therefore, in this problem, p = 44. This dataset contains the gene expression data for
120 single cells at 8 different time points. For each time point, we randomly split the 120 samples
into 6 sets, so that each set contains 20 samples. By doing this, we construct 48 estimation problems
each of which contains 20 samples. 10 samples are used for recovering the parameters Î²[âˆ—] and the
other 10 samples are used for evaluate it by computing the least-square error. We use 36 problems
for training, 6 problems for validation, and 6 problems for testing.

(2) Parkinsons - a disease dataset that contains symptom scores of Parkinson for different patients.
Each patient is considered as an estimation problem. In each estimation problem, the goal is learning
the regression weights Î²[âˆ—] on 19 bio-medical features to predict the symptom score. This dataset
contains 42 patients, so there are 42 estimation problems in total. Each patient is examined at
different time-point and each time a sample is generated. For each patient we randomly select 100
samples, so that eventually our dataset contains 42 estimation problems each of which contains 100
samples. 50 are used for recovering the parameter Î²[âˆ—] and 50 are used for evaluation. We use 28
problems for training, 7 problems for validation, and 7 problems for testing.

(3) School - an examination score dataset of students from 139 secondary schools in London. Each
school is considered as an estimation problem. In each estimation problem, the goal is learning the
regression weights Î²[âˆ—] on 28-dimensional school and student features to present the exam scores
for all students. We use the dataset from Malsar package (Zhou et al., 2011). For each school, we
randomly select 40 students as the samples. Since some schools contain less than 40 students, we
finally obtain 125 estimation problems (schools) each of wich contains 40 samples. 20 are used for


-----

recovering the parameter Î²[âˆ—] and 20 are used for evaluation. We use 100 problems for training, 10
problems for validation, and 15 problems for testing.

On each dataset, we train each learning-based algorithm for 200 epochs using Adam with learning
rata 1e-3. The batch size is set to be 6.


-----

