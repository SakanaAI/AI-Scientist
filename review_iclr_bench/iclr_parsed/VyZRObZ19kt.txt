# LEARNED INDEX WITH DYNAMIC Ïµ

**Anonymous authors**
Paper under double-blind review

ABSTRACT

Index structure is a fundamental component in database and facilitates broad data
retrieval applications. Recent learned index methods show superior performance
by learning hidden yet useful data distribution with the help of machine learning,
and provide a guarantee that the prediction error is no more than a pre-defined
_Ïµ. However, existing learned index methods adopt a fixed Ïµ for all the learned_
segments, neglecting the diverse characteristics of different data localities. In
this paper, we propose a mathematically-grounded learned index framework with
dynamic Ïµ, which is efficient and pluggable to existing learned index methods. We
theoretically analyze prediction error bounds that link Ïµ with data characteristics
for an illustrative learned index method. Under the guidance of the derived bounds,
we learn how to vary Ïµ and improve the index performance with a better space-time
trade-off. Experiments with real-world datasets and several state-of-the-art methods
demonstrate the efficiency, effectiveness and usability of the proposed framework.

1 INTRODUCTION

Data indexing (Graefe & Kuno, 2011; Wang et al., 2018; Luo & Carey, 2020; Zhou et al., 2020), which
stores keys and corresponding payloads with designed structures, supports efficient query operations
over data and benefits various data retrieval applications. Recently, Machine Learning (ML) models
have been incorporated into the design of index structure, leading to substantial improvements in
terms of both storage space and querying efficiency (Kipf et al., 2019; Ferragina & Vinciguerra, 2020a;
Mitzenmacher, 2018; Vaidya et al., 2021). The key insight behind this trending topic of â€œlearned
indexâ€ is that the data to be indexed contain useful distribution information and such information can
be utilized by trainable ML models that map the keys to their stored positions. State-of-the-art learned
index methods (Galakatos et al., 2019; Kipf et al., 2020; Ferragina & Vinciguerra, 2020b; Ferragina
et al., 2020) adopt piece-wise linear segments to approximate the data distribution and introduce an
important pre-defined parameter Ïµ. These methods ensure that the maximal prediction error of each
learned segment is no more than Ïµ and provide a worst-case guarantee of querying efficiency.

By tuning Ïµ, various space-time preferences from users can be met. For example, a relatively large Ïµ
can result in a small index size while having large prediction errors, and on the other hand, a relatively
small Ïµ provides with small prediction errors while having more learned segments and thus a large
index size. However, existing learned index methods implicitly assume that the whole dataset to be
indexed contains the same characteristics for different localities and thus adopt the same Ïµ for all the
learned segments, leading to sub-optimal index performance. More importantly, the impact of Ïµ on
index performance is intrinsically linked to data characteristics, which are not fully explored and
utilized by existing learned index methods.

Motivated by these, in this paper, we theoretically analyze the impact of Ïµ on index performance,
and link the characteristics of data localities with the dynamic adjustments of Ïµ. Based on the
derived theoretical results, we propose an efficient and pluggable learned index framework that
dynamically adjusts Ïµ in a principled way. To be specific, under the setting of an illustrative learned
index method MET (Ferragina et al., 2020), we present novel analysis about the prediction error
bounds of each segment that link Ïµ with the mean and variance of data localities. The segment-wise
prediction error embeds the space-error trade-off as it is the product of the number of covered keys
and mean absolute error, which determine the index size and preciseness respectively. The derived
mathematical relationships enable our framework to fully explore diverse data localities with an
_Ïµ-learner module, which learns to predict the impact of Ïµ on the index performance and adaptively_
choose a suitable Ïµ to achieve a better space-time trade-off.


-----

We apply the proposed framework to several state-of-the-art (SOTA) learned index methods, and
conduct a series of experiments on three widely adopted real-world datasets. Comparing with
the original learned index methods with fixed Ïµ, our dynamic Ïµ versions achieve significant index
performance improvements with better space-time trade-offs. We also conduct various experiments
to verify the necessity and effectiveness of the proposed framework, and provide both ablation study
and case study to understand how the proposed framework works.

2 BACKGROUND

2.1 _Ïµ-BOUNDED LEARNED INDEX_

Given a dataset D = {(x, y)|x âˆˆX _, y âˆˆY}, X is the set of keys over a universe U such as reals or_
integers, and Y is the set of positions where the keys and corresponding payloads are stored. The
index such as B[+]-tree (Abel, 1984) aims to build a compact structure to support efficient query
operations over D. Typically, the keys are assumed to be sorted in ascending order to satisfy the
_key-position monotonicity, i.e., for any two keys, xi > xj iff their positions yi > yj, such that the_
range query ( [xlow, xhigh]) can be handled.
_X âˆ©_

Recently, learned index methods (Kraska et al., 2018; Li et al., 2019; Tang et al., 2020; Dai et al., 2020;
Crotty, 2021) leverage ML models to mine useful distribution information from D, and incorporate
such information to boost the index performance. To look up a given key x, the learned index first
predicts position Ë†y using the learned models, and subsequently finds the stored true position y based
on Ë†y with a binary search or exponential search. Thus the querying time consists of the inference
time of the learned models and the search time in O(log(|yË† âˆ’ _y|)). By modeling the data distribution_
information, learned indexes achieve faster query speed than traditional B[+]-tree index, meanwhile
using several orders-of-magnitude smaller storage space (Ding et al., 2020; Galakatos et al., 2019;
Ferragina & Vinciguerra, 2020b; Kipf et al., 2020; Marcus et al., 2020).

Many existing learned index methods adopt piece-wise linear segments to approximate the distribution
of D due to their effectiveness and low computing cost, and introduce the parameter Ïµ to provides a
worst-case preciseness guarantee and a tunable knob to meet various space-time trade-off preferences.
Here we briefly introduce the SOTA Ïµ-bounded learned index methods that are most closely to our
work, and refer to the review chapter of (Ferragina & Vinciguerra, 2020a) for details of other methods.
Specifically, Galakatos et al. (2019) greedily learn a set of piece-wise linear segments in a one-pass
manner. Ferragina & Vinciguerra (2020b) adopt another one-pass algorithm that achieves the optimal
number of learned segments. Kipf et al. (2020) introduce a radix structure to organize the learned
segments. Ferragina et al. (2020) adopt a fixed slope setting for all learned segments. Existing
methods constraint all learned segments with the same Ïµ, i.e., the learning process ensures that the
maximum prediction error is within a pre-defined Ïµ where Ïµ âˆˆ Z>1. In this paper, we will discuss the
impact of Ïµ in more depth and invistigate how to enhance existing learned index methods from a new
perspective: dynamic adjustment of Ïµ considering the diversity of different data localities.

2.2 MEAN EXIT TIME (MET) ALGORITHM

Here we describe an illustrative learned index algorithm MET (Ferragina et al., 2020). Specifically,
for any two consecutive keys ofa random process {Gi}iâˆˆN, where D G, suppose their key intervali is a positive independent and identically distributed (i.i.d.) (xi âˆ’ _xiâˆ’1) is drawn according to_
random variable whose mean is Âµ and variance is Ïƒ[2]. The MET algorithm learns linear segments
**S = [S1, ..., Si, ..., SN** ] in one pass, where Si : y = aix + bi is the learnable linear segment and N is
the total number of learned segments. The learning process is as follows: The current linear segment
fixes the slope ai = 1/Âµ and goes through the first available data point, thus bi is also determined.
Then the segment covers as many data points as possible until a data point, say (x[â€²], y[â€²]) achieves the
prediction error larger than Ïµ. The violation of Ïµ triggers a new linear segment, and the data point
(x[â€²], y[â€²]) will be the first available data point, and the process repeats until no data point is available.
Although the MET algorithm adopts a simple learning mechanism, it makes the theoretical analysis
convenient by modeling the learning process as a random walk process. Other Ïµ-bounded learned
index methods such as FITing-Tree (Galakatos et al., 2019), PGM (Ferragina & Vinciguerra, 2020b)
and Radix-Spline (Kipf et al., 2020) learn linear segments in a similar manner while having different
mechanisms to determine the parameters of _Si_ . Ferragina et al. (2020) reveal the relationship
_{_ _}_


-----

between Ïµ and index size performance based on MET. In Section 3.3, we present novel analysis
about the impact of Ïµ on not only the index size, but also the index preciseness and a comprehensive
_trade-off quantity, which facilitates the proposed dynamic Ïµ adjustment._

3 LEARN TO VARY Ïµ

3.1 PROBLEM FORMULATION AND MOTIVATION

Before introducing the proposed framework, we first formulate the task of learning index from
data with Ïµ guarantee, and provide some discussions about why we need to vary Ïµ. Given a dataset
_D to be indexed and an Ïµ-bounded learned index algorithm A, we aim to learn segments S =_

[S1, ..., Si..., SN ] as index structure such that the size of S and _i=1_ _[MAE][(][D][i][|][S][i][)][ are both small,]_
where Si is the i-th learned linear segment with the parameter Ïµi, MAE is the mean absolute prediction
error, andthe algorithm Di âŠ‚D A repeatedly checks whether the prediction error of new data point violates the given is the data whose keys are covered by Si. For the remaining data[P][N] _D \_ _j<i_ _[D][j][,]_

_Ïµi, and outputs the learned segment Si that covers_ _i. When all the Ïµis for i_ [N ] take the same[S]
_D_ _âˆˆ_
value, the problem becomes the one that existing learned index methods are dealing with.

Now letâ€™s examine the effect of parameter Ïµ. To query a specific data point, say (x, y), we first need to
find the specific segment S[â€²] that covers x, and then search its true position y based on the estimated
one Ë†y = S[â€²](x). For the first step, we can find S[â€²] from S in O(log(N )); for the second step, the
search of y based on Ë†y can be done in O(log(|yË† âˆ’ _y|)). In summary, we can find the true position of_
the queried data point in O(log(N ) + log(|yË† âˆ’ _y|))_ [1]. From here, we can see that the parameter Ïµ
plays an important role to trade off two contradictory performance terms, i.e., the size of the learned
index N, and MAE of the whole data MAE(D|S). If we adopt a small Ïµ, the maximal prediction error
constraint is more frequently violated, leading to a large N ; meanwhile, the preciseness of learned
index is improved, leading to a small MAE(D|S). On the other hand, with a large Ïµ, we will get a
more compact learned index (i.e., a small N ) with larger prediction errors (i.e., a large MAE(D|S)).
Thus these two inversely changed terms jointly impact the querying efficiency.

Actually, the effect of Ïµ on index performance is intrinsically linked to the characteristic of the
data to be indexed. For real-world datasets, an important observation is that the linearity degree
_varies in different data localities. Recall that we use piece-wise linear segments to fit the data, and_
_Ïµ determines the partition and the fitness of the segments. By varying Ïµ, we can adapt to the local_
variations of D and adjust the partition such that each learned segment fits the data better. Formally,
letâ€™s consider the quantity SegErri that is defined as the total prediction error within a segment Si,
_i.e., SegErri =_ (x,y)âˆˆDi

_Len(_ _i) and the mean absolute error[|][y][ âˆ’]_ _[S][i][(][x] MAE[)][|][, which is also the product of the number of covered keys](_ _i_ _Si). Note that a large Len(_ _i) leads to a small N_
_D_ _D_ _|_ _D_
since |D| = _i=1[P][Len][(][D][i][)][. From this view, the quantity][ SegErr][i][ internally reflects the space-error]_
trade-off. Later we will show how to leverage this quantity to dynamically adjust Ïµ.

[P][N]

3.2 OVERALL FRAMEWORK

In practice, it is intractable to directly solve the problem formulated in Section 3.1. With a given Ïµi,
the one-pass algorithm A determines Si and Di until the error bound Ïµi is violated. In other words,
it is unknown what the data partition _i_ will be a priori, which makes it impossible to solve the
_{D_ _}_
problem by searching among all the possible _Ïµi_ s and learning index with a set of given _Ïµi_ .
_{_ _}_ _{_ _}_

In this paper, we investigate how to efficiently find an approximate solution to this problem via the
introduced Ïµ-learner module. Instead of heuristically adjusting Ïµ, the Ïµ-learner learns to predict
the impact of Ïµ on the index structure and adaptively adjusts Ïµ in a principled way. Meanwhile, the
introducing of Ïµ-learner should not sacrifice the efficiency of the original one-pass learned index
algorithms, which is important for real-world practical applications.

These two design considerations establish our dynamic Ïµ framework as shown in Figure 1. The
_Ïµ-learner is based on an estimation function SegErr = f_ (Ïµ, Âµ, Ïƒ) that depicts the mathematical
relationships among Ïµ, SegErri and the characteristics Âµ, Ïƒ of the data to be indexed. As a start, users
can provide an expected ËœÏµ that indicates various preferences under space-sensitive or time-sensitive
applications. To meet the user requirements, afterwards, we will internally transform the ËœÏµ into another

1In Appendix C, we link the absolute prediction error and specific searching algorithms in further details.


-----

|&âˆ’Learner * ", +,,|Expected,-&./00|Expected )(|
|---|---|---|



**User**


**: %-learner Inference**

**: %-learner Learning**

**: Index Learning**


**15** (

**10** '["], ((["], *["]) &âˆ’Learner

**Position** **5** **lookahead** -  ", +,,

**choose "$**

**0**

**10** **20** **Key** **30** **update**

**15** [,!, 2!]

**: Learned Segments: Data Points** **Position** **105** "$ **reward**,-./00((, *) !

**: M&'|) âˆ’+)|** **0** "+

**10** **20** **30**

**Key**


Figure 1: Dynamic Ïµ framework with the Ïµ-learner module.

proxy quantity _SegErr[^]_, which reflects the expected prediction error for each segment if we set Ïµi = ËœÏµ.
This transformation also links the adjustment of Ïµ and data characteristics together, which enables the
data-dependent adjustment of Ïµ. Beginning with ËœÏµ, the Ïµ-learner chooses a suitable Ïµi according to
current data characteristics, then learn a segment Si using A, and finally enhance the Ïµ-learner with
the rewarded ground-truth SegErri of each segment. To make the introduced adjustment efficient,
we propose to only sample a small Look-ahead data D[â€²] to estimate the characteristics (i.e., Âµ and Ïƒ)
of the following data locality. The learning and adjusting processes are repeatedly conducted and
also in an efficient one-pass manner.

Note that the proposed framework provides users the same interface as the ones used by original
learned index methods. That is, we add no any additional cost to the usersâ€™ experience, and users
can smoothly and painlessly use our framework with given ËœÏµ just as they use the original methods
with given Ïµ. The Ïµ is an intuitive, easy-to-set and method-agnostic quantity for users. On the one
hand, we can easily impose restrictions on the worst-case querying cases with Ïµ as the data accessing
number in querying process is O(log(|yË† âˆ’ _y|)). On the other hand, Ïµ is easier to estimate than the_
other quantities such as index size and querying time, which are dependent on specific algorithms,
data layouts, implementations and experimental platforms. Our pluggable framework retains the
benefits of existing learned index methods, such as the aforementioned usability of Ïµ and the ability
to handle dynamic update case (Galakatos et al., 2019; Ferragina & Vinciguerra, 2020b).

We have seen how Ïµ determines index performance and how SegErri embeds the space-error tradeoff in Section 3.1. In Section 3.3, we will further theoretically analyze the relationship among Ïµ,
_SegErri, and data characteristics Âµ, Ïƒ at different localities. Based on the analysis, we elaborate the_
details of Ïµ-learner and the internal transformation between Ïµ and SegErri in Section 3.4.


3.3 PREDICTION ERROR ESTIMATION

In this section, we will theoretically study the impact of Ïµ on the prediction error SegErri of each
learned segment Si. Specifically, for the MET algorithm, we can prove the following theorem to
bound the expectation of SegErri with Ïµ and the key interval distribution of the data to be indexed.
**Theorem 1. Given a dataset D to be indexed and an Ïµ where Ïµ âˆˆ** Z>1, consider the setting of the
_MET algorithm (Ferragina et al., 2020), in which key intervals of D are drawn from a random process_
_consisting of positive i.i.d. random variables with mean Âµ and variance Ïƒ[2], and Ïµ â‰«_ _Ïƒ/Âµ. For a_
_learned segment Si and its covered data_ _i, denote SegErri =_ (x,y) _Di_
_D_ _âˆˆ_

_expectation of SegErri satisfies:_ _[|][y][ âˆ’]_ _[S][i][(][x][)][|][. Then the]_

1 _Âµ_ 2 3 [P]

4 ( _[Âµ]_

_Ï€_ _Ïƒ [Ïµ][2][ <][ E][[][SegErr][i][]][ <][ 2]3_ _Ï€_ [(5]3 [)] _Ïƒ_ [)][2][Ïµ][3][.]

r r

This theorem reveals that the prediction error SegErri depends on both Ïµ and the data characteristics
(Âµ and Ïƒ). Recall that CV = Ïƒ/Âµ is the coefficient of variation, a classical statistical measure of
the relative dispersion of data points. In the context of the linear approximation, the data statistic
1/CV = Âµ/Ïƒ in our bounds intrinsically corresponds to the linearity degree of the data. With this, we
can find that when Âµ/Ïƒ is large, the data is easy-to-fit with linear segments, and thus we can choose a
small Ïµ to achieve precise predictions. On the other hand, when Âµ/Ïƒ is small, it becomes harder to
fit the data using a linear segment, and thus Ïµ should be increased to absorb some non-linear data
localities. In this way, we can make the total prediction error SegErri for different learned segments
consistent and achieve a better space-error trade-off. This analysis also confirms the motivation of


-----

varying Ïµ: The local linearity degrees of the indexed data can be diverse, and we should adjust Ïµ
according to the local characteristic of the data, such that the learned index can fit and leverage the
data distribution better. In the design of the Ïµ-learner module (Section 3.4), we will take the derived
closed-form relationships among SegErri, Ïµ and data statistic Âµ/Ïƒ into account.

In the rest of this section, we provide a proof sketch of this theorem due to the space limitation. For
detailed proof, please refer to our Appendix. The main idea is to model the learning process of linear
approximation with Ïµ guarantee as a random walk process, and consider that the absolute prediction
error of each data point follows folded normal distributions. Specifically, given a learned segment
_Si : y = aix + bi, we can calculate the expectation of SegErri for this segment as:_

(j[âˆ—]âˆ’1) _âˆž_ _nâˆ’1_

E[SegErri] = aiE _Zj_ = ai E _Zj_ Pr(j[âˆ—] = n), (1)

ï£® _|_ _|ï£¹_ ï£® _|_ _|ï£¹_

_j=0_ _n=1_ _j=0_

X X X

whereZj _Ïµ/a Zj is thei_ is the random variable indicating the maximal position when the random walk is within j-th position of a transformed random walkï£° ï£» _{ï£°Zj}jâˆˆN, jï£»[âˆ—]_ = max{j âˆˆ N| âˆ’ _Ïµ/ai â‰¤_
the strip of boundary â‰¤ _}_ _Ïµ/ai, and the last equality is due to the definition of expectation._
_Â±_

Under the MET algorithm setting where ai = 1/Âµ and Ïµ â‰« _Ïƒ/Âµ, we can show that the increments of_
the transformed random walk _Zj_ have zero mean and variance Ïƒ[2], and many steps are necessary to
_{_ _}_
reach the random walk boundary. With the Central Limit Theorem, we can assume the Zj follows
normal distribution with mean Âµzj = 0 and variance Ïƒzj[2] [=][ jÏƒ][2][, and thus][ |][Z][j][|][ follows the folded]
normal distribution with expectation E(|Zj|) = 2/Ï€Ïƒ[âˆš]j. Thus Eq. (1) can be written as

_n_ 1 _n_ 1 _n_ 1

1 _âˆž_ _âˆ’_ _âˆž_ _âˆ’_ p 2 _âˆž_ _âˆ’_

E _Zj_ Pr(j[âˆ—] = n) < [1] E [ _Zj_ ] Pr(j[âˆ—] = n) = _[Ïƒ]_ _j Pr(j[âˆ—]_ = n).

_Âµ_ ï£® _|_ _|ï£¹_ _Âµ_ _|_ _|_ _Âµ_ _Ï€_

_n=1_ _j=0_ _n=1_ _j=0_ r _n=1_ _j=0_

X X X X X X p

ï£° ï£» _Âµ[4]_

Using E[j[âˆ—]] = _[Âµ][2]_

_Ïƒ[2][ Ïµ][2][ and][ V ar][[][j][âˆ—][] = 2]3_ _Ïƒ[4][ Ïµ][4][ as derived in (Ferragina et al., 2020), we get][ E][[(][j][âˆ—][)][2][] =]_

5 _Âµ[4]_ _j=0_ _âˆšj < 23_ _[n][âˆš][n][ and][ E][[][X]_ 34 ] (E[X]) 34, we get the upper bound:
3 _Ïƒ[4][ Ïµ][4][. With the inequality][ P][n][âˆ’][1]_ _â‰¤_

E[SegErri] < [2] 2 _Ïƒ_ 32 ] 2 _Ïƒ_ E[(j[âˆ—])[2]] [3]4 = [2] 2 43 ( _[Âµ]_

3 _Ï€_ _Âµ_ [E][[(][j][âˆ—][)] _â‰¤_ 3[2] _Ï€_ _Âµ_ 3 _Ï€_ [(5]3 [)] _Ïƒ_ [)][2][Ïµ][3][.]

r r r

For the lower bound, applying the triangle inequality into Eq. (1), we can get   E[SegErri] >
1 _âˆž_
_Âµ_ _n=1_ [E][ [][|][Z][|][] Pr(][j][âˆ—] [=][ n][)][, where][ Z][ =][ P]j[n]=0[âˆ’][1] _[Z][j][, and][ Z][ follows the normal distribution since]_
_Zj_ _N_ (0, Ïƒzj[2] [)][. We can prove that][ |][Z][|][ follows the folded normal distribution whose expectation]
P âˆ¼
E[|Z|] > Ïƒ(n âˆ’ 1)/[âˆš]Ï€. Thus the lower bound is:

1 _âˆž_ 1 1

E[SegErri] > [Ïƒ] (n 1) Pr(j[âˆ—] = n) = _[Ïƒ]_

_Âµ_ r _Ï€_ _n=1_ _âˆ’_ _Âµ_ r _Ï€_ [E][ [][j][âˆ—] _[âˆ’]_ [1] =] r _Ï€_ [(] _Ïƒ [Âµ]_ _[Ïµ][2][ âˆ’]_ _[Ïƒ]Âµ_ [)][.]

X


Since Ïµ â‰« _[Ïƒ]Âµ_ [, we can omit the right term] 1/Ï€ Â· Ïƒ/Âµ and finish the proof. Although the derivations

are based on the MET algorithm whose slope is the reciprocal of Âµ, we found that the mathematical

p

forms among Ïµ, Âµ/Ïƒ and SegErri are still applicable to other Ïµ-bounded methods, and further prove
that the learned segment slopes of other methods are close to the reciprocal of expected key intervals
in Appendix. We will empirically show the links between MET and other SOTA Ïµ-bounded methods,
and how effectively the proposed framework works for them on real-world datasets (Section 4.2).

3.4 _Ïµ-LEARNER_


Now given an Ïµ, we have obtained the closed-form bounds of the SegErr in Theorem 1, and both
the upper and lower bounds are in the form of w1( _Ïƒ[Âµ]_ [)][w][2] _[Ïµ][w][3]_ [, where][ w][1][,][2][,][3][ are some coefficients. As]

the concrete values of these coefficients can be different for different datasets and different methods,
we propose to learn the following trainable estimator to make the error prediction preciser:

_SegErr = f_ (Ïµ, Âµ, Ïƒ) =w1( _[Âµ]_

_Ïƒ_ [)][w][2] _[Ïµ][w][3]_ _[,]_

(2)

1 2 3

_s.t._ 4, 1 _w2_ 2, 2 _w3_ 3.

r _Ï€_ _[â‰¤]_ _[w][1][ â‰¤]_ 3[2] r _Ï€_ [(5]3 [)] _â‰¤_ _â‰¤_ _â‰¤_ _â‰¤_


-----

With this learnable estimator, we feed data characteristic Âµ/Ïƒ of the look-ahead data and the trans
formed _SegErr^_ into it and find a suitable Ïµ[âˆ—] as _SegErr/w^_ 1( _Ïƒ[Âµ]_ [)][w][2] 1/w3. We will discuss the

look-ahead data and the transformed _SegErr[^]_ in the following paragraphs. Now letâ€™s discuss the rea- 
sons for how this adjustment can achieve better index performance. Actually, the Ïµ-learner proactively
plans the allocations of the total prediction error indicated by user (i.e., ËœÏµ Â· |D|) and calculates the
tolerated _SegErr[^]_ for the next segment. By adjusting current Ïµ to Ïµ[âˆ—], the following learned segment
can fully utilize the distribution information of the data and achieve better performance in terms of
space-error trade-off. To be specific, when Âµ/Ïƒ is large, the local data has clear linearity, and thus we
can adjust Ïµ to a relatively small value to gain precise predictions; although the number of data points
covered by this segment may decrease and then the number of total segments increases, such cost
paid in terms of space is not larger than the benefit we gain in terms of precise predictions. Similarly,
when Âµ/Ïƒ is small, Ïµ should be adjusted to a relatively large value to lower the learning difficulty and
absorb some non-linear data localities; in this case, we gain in terms of space while paying some
costs in terms of prediction accuracy. The segment-wise adjustment of Ïµ improves the overall index
performance by continually and data-dependently balancing the cost of space and preciseness.

**Look-ahead Data.** To make the training and inference of the Ïµ-learner light-weight, we propose to
look ahead a few data D[â€²] to reflect the characteristics of the following data localities. Specifically,
we leverage a small subset _j<i_
_D[â€²]_ _âŠ‚D \_ _[D][j][ to estimate the value][ Âµ/Ïƒ][ for the following data.]_

In practice, we set the size of to be 404 when learning the first segment as initialization, and

(iâˆ’11) _ijâˆ’=11_ _[Len][(][D][j][)]_ _Â· Ï for the other following segments. Here D[â€²]_ [S] _Ï is a pre-defined parameter_
indicating the percentage that is relative to the average number of covered keys for learned segments,

  P 

considering that the distribution of Âµ/Ïƒ can be quite different to various datasets. As for the first
segment, according to the literature (Kelley, 2007), the sample size 404 can provide a 90% confidence
intervals for a coefficient of variance Ïƒ/Âµ â‰¤ 0.2.

_SegErr^_ **and Optimization.** As aforementioned, taking the user-expected ËœÏµ as input, we aim to
reflect the impact of ËœÏµ with a transformed proxy quantity _SegErr[^]_ such that the Ïµ-learner can choose
suitable Ïµ[âˆ—] to meet usersâ€™ preference while achieving better space-error trade-off. Specifically, we
make the value of _SegErr^_ updatable, and update it to be _SegErr^_ = w1(Ë†Âµ/ÏƒË†)[w][2] _ÏµËœ[w][3]_ once a new
segment is learned, where Ë†Âµ/ÏƒË† is the mean value of all the processed data so far. This strategy enables
us to promptly incorporate both the user preference and the data distribution into the calculation of
_SegErr^_ . As for the optimization of the f (Ïµ, Âµ, Ïƒ), we adopt the projected gradient descent (Calamai
& More, 1987; den Hertog & Roos, 1991) with the parameter constraints in Eq. (2). In this way,Â´
we only need to track a few statistics and learn the Ïµ estimator in an efficient one-pass manner. The
overall adjustment algorithm is summarized in Appendix D.

4 EXPERIMENTS

4.1 EXPERIMENTAL SETTINGS

**Baselines.** We apply our framework into several SOTA Ïµ-bounded learned index methods that use
different mechanisms to determine the parameters of segments _Si_ . Among them, MET (Ferragina
_{_ _}_
et al., 2020) fixes the segment slope as the reciprocal of the expected key interval. FITing-Tree
(Galakatos et al., 2019) and Radix-Spline (Kipf et al., 2020) adopt a greedy shrinking cone algorithm
and a spline interpolating algorithm respectively. PGM (Ferragina & Vinciguerra, 2020b) adopts
a convex hull based algorithm to achieve the minimum number of learned segments. Further
introduction and implementation details can be found in Appendix.

**Datasets.** We use several widely adopted datasets with differing data scales and distributions
(Kraska et al., 2018; Galakatos et al., 2019; Ferragina & Vinciguerra, 2020b; Li et al., 2021). Weblogs
and IoT contain about 715M log entries from a university web server and 26M event entries from
different IoT sensors respectively, in which the keys are both log timestamps. Map dataset contains
location coordinates that are collected around the world from the OpenStreetMap contributors (2017),
and the keys are longitude + 90 Â· latitude of about 1.8M places. Lognormal is a synthetic dataset
whose key intervals follow the lognormal distribution. We generate 20M keys with 40 partitions


-----

having different generation parameters to simulate the varied data characteristics among different
localities. More dataset details and visualization are presented in Appendix F.

**Evaluation Metrics.** We evaluate the index performance in terms of its size, prediction preciseness,
and the total querying time. Specifically, we report the number of learned segments N, the index size
in bytes, the MAE as _|D1_ _|_ (x,y)âˆˆD _[|][y][ âˆ’]_ **[S][(][x][)][|][, and the total querying time per query in ns (][i.e.][, we]**

perform querying operations for all the indexed data, record the total time of getting the payloads

P

given the keys, and report the time that is averaged over all the queries). For a quantitative comparison
w.r.t. the trade-off improvements, we calculate the area under the space-error curve (AUSEC) where
the x-axis and y-axis indicate N and MAE respectively. For AUSEC metric, the smaller, the better.

4.2 OVERALL INDEX PERFORMANCE

**Space-Error Trade-off Improvements.** In Table 1, we summarize the AUSEC improvements in
percentage brought by the proposed framework of all the baseline methods on all the datasets. We
also illustrate the space-error trade-off curves for some cases in Figure 2, where the blue curves
indicate the results achieved by fixed Ïµ version while the red curves are for dynamic Ïµ. Other baselines
and datasets yield similar curves, which we include in Appendix due to the space limitation. From
these results, we can see that the dynamic Ïµ versions of all the baseline methods achieve much better
error-space trade-off (âˆ’16.48% to âˆ’23.57% averaged improvements as smaller AUSEC indicates
better performance), demonstrating the effectiveness and the wide applicability of the proposed
framework. As discussed in previous sections, datasets usually have diverse key distributions at
different data localities, and the proposed framework can data-dependently adjust Ïµ to fully utilize
the distribution information of data localities and thus achieve better index performance in terms
of space-error trade-off. Note that the Map dataset has significant non-linearity caused by spatial
characteristics, and it is hard to fit using linear segments (all baseline methods learn linear segments),
thus relatively small improvements are achieved.

Table 1: The AUSEC relative improvements for learned index methods with dynamic Ïµ.

|Col1|Weblogs IoT Map Lognormal Average|
|---|---|


|MET FITing-Tr Radix-Spli PGM|-25.87% -7.66% -10.89% -21.48% -16.48% ee -31.18% -25.56% -9.30% -28.24% -23.57% ne -28.37% -24.59% -8.77% -31.32% -23.26% -22.42% -25.01% -7.18% -19.58% -18.55%|
|---|---|



Figure 2: The space-error trade-off curves for learned index methods.

Weblogs Dataset IoT Dataset

2520 ðœ–Ìƒ=2 FITing-Tree, Dynamic Îµ 1,6001,4001,200 FITing-Tree, Dynamic Îµ

Index Size (KB) 1050 ðœ–Ìƒ=4 ðœ–Ìƒ=8 ðœ–Ìƒðœ–=16=8 ðœ–=16 ðœ–Ìƒ=32 ðœ–=32 Index Size (KB) 6004002000 ðœ–Ìƒ=32 ðœ–Ìƒ=64ðœ–=64ðœ–Ìƒ=128 ðœ–Ìƒðœ–=256=128 ðœ–=256

Figure 3: Improvements in terms of querying time for learned index methods with dynamic Ïµ.

Weblogs Dataset

30 ðœ–=2

FITing-Tree, Original

25

FITing-Tree, Dynamic Îµ

20 ðœ–Ìƒ=2

15 ðœ–=4

10

Index Size (KB) 50 ðœ–Ìƒ=4 ðœ–Ìƒ=8 ðœ–Ìƒðœ–=16=8 ðœ–=16 ðœ–Ìƒ=32 ðœ–=32

600 700 800 900 1000 1100

Querying Time (ns)

IoT Dataset

2,0001,800 ðœ–=16 FITing-Tree, Original
1,600
1,400 FITing-Tree, Dynamic Îµ
1,200
1,000800 ðœ–Ìƒ=16 ðœ–=32

Index Size (KB) 600400 ðœ–Ìƒ=32 ðœ–=64 ðœ–=128

2000 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–Ìƒ=256 ðœ–=256

1100 1200 1300 1400 1500 1600 1700 1800

Querying Time (ns)


**Querying Time Improvements.** Recall that the querying time of each data point is in O(log(N ) +

log(|y âˆ’ _yË†|) as we mentioned in Section 3.1, where N and |y âˆ’_ _yË†| are inversely impacted by Ïµ. To_
examine whether the performance improvements w.r.t. space-error trade-off (i.e., Table 1) can lead
to better querying efficiency in real-world systems, we show the averaged total querying time per


-----

query and the actual learned index size in bytes for two scenarios in Figure 3. We can observe that
the dynamic Ïµ versions indeed gain faster querying speed, since we improve both the term N as well
as the term |y âˆ’ _yË†| via adaptive adjustment of Ïµ. The similar conclusion can be drawn from other_
baselines and datasets, and we present their results in Appendix. Another thing to note is that, this
experiment also verifies the usability of our framework in which users can flexibly set the expected ËœÏµ
to meet various space-time preferences just as they set Ïµ in the original learned index methods.

**Index Building Cost.** Comparing with the original learned index methods that adopt a fixed Ïµ, our
framework introduces extra computation to dynamically adjust Ïµ in the index building stage. Does
this affect the efficiency of original learned index methods? Here we report the relative increments of
building times in Table 2. From it, we can observe that the proposed dynamic Ïµ framework achieves
comparable building times to all the original learned index methods on all the datasets, showing the
efficiency of our framework since it has the same complexity as the original methods (both in O(|D|)).
Also note that we only need to pay this extra cost once, i.e., building the index once, and then the
index structures can accelerate the frequent data querying operations for real-world applications.

Table 2: Building time increments in percentage for learned index methods with dynamic Ïµ.

|Col1|Weblogs IoT Map Lognormal Average|
|---|---|


|MET FITing-Tree Radix-Spline PGM|10.54% 5.14% 7.55% 5.26% 7.12% 10.7% 1.88% 6.04% 5.23% 5.96% 10.19% 1.64% 3.56% 8.96% 6.09% 16.76% 2.2% 1.07% 21.29% 10.33%|
|---|---|



4.3 ABLATION STUDY OF DYNAMIC Ïµ

To gain further insights about how the proposed dynamic Ïµ framework works, we compare the
proposed one with three dynamic Ïµ variants: (1) Random Ïµ is a vanilla version that randomly choose
_Ïµ from [0, 2ËœÏµ] when learning each new segment; (2) Polynomial Learner differs our framework with_
another polynomial function SegErr(Ïµ) = Î¸1Ïµ[Î¸][2] where Î¸1 and Î¸2 are trainable parameters; (3) Least
_Square Learner differs our framework with an optimal (but very costly) strategy to learn f_ (Ïµ, Âµ, Ïƒ)
with the least square regression.

Table 3: The AUSEC relative changes of dynamic Ïµ variants compared to the proposed framework.

|Col1|Weblogs IoT Map Lognormal Average|
|---|---|


|Random Ïµ Polynomial Learner Least Square Learner|+70.94% +68.19% +51.73% +73.38% +66.06% +49.32% +40.57% +7.29% +42.77% +34.99% +4.44% +9.32% +2.20% 17.63% 0.42% âˆ’ âˆ’|
|---|---|



We summarize the AUSEC changes in percentage compared to the proposed framework in Table 3.
Here we only report the results for FITing-Tree due to the space limitation and similar results can
be observed for other methods. Recall that for AUSEC, the smaller, the better. From this table, we
have the following observations: (1) The Random Ïµ version achieves much worse results than the
proposed dynamic Ïµ framework, showing the necessity and effectiveness of learning the impact of
_Ïµ. (2) The Polynomial Learner achieves better results than the Random Ïµ version while still have a_
large performance gap compared to our proposed framework. This indicates the usefulness of the
derived theoretical results that link the index performance, the Ïµ and the data characteristics together.
(3) For the Least Square Learner, we can see that it achieves similar AUSEC results compared with
the proposed framework. However, it has higher computational complexity and pays the cost of much
larger building times, e.g., 14Ã— and 50Ã— longer building times on IoT and Map respectively. These
results demonstrate the effectiveness and efficiency of the proposed framework that adjusts Ïµ based
on the theoretical results, which will be validated next.

4.4 THEORETICAL RESULTS VALIDATION

We study the impact of Ïµ on SegErri for the MET algorithm in Theorem 1, where the derivations
are based on the setting of the slope condition ai = 1/Âµ. To confirm that the proposed framework
also works well with other Ïµ-bounded learned index methods, we analyze the learned slopes of other
_Ïµ-bounded methods in Appendix. In summary, we prove that for a segment Si : y = aix + bi whose_


-----

**2**

**1**

**0**

|Ã—103 Ma a= 1/Âµ|ap Dataset|
|---|---|
|ai = 1/Âµi FITing-T RadixSpli PGM|ree ne|
|||


**_ai = 1/Âµi_**
**FITing-Tree**
**RadixSpline**
**PGM**


**0** **1** **2** **3** **4**

**1/Âµi** **_Ã—10[3]_**

Figure 4: Learned slopes.




**Lognormal Âµ = 1 Ïƒ = 0.5** **Lognormal Âµ = 1 Ïƒ = 1**

**45** **40**
**40** **MET Upper BoundMET** **PGMRadixSpline** **35** **MET Upper BoundMET** **PGMRadixSpline**
**35** **MET Lower Bound** **FITing-Tree** **30** **MET Lower Bound** **FITing-Tree**
**30** **25**
**25**

**20**

**20**

**Log(SegErr)** **1510** **Log(SegErr)** **1510**

**5** **5**
**0** **0**

**100** **200** **300** **400** **100** **200** **300** **400**

**_Ïµ_** **_Ïµ_**


Figure 5: Illustration of the derived bounds.


covered data is Di and the expected key interval of Di is Âµi, then ai concentrates on 1/Âµi within
2Ïµ/(E[Len(Di)] âˆ’ 1) relative deviations. Here we plot the learned slopes of baseline learned index
methods in Figure 4. We can see that the learned slopes of other methods indeed center along the line
_ai = 1/Âµi, showing the close connections among these methods and confirming that the proposed_
framework can work well with other Ïµ-bounded learned index methods.

We further compare the theoretical bounds with the actual SegErri for all the adopted learned
index methods. In Figure 5, we only show the results on Lognormal dataset due to space limitation.
As expected, we can see that the MET method has the actual SegErri within the derived bounds,
verifying the correctness of the Theorem 1. Besides, the other Ïµ-bounded methods show the same
trends with the MET method, providing the evidence that these methods have the same mathematical
forms as we derived, and thus the Ïµ-learner also works well with them.

4.5 CASE STUDY


We visualize the partial learned segments for FITing-Tree with
fixed and dynamic Ïµ on IoT dataset in Figure 6, where the N and
_SegErri indicates the number of learned segments and the_
total prediction error for the shown segments respectively. The
P
_âˆ’Âµ/Ïƒâˆ’â†’ indicates the characteristics of covered data_ _i_ . We can
_{D_ _}_
see that our dynamic framework helps the learned index gain
both smaller space (7 v.s. 4) and smaller total prediction errors
(48017 v.s. 29854). Note that Ïµs within _â†’[âˆ’]Ïµi are diverse due to the_
diverse linearity of different data localities: For the data whose
positions are within about [30000, 30600] and [34700, 35000],
the proposed framework chooses large Ïµs as their Âµ/Ïƒs are small,
and by doing so, it achieves smaller N than the fixed version by
absorbing these non-linear localities; For the data at the middle Figure 6: Visualization of the
part, they have clear linearity with large Âµ/Ïƒs, and thus the learned index (partial) on IoT for
proposed framework adjusts Ïµ as 19 and 10 that are smaller than FITing-Tree with fixed Ïµ = 32 and
32 to achieve better precision. These experimental observations dynamic version ( ËœÏµ = 32).
are consistent with our analysis in the paragraph under Eq. (2),
and clearly confirm that the proposed framework adaptively adjusts Ïµ based on data characteristics.

5 CONCLUSIONS


Existing learned index methods introduce an important hyper-parameter Ïµ to provide a worst-case
preciseness guarantee and meet various space-time user preferences. In this paper, we provide formal
analyses about the relationships among Ïµ, data local characteristics and the introduced quantity
_SegErri for each learned segment, which is the product of the number of covered keys and MAE,_
and thus embeds the space-error trade-off. Based on the derived mathematical relationships, we
present a pluggable dynamic Ïµ framework that leverages an Ïµ-learner to data-dependently adjust Ïµ and
achieve better index performance in terms of space-error trade-off. A series of experiments verify the
effectiveness, efficiency and usability of the proposed framework.

We believe that our work contributes a deeper understanding of how the Ïµ impacts the index performance, and enlightens the exploration of fine-grained trade-off adjustments by considering data local
characteristics. Our study also opens several interesting future works. For example, we can apply the
proposed framework to other problems in which the piece-wise approximation algorithms with fixed
_Ïµ are used while still requiring space-error trade-off, such as similarity search and lossy compression_
for time series data (Chen et al., 2007; Xie et al., 2014; Buragohain et al., 2007; Oâ€™Rourke, 1981).


-----

REPRODUCIBILITY STATEMENT

For the Theorem 1 presented in Section 3.3, we give a complete proof in Appendix A. We introduce
more implementation details of our method and baselines in Appendix E. More detailed description
of the adopted datasets is included in Appendix F. To facilitate the reproducibitlity, we share
downloadable source codes and IPython notebooks, and attach binary files of the public experimental
datasets in the anonymous link [2].

REFERENCES

David J Abel. A B+-tree structure for large quadtrees. Computer Vision, Graphics, and Image
_Processing, 27(1):19â€“31, 1984._

[Timo Bingmann. Stx b+ tree. https://panthema.net/2007/stx-btree/, 2013.](https://panthema.net/2007/stx-btree/)

Chiranjeeb Buragohain, Nisheeth Shrivastava, and Subhash Suri. Space efficient streaming algorithms
for the maximum error histogram. In IEEE 23rd International Conference on Data Engineering,
pp. 1026â€“1035, 2007.

Paul H Calamai and Jorge J More. Projected gradient methods for linearly constrained problems.Â´
_Mathematical programming, 39(1):93â€“116, 1987._

Qiuxia Chen, Lei Chen, Xiang Lian, Yunhao Liu, and Jeffrey Xu Yu. Indexable pla for efficient
similarity search. In Proceedings of the 33rd international conference on Very large data bases, pp.
435â€“446, 2007.

Andrew Crotty. Hist-tree: Those who ignore it are doomed to learn. In 11th Conference on Innovative
_Data Systems Research, 2021._

Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth, Andrea ArpaciDusseau, and Remzi Arpaci-Dusseau. From wisckey to bourbon: A learned index for log-structured
merge trees. In 14th USENIX Symposium on Operating Systems Design and Implementation, pp.
155â€“171, 2020.

Dick den Hertog and Cees Roos. A survey of search directions in interior point methods for linear
programming. Mathematical Programming, 52(1):481â€“509, 1991.

Jialin Ding, Umar Farooq Minhas, Hantian Zhang, Yinan Li, Chi Wang, Badrish Chandramouli,
Johannes Gehrke, Donald Kossmann, and David B. Lomet. Alex: An updatable adaptive learned
index. In Proceedings of the ACM SIGMOD International Conference on Management of Data,
pp. 969â€“984, 2020.

Paolo Ferragina and Giorgio Vinciguerra. Learned data structures. In Recent Trends in Learning
_From Data, pp. 5â€“41. 2020a. doi: 10.1007/978-3-030-43883-8 2._

Paolo Ferragina and Giorgio Vinciguerra. The PGM-Index: A fully-dynamic compressed learned
index with provable worst-case bounds. Proceedings of the VLDB Endowment, 13(8):1162â€“1175,
2020b. ISSN 2150-8097.

Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so effective? In
_International Conference on Machine Learning, pp. 3123â€“3132, 2020._

Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim Kraska. FITingTree: A data-aware index structure. In Proceedings of the International Conference on Management
_of Data, pp. 1189â€“1206, 2019._

Goetz Graefe and Harumi Kuno. Modern b-tree techniques. In 27th International Conference on
_Data Engineering, pp. 1370â€“1373, 2011._

2https://github.com/AnonyMLResearcher/AnonyCodesData/blob/main/Supplemental%20MaterialsICLR22-Paper997.zip


-----

Ken Kelley. Sample size planning for the coefficient of variation from the accuracy in parameter
estimation approach. Behavior Research Methods, 39(4):755â€“766, 2007.

Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter A. Boncz, and Alfons Kemper.
Learned cardinalities: Estimating correlated joins with deep learning. In 9th Biennial Conference
_on Innovative Data Systems Research, 2019._

Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska,
and Thomas Neumann. Radixspline: A single-pass learned index. In Proceedings of the Third
_International Workshop on Exploiting Artificial Intelligence Techniques for Data Management,_
2020.

Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index
structures. In Proceedings of the International Conference on Management of Data, pp. 489â€“504,
2018.

Xin Li, Jingdong Li, and Xiaoling Wang. Aslm: Adaptive single layer model for learned index. In
_International Conference on Database Systems for Advanced Applications, pp. 80â€“95. Springer,_
2019.

Yaliang Li, Daoyuan Chen, Bolin Ding, Kai Zeng, and Jingren Zhou. A pluggable learned index
method via sampling and gap insertion. arXiv preprint arXiv:2101.00808, 2021.

Chen Luo and Michael J Carey. Lsm-based storage techniques: a survey. The VLDB Journal, 29(1):
393â€“418, 2020.

Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra, Alfons Kemper,
Thomas Neumann, and Tim Kraska. Benchmarking learned indexes. Proceedings of the VLDB
_Endowment, 14(1):1â€“13, 2020._

Michael Mitzenmacher. A model for learned bloom filters, and optimizing by sandwiching. In
_Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp._
462â€“471, 2018.

OpenStreetMap contributors. Planet dump retrieved from https://planet.osm.org . https://www.
openstreetmap.org, 2017.

Joseph Oâ€™Rourke. An on-line algorithm for fitting straight lines between data ranges. Communications
_of the ACM, 24(9):574â€“578, 1981._

Jun Rao and Kenneth A. Ross. Cache conscious indexing for decision-support in main memory. In
_Proceedings of the 25th International Conference on Very Large Data Bases, pp. 78â€“89, 1999._

Chuzhe Tang, Youyun Wang, Zhiyuan Dong, Gansen Hu, Zhaoguo Wang, Minjie Wang, and Haibo
Chen. Xindex: a scalable learned index for multicore data storage. In Proceedings of the 25th
_ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp. 308â€“320,_
2020.

Kapil Vaidya, Eric Knorr, Michael Mitzenmacher, and Tim Kraska. Partitioned learned bloom filters.
In International Conference on Learning Representations, 2021.

Jingdong Wang, Ting Zhang, jingkuan song, Nicu Sebe, and Heng Tao Shen. A survey on learning to
hash. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(4):769â€“790, 2018.

Qing Xie, Chaoyi Pang, Xiaofang Zhou, Xiangliang Zhang, and Ke Deng. Maximum error-bounded
piecewise linear representation for online stream approximation. The VLDB journal, 23(6):
915â€“937, 2014.

Xuanhe Zhou, Chengliang Chai, Guoliang Li, and Ji Sun. Database meets artificial intelligence: A
survey. IEEE Transactions on Knowledge and Data Engineering, 2020.


-----

APPENDICES FOR THE SUBMISSION: LEARNED INDEX WITH DYNAMIC Ïµ

A PROOF OF THEOREM 1

Given a learned segment Si : y = aix + bi, denote ci as the stored position of the last covered data
for the (i âˆ’ 1)-th segment (c1 = 0 for the first segment). We can write the expectation of SegErri
for the segment Si as the following form:

(j[âˆ—]âˆ’1)

E[SegErri] = E _aiXj + bi_ (j + ci + 1) _,_

ï£® _j=0_ _|_ _âˆ’_ _|ï£¹_

X

ï£° ï£»

where j[âˆ—] indicates the length of the segment, and Xj indicates the j-th key covered by the segment
_Si. As studied in Ferragina et al. (2020), the linear-approximation problem with Ïµ guarantee can_
be modeled as random walk processes. Specifically, Xj = X0 + _k=0_ _[G][k][ (for][ j][ âˆˆ]_ [Z][>][0][) where]
_Gk is the key increment variable whose mean and variance is Âµ and Ïƒ[2]_ respectively. Denote the
when the random walk is within the strip of boundaryZandj = j[âˆ—] X=j âˆ’ maxj/a{ji âˆˆ + (Nb| âˆ’i âˆ’Ïµ/aci âˆ’i â‰¤1)Z/aj â‰¤i as theÏµ/ai j} as the random variable indicating the maximal position-th position of the transformed random walkÏµ/ai. The expectation can be rewritten as[P][j] _{Zj}jâˆˆN,_
_Â±_


(j[âˆ—]âˆ’1)

_aiXj_ _j + (bi_ _ci_ 1) =aiE
_j=0_ _|_ _âˆ’_ _âˆ’_ _âˆ’_ _|ï£¹_

X

ï£»

=ai


(j[âˆ—]âˆ’1)

_Zj_

ï£® _|_ _|_

_j=0_

X

ï£°


(3)


_âˆž_ _nâˆ’1_

=ai E _Zj_ Pr(j[âˆ—] = n).

ï£® _|_ _|ï£¹_

_n=1_ _j=0_

X X

ï£° ï£»

The last equality in Eq. (3) is due to the definition of expectation. Following the MET algorithm that
the Si goes through the point (X0, Y0 = ci + 1), we get bi = âˆ’aiX0 + ci + 1 and we can rewrite
_Zj as the following form:_


_j>0_
_Z0 = 0,_ _Zj_ = Xj âˆ’ _X0 âˆ’_ _j/ai =_


_k=1_ _Gk âˆ’_ _j/ai =_

X


(Gk 1/ai) = (Wk),
_k=1_ _âˆ’_ _k=1_

X X


where Wk is the walk increment variable of Zj, E[Wk] = Âµ âˆ’ 1/ai and V ar[Wk] = Ïƒ[2]. Under
the MET algorithm setting where ai = 1/Âµ and Îµ â‰« _Ïƒ/Âµ, the transformed random walk {Zj} has_
increments with zero mean and variance Ïƒ[2], and many steps are necessary to reach the random walk
boundary. With the Central Limit Theorem, we can assume that Zj follows the normal distribution
with mean Âµzj and variance Ïƒzj[2] [, and thus][ |][Z][j][|][ follows the folded normal distribution:]

_Zj_ (Âµ 1/ai)j, jÏƒ[2][],
_âˆ¼N_ _âˆ’_

E(|Zj|) = Âµzj[1 âˆ’ 2Î¦( âˆ’ _Âµzj /Ïƒzj)] + Ïƒzj_ 2/Ï€ exp(âˆ’Âµ[2]zj[/][2][Ïƒ]zj[2] [)][,]

where Î¦ is the normal cumulative distribution function. For the MET algorithm,p _ai = 1/Âµ and thus_
the Âµzj = 0, Ïƒzj = Ïƒ[âˆš]j, and E(|Zj|) = 2/Ï€Ïƒ[âˆš]j. Then the Eq. (3) can be written as
p


_nâˆ’1_

_Zj_ Pr(j[âˆ—] = n) < [1]
_|_ _|ï£¹_ _Âµ_
_j=0_

X

ï£»

= _[Ïƒ]_


_nâˆ’1_

E [|Zj|] Pr(j[âˆ—] = n)
_j=0_

X


_n=1_


_n=1_


(4)


_âˆž_ _nâˆ’1_

_n=1_ _j=0_

X X


_j Pr(j[âˆ—]_ = n).


For the inner sum term in Eq. (4), we have ([P][n]j=0[âˆ’][1] _âˆšj) < 23_ _[n][âˆš][n][ since]_

_nâˆ’1_ _j <_ _nâˆ’1_ _j +_ _âˆšn_ _<_ _n_ _âˆšx dx = 2_

_j=0_ _j=0_ 2 Z0 3 _[n][âˆš][n,]_

X p X p


-----

then the result in Eq. (4) becomes


_âˆž_

_n[âˆš]n Pr(j[âˆ—]_ = n)

_n=1_

X


E[SegErri] < [2]

3

= [2]



[3]

= [2] 2 _Ïƒ_ 32 ] = [2] 2 _Ïƒ_ (j[âˆ—])[2][][ 3]4 2 _Ïƒ_ E[(j[âˆ—])[2]] 4,

3 _Ï€_ _Âµ_ [E][[(][j][âˆ—][)] 3 _Ï€_ _Âµ_ [E] _â‰¤_ 3[2] _Ï€_ _Âµ_

r r r

h   

3 [i] 3
where the last inequality holds due to the Jensen inequality E[X 4 ] (E[X]) 4 . Using E[j[âˆ—]] = _[Âµ][2]_
_â‰¤_ _Ïƒ[2][ Ïµ][2]_

_Âµ[4]_ _Âµ[4]_

and V ar[j[âˆ—]] = [2]

3 _Ïƒ[4][ Ïµ][4][ derived in MET algorithm Ferragina et al. (2020), we get][ E][[(][j][âˆ—][)][2][] = 5]3_ _Ïƒ[4][ Ïµ][4][,]_

which yields the following upper bound:


E[SegErri] < [2]


2 3

4 ( _[Âµ]_

_Ï€_ [(5]3 [)] _Ïƒ_ [)][2][Ïµ][3][.]


For the lower bound, applying the triangle inequality into the Eq. (3), we have


_nâˆ’1_

_Zj_ Pr(j[âˆ—] = n) > [1]
_|_ _|ï£¹_ _Âµ_
_j=0_

X

ï£»

= [1]


_âˆž_ _nâˆ’1_

E _Zj_ Pr(j[âˆ—] = n)

ï£®| _|ï£¹_

_n=1_ _j=0_

X X

_âˆž_ ï£° ï£»

E [|Z|] Pr(j[âˆ—] = n),
_n=1_

X


_n=1_


(5)


where Z = _j=0_ _[Z][j][. Since][ Z][j][ âˆ¼]_ _[N]_ [(0][, Ïƒ]zj[2] [)][, the][ Z][ follows the normal distribution:]

_nâˆ’1_ _nâˆ’1_ _nâˆ’1_

[P][n][âˆ’][1]

_Z âˆ¼_ N _ÂµZ = 0, ÏƒZ[2]_ [=] _Ïƒzj[2]_ [+] _rjkÏƒzjÏƒzk_ _,_

_j=0_ _j=0_ _k=0,k=j_

 X X XÌ¸ 

where rjk is the correlation between Zj and Zk. Since ÂµZ = 0, the |Z| follows the folded normal
distribution with E[|Z|] = ÏƒZ 2/Ï€. Since the random walk {Zj} is a process with i.i.d. increments,

the correlation rjk 0. With Ïƒzj = Ïƒ[âˆš]j > 0 and rjk 0, we have
_â‰¥_ p _â‰¥_

2 _nâˆ’1_

E[|Z|] > _Ï€_ _Ïƒzj > Ïƒ_ _n(n âˆ’_ 1)/Ï€ > [Ïƒ][(][n]âˆš[ âˆ’]Ï€ [1)] _,_

r _j=0_

X p

and the result in Eq. (5) becomes:


_nâˆ’1_

E _Zj_ Pr(j[âˆ—] = n)

ï£®| _|ï£¹_

_j=0_

X

_âˆžï£°_ ï£»

(n âˆ’ 1) Pr(j[âˆ—] = n)
_n=1_

X


E[SegErri] > [1]

_Âµ_

_> [Ïƒ]_

_Âµ_

= _[Ïƒ]_

_Âµ_

Since Ïµ â‰« _[Ïƒ]Âµ_ [, we can omit the right term]


_n=1_


1

_Ï€_ [(] _Ïƒ [Âµ]_ _[Ïµ][2][ âˆ’]_ _[Ïƒ]Âµ_ [)][.]


1

_Ï€_ [E][ [][j][âˆ—] _[âˆ’]_ [1] =]


_Ïƒ_
_Âµ_ [and finish the proof.]


B LEARNED SLOPES OF OTHER Ïµ-BOUNDED METHODS

As shown in Theorem 1, we have known how Ïµ impacts the SegErri of each segment learned by
the MET algorithm, where the theoretical derivations largely rely on the slope condition ai = 1/Âµ.
Here we prove that for other Ïµ-bounded methods, the learned slope of each segment (i.e., ai of Si)
concentrates on the reciprocal of the expected key interval as shown in the following Theorem.


-----

**Theorem 2. Given an Ïµ âˆˆ** Z>1 and an Ïµ-bounded learned index algorithm A. For a linear segment
_Si : y = aix + bi learned by A, denote its covered data and the number of covered keys as Di_
_and Len(Di) respectively. Assuming the expected key interval of Di is Âµi, the learned slope ai_
_concentrates on Ëœa = 1/Âµi with bounded relative difference:_

2Ïµ 2Ïµ
(1 _a_ _E[ai]_ (1 + _a._
_âˆ’_ E[Len(Di)] âˆ’ 1 [)Ëœ] _â‰¤_ _â‰¤_ E[Len(Di)] âˆ’ 1 [)Ëœ]


_Proof. For the learned linear segment Si, denote its first predicted position and last predicted position_
as y0[â€²] [and][ y]n[â€²] [respectively, we have its slope][ a][i] [=][ y]xnn[â€²] _[âˆ’]âˆ’[y]x0[â€²]0_ [. Notice that][ y][0][ âˆ’] _[Ïµ][ â‰¤]_ _[y]0[â€²]_ _[â‰¤]_ _[y][0]_ [+][ Ïµ][ and]

_yn_ _Ïµ_ _yn[â€²]_ [+][ Ïµ][ due to the][ Ïµ][ guarantee, we have][ y][n] _n_ 0 [+ 2][Ïµ][ and]
the expectation of âˆ’ _â‰¤_ _[â‰¤]_ _[y][n] ai can be written as_ _[âˆ’]_ _[y][0]_ _[âˆ’]_ [2][Ïµ][ â‰¤] _[y][â€²]_ _[âˆ’]_ _[y][â€²]_ _[â‰¤]_ _[y][n]_ _[âˆ’]_ _[y][0]_

E[ _[y][n][ âˆ’]_ _[y][0][ + 2][Ïµ]_ ] _E[ai] =_ _[y]n[â€²]_ _[âˆ’]_ _[y]0[â€²]_ E[ _[y][n][ âˆ’]_ _[y][0][ + 2][Ïµ]_ ].

_xn_ _x0_ _â‰¤_ _xn_ _x0_ _â‰¤_ _xn_ _x0_
_âˆ’_ _âˆ’_ _âˆ’_

Note that for any learned segment Si whose first covered data is (x0, y0) and last covered data is
(xn, yn), we have E[ _[x]y[n]n[âˆ’][x]y0[0]_ [] =][ Âµ][i][ and thus the inequalities become]

_âˆ’_

1 2Ïµ 1 2Ïµ

] _E[ai]_ ].

_Âµ_ _xn_ _x0_ _â‰¤_ _â‰¤_ _Âµ_ [+][ E][[] _xn_ _x0_

_[âˆ’]_ [E][[] _âˆ’_ _âˆ’_

Since Ëœa = 1/Âµi and E[xn âˆ’ _x0] = (E[Len(Di)] âˆ’_ 1)Âµi, we finish the proof.


The Theorem 2 shows that the relative deviations between learned slope ai and Ëœa are within
2Ïµ/(E[Len(Di)] âˆ’ 1). For the MET and PGM learned index methods, we have the following
corollary that depicts preciser deviations without the expectation term E[Len(Di)].

**Corollary 2.1. For the MET method Ferragina et al. (2020) and the optimal Ïµ-bounded linear**
_approximation method that learns the largest segment length used in PGM Ferragina & Vinciguerra_
_(2020b), the slope relative differences are at O(1/Ïµ)._

_Proof. We note that the segment length of a learned segment is at O(Ïµ[2]) for the MET algorithm,_
which is proved in the Theorem 1 of Ferragina et al. (2020). Since PGM achieves the largest learned
segment length that is larger than the one of the MET algorithm, we finish the proof.

C CONNECTING PREDICTION ERROR WITH SEARCHING STRATEGY

As we mentioned in Section 3.1, we can find the true position of the queried data point in O(log(N )+
log(|yË† âˆ’ _y|)) where N is the number of learned segments and |yË† âˆ’_ _y| is the absolute prediction error._
A binary search or exponential search can be used to finds the stored true position y based on Ë†y. It is
worth noting out that the searching cost in terms of searching range |yË† âˆ’ _y| of binary search strategy_
corresponds to the maximum absolute prediction error Ïµ, whereas the one of exponential search
corresponds to the mean absolute prediction error (MAE). In this paper, we decouple the quantity
_SegErri as the product of Len(Di) and MAE(Di|Si) in the derivation of Theorem 1. Built upon_
the theoretical analysis, we adopt exponential search in experiments to better leverage the predictive
models.

To clarify, letâ€™s consider a learned segment Si with its covered data Di. Denote the absolute prediction
error of k-th data point covered by this segment as Ë†yk _yk_, the maximum absolute prediction error
as Ïµi where | Ë†yk âˆ’ _yk| â‰¤_ _Ïµi for all k âˆˆ_ [len(Di)]. _|_ _âˆ’_ _|_

-  The binary search is conducted within the searching range [ Ë†yk _Ïµi] for each data point_ [3],
thus the mean search range is _k=1_ _len(1Di)_ [2][Ïµ][i][ =][ O][(][Ïµ][i][)][, which is independent of the] Â±

preciseness of the learned segment and an upper bound of MAE( _i_ _Si)._
_D_ _|_

3The lower bound and upper bounds of searching ranges should be constricted to[P][len][(][D][i][)] 0 and len(Di) respectively.
For brevity, we omit the corner cases when comparing these two searching strategies as they both need to handle
the out-of-bounds scenario.


-----

-  The exponential search first finds the searching range where the queried data may present by
centering around the Ë†y, repeatedly doubling the range [yË† Â± 2[q]] where the integer q grows
from 0, and comparing the queried data with the data points at positions Ë†y _Â±_ 2[q]. After finding
the specific range such that adata, an binary search is conducted to find the exact location. In this way, the mean search qk satisfies 2[log(][q][k][)][âˆ’][1] _â‰¤| Ë†yk âˆ’_ _yk| â‰¤_ 2[âŒˆ][log(][q][k][)][âŒ‰] for the k-th
range is _k=1_ _len(1_ _i)_ [(2][âŒˆ][log(][q][k][)][âŒ‰][+1][) =][ O] _MAE(_ _i_ _Si)_, which can be much smaller

_D_ _D_ _|_
than O(Ïµi) especially for strong predictive models and the datasets having clear linearity.

[P][len][(][D][i][)]   

D THE ALGORITHM OF DYNAMIC Ïµ ADJUSTMENT

**_Algorithm Dynamic Ïµ Adjustment with Pluggable Ïµ Learner_**

**_Input: D: Data to be indexed, A: Learned index algorithm, ËœÏµ: Expected Ïµ, Ï: Length percentage_**
_for look-ahead data_

**_Output: S: Learned segments with varied Ïµs_**

_1: initial parameters w1,2,3 of the learned function: f_ (Ïµ, Âµ, Ïƒ) = w1( _Ïƒ[Âµ]_ [)][w][2] _Ïµ[Ëœ][w][3]_

_2: initial mean length of learned segments so far: Len(DS) â†_ 404
_3: S â†_ âˆ…, (Ë†Âµ/ÏƒË†) â† 0

_4: repeat_

_6:5:_ _Ïµ(Âµ/Ïƒ[âˆ—]_ _â†) â†SegErr/w^lookahead1((Ïƒ[Âµ]D[)][w], Len[2]_ 1/w(D3 **_S) Â· Ï)_** _/* adjust Ïµ based on the learner *//* get data statistic */_

_7:_ [Si, Di] â†A(D, Ïµ[âˆ—])  _/* learn new segment Si using adjusted Ïµ[âˆ—]_ _*/_

_8:_ **_S_** **_S_** _i_
_â†_ _âˆªS_

_9:_ _D â†D \ Di, DS â†DS âˆªDi_

_10:_ _Len(DS) â†_ _running-mean_ _Len(DS), Len(Di)_ _/* online update Len(DS) */_

_11:_ (Ë†Âµ/ÏƒË†) _running-mean_ (Ë†Âµ/ÏƒË†), (Âµ/Ïƒ)
_â†_   

_12:_ _w1,2,3_ _optimize(f, Si, SegErri)_ _/* train the learner with ground-truth */_
_â†_   

_13:_ _SegErr^_ _w1(Ë†Âµ/ÏƒË†)[w][2]_ _ÏµËœ[w][3]_
_â†_

_14: until D = âˆ…_

In Section 3.4, we provide detailed description about the initialization and adjustment sub-procedures.
The lookahead() and optimize() are in the Look-ahead Data and _SegErr^_ **and Optimization**
paragraph respectively.

E IMPLEMENTATION DETAILS

All the experiments are conducted on a Linux server with an Intel Xeon Platinum 8163 2.50GHz
CPU. We first introduce more details and the implementation of baseline learned index methods.
_MET (Ferragina et al., 2020) fixes the segment slope as the reciprocal of the expected key interval,_
and goes through the first available data point for each segment. FITing-Tree (Galakatos et al., 2019)
adopts a greedy shrinking cone algorithm and the learned segments are organized with a B[+]-tree.
Here we use the stx::btree (v0.9) implementation (Bingmann, 2013) and set the filling factors of
inner nodes and leaf nodes as 100%, i.e., we adopt the full-paged filling manner. Radix-Spline (Kipf
et al., 2020) adopts a greedy spline interpolating algorithm to learn spline points, and the learned
spline segments are organized with a flat radix table. We set the number of radix bits as r = 16 for
the Radix-Spline method, which means that the leveraged radix table contains 2[16] entries. PGM
(Ferragina & Vinciguerra, 2020b) adopts a convex hull based algorithm to achieve the minimum
number of learned segments, and the segments can be organized with the help of binary search,
CSS-Tree (Rao & Ross, 1999) and recursive structure. Here we implement the recursive version
since it beats the other two variants in terms of indexing performance.

We then describe a few additional details of the proposed framework in terms of the Ïµ-learner
initialization and the hyper-parameter setting. For the w1,2,3 of the Ïµ-learner shown in the Eq. (2), at
the beginning, we learn the first five segments with the Ïµ sequence [ [1]4 _Ïµ,[Ëœ]_ 2[1] _Ïµ,[Ëœ]_ ËœÏµ, 2ËœÏµ, 4ËœÏµ], then track their

rewarded SegErri and update the parameters w1,2,3 using least square regression. We empirically


-----

found that this light-weight initialization leads to better index performance compared to the versions
with random parameter initialization, and it benefits the exploration of diverse Ïµ[âˆ—], i.e., leading to
the larger variance of the dynamic Ïµ sequence [Ïµ1, . . ., Ïµi, . . ., ÏµN ]. As for the hyper-parameter Ï
(described in the Section 3.4), we conduct grid search over Ï âˆˆ [0.1, 0.4, 0.7, 1.0] on Map an IoT
datasets. We found that all the Ïs achieve better space-error trade-off (i.e., smaller AUSEC results)
than the fixed Ïµ versions. Since the setting Ï = 0.4 achieves averagely best results on the two datasets,
we set Ï to be 0.4 for the other datasets.

F DATASET DETAILS


Our framework is verified on several widely adopted datasets having different data scales and
distributions. Weblogs Kraska et al. (2018); Galakatos et al. (2019); Ferragina & Vinciguerra (2020b)
contains about 715M log entries for the requests to a university web server and the keys are log
timestamps. IoT Galakatos et al. (2019); Ferragina & Vinciguerra (2020b) contains about 26M event
entries from different IoT sensors in a building and the keys are recording timestamps. Map dataset
Kraska et al. (2018); Galakatos et al. (2019); Ding et al. (2020); Ferragina & Vinciguerra (2020b); Li
et al. (2021) contains location coordinates of 1.8M places that are collected around the world from
the Open Street Map OpenStreetMap contributors (2017), and the keys are compound by coordinates
as longitude + 90 Â· latitude. Lognormal Ferragina & Vinciguerra (2020b) is a synthetic dataset
whose key intervals follow the lognormal distribution: ln(Gi) âˆ¼N (Âµlg, Ïƒlg[2] [)][. To simulate the varied]
data characteristics among different localities. We generate 20M keys with 40 partitions by setting
_Âµlg = 1 and setting Ïƒlg with a random number within [0.1, 1] for each partition._

We normalize the positions of stored data into the range [0, 1], and thus the key-position distribution
can be modeled as Cumulative Distribution Function (CDF). We plot the CDFs and zoomed-in CDFs
of experimental datasets in Figure 7 and Figure 8 respectively, which intuitively illustrate the diversity
of the adopted datasets.


**Key** **_Ã—10[9]_**

**Weblogs** **IoT** **Map** **Lognormal**

**1.0** **1.0** **1.0** **1.0**

**0.8** **0.8** **0.8** **0.8**

**CDF** **00..64** **CDF** **00..64** **CDF** **00..64** **CDF** **00..64**

**0.2** **0.2** **0.2** **0.2**

**0.0** **0.0** **0.0** **0.0**

**1.450 1.455 1.460 1.465 1.470 1.475 1.480** **1.485 1.490 1.495 1.500 1.505 1.510 1.515** **2000** **3000** **4000** **5000** **0** **1** **2** **3** **4** **5** **6**

**Key** **10[9]** **Key** **10[9]** **Key** **Key** **10[7]**


**Key** **_Ã—10[9]_**


**Key** **_Ã—10[9]_**


**Key**


**Key** **_Ã—10[7]_**

**Key** **_Ã—10[7]_**


Figure 7: CDFs of adopted datasets.


|Col1|Col2|Col3|Col4|Col5|
|---|---|---|---|---|
||||||


**Zoomed-in Map** **Zoomed-in Lognormal**

**0.660** **0.660**

**0.655** **0.655**

**0.650** **CDF** **0.650**

**0.645** **0.645**

**0.640** **0.640**

**3250** **3260** **3270** **3280** **3290** **3300** **3.95** **4.00** **4.05** **4.10**

**Key** **Key** **10[7]**

Figure 8: Zoomed-in CDFs of adopted datasets.


**Zoomed-in Weblogs**

**0.660**

**0.655**

**0.650**

**0.645**

**0.640**

**1.4718** **1.4720** **1.4722** **1.4724**

**Key** **10[9]**


G ADDITIONAL EXPERIMENTAL RESULTS

**Overall Index Performance.** For the space-error trade-off improvements and the actual querying
efficiency improvements brought by the proposed framework, we illustrate more space-error tradeoff curves in Figure 9 and querying time results in Figure 10. Recall that the N -MAE trade-off
curve adequately reflects the index size and querying time: (1) the segment size in bytes and N are
only different by a constant factor, e.g., the size of a segment can be 128bit if it consists of two


-----

double-precision float parameters (slope and intercept); (2) the querying operation can be done in
_O(log(N_ ) + log(|y âˆ’ _yË†|) as we mentioned in Section 3.1, thus a better N_ -MAE trade-off indicates
a better querying efficiency. From these figures, we can see that the dynamic Ïµ versions of all the
baseline methods achieve better space-error trade-off and better querying efficiency, verifying the
effectiveness and the wide applicability of the proposed framework.

Figure 9: The additional space-error trade-off curves for learned index methods.

**Ablation Study.** To examine the necessity and the effectiveness of the proposed framework, in
Section 4.3, we compare the proposed framework with three dynamic Ïµ variants for the FITing-Tree
method. Here we demonstrate the AUSEC relative changes for the Radix-Spline method with the
same three variants in Table 4 and similar conclusions can be drawn.

Table 4: The AUSEC relative changes of dynamic Ïµ variants compared to the Radix-Spline method
with the proposed framework.

|Col1|Weblogs IoT Map Lognormal|
|---|---|


|Random Ïµ omial Learner Square Learner|+81.23% +74.78% +59.20% +83.16% +56.20% +53.28% +7.01% +55.01% -9.56% +9.81% +0.58% 11.23% âˆ’|
|---|---|



**Theoretical Validation.** In Section 4.4, we show that all the learned index baseline methods learn
similar segment slopes on the Map dataset. Here we illustrate the learned slope results on the IoT,
Weblogs and Lognormal datasets in Figure 11, which supports the Theorem 2 that the learned segment
slopes concentrate on the 1/Âµi with a bounded relative difference.


-----

Besides, for the comparison between the theoretical bounds and the actual SegErri of all the adopted
learned index methods, we show more results on another two datasets Gamma and Uniform in Figure
12, where the key intervals of the two datasets follow gamma distribution and uniform distribution
respectively. These results show that the MET method gains actual SegErri within the bounds,
verifying the correctness of the Theorem 1 again. Here all the learned index methods also achieve the
same trends, showing that these methods have the same mathematical forms w.r.t. the SegErri, Ïµ
and Âµ/Ïƒ, and hence the Ïµ-learner can effectively learn the estimator and adaptively choose suitable Ïµ.

Weblogs Dataset 2,100 IoT Dataset

Index Size (KB) 544 ðœ–Ìƒ=8 ðœ–Ìƒ=16ðœ–=8ðœ–Ìƒ=32 ðœ–=16ðœ–=32 Index Size (KB) 700500300100 ðœ–Ìƒ=32 ðœ–Ìƒ=64 ðœ–=64ðœ–Ìƒ=128 ðœ–=128ðœ–Ìƒ=256 ðœ–=256

Index Size (KB) 1801308030 ðœ–Ìƒ=32 ðœ–Ìƒ=64 ðœ–Ìƒ=128ðœ–=64ðœ–=128ðœ–Ìƒ=256 ðœ–=256 Index Size (KB) 4003002001000 ðœ–Ìƒ=32 ðœ–=32ðœ–Ìƒ=64 ðœ–=64ðœ–Ìƒ=128 ðœ–=128ðœ–Ìƒ=256 ðœ–=256

1200 1250 1300 1350 1400 1250 1350 1450 1550 1650 1750

Weblogs Dataset IoT Dataset

1,001996 ðœ–Ìƒ=2 ðœ–=4 Radix-Spline, Dynamic Îµ 1,7001,500 ðœ–Ìƒ=16 ðœ–=32 Radix-Spline, Dynamic Îµ

500 600 700 800 900 1000 1100 700 900 1100 1300 1500 1700

Weblogs Dataset IoT Dataset

20 ðœ–Ìƒ=64ðœ–Ìƒ=128ðœ–=64ðœ–ðœ–Ìƒ=128=256 ðœ–=256 14040 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–=128ðœ–Ìƒ=256 ðœ–=256

Index Size (KB) 503010950 ðœ–Ìƒ=32ðœ–Ìƒ=128ðœ–Ìƒ=641000 ðœ–ðœ–=128=641050 ðœ–Ìƒ=256 1100ðœ–=256 1150 Index Size (KB) 1015111000 ðœ–Ìƒ=321100 ðœ–Ìƒ=64ðœ–=321200ðœ–Ìƒðœ–=128=641300 ðœ–=1281400 ðœ–Ìƒ=2561500ðœ–=2561600

Querying Time (ns) Querying Time (ns)

Weblogs Dataset

204 ðœ–Ìƒ=2 ðœ–=2

154

104 ðœ–Ìƒ=4 ðœ–=4 MET, OriginalMET, Dynamic Îµ

Index Size (KB) 54 ðœ–Ìƒ=8 ðœ–=8 ðœ–=16

4 ðœ–Ìƒ=16 ðœ–Ìƒ=32 ðœ–=32

1000 1100 1200 1300 1400 1500 1600

Querying Time (ns)

Map Dataset

380 ðœ–=16

330 ðœ–Ìƒ=16

280 MET, Original

230 ðœ–=32 MET, Dynamic Îµ

Index Size (KB) 180130 ðœ–Ìƒ=32 ðœ–=64

8030 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–=128ðœ–Ìƒ=256 ðœ–=256

1200 1250 1300 1350 1400

Querying Time (ns)

Weblogs Dataset

1,006 ðœ–=2 Radix-Spline, Original

Radix-Spline, Dynamic Îµ

1,001 ðœ–Ìƒ=2

996 ðœ–=4

Index Size (KB) 991 ðœ–Ìƒ=4 ðœ–=8 ðœ–=16 ðœ–=32

986 ðœ–Ìƒ=8 ðœ–Ìƒ=16 ðœ–Ìƒ=32

500 600 700 800 900 1000 1100

Querying Time (ns)

Weblogs Dataset

10 ðœ–=16

ðœ–Ìƒ=16

8 PGM, Original

6 PGM, Dynamic Îµ

ðœ–=32

Index Size (KB) 4 ðœ–Ìƒ=32

20 ðœ–Ìƒ=64ðœ–Ìƒ=128ðœ–=64ðœ–ðœ–Ìƒ=128=256 ðœ–=256

650 750 850 950 1050

Querying Time (ns)

Map Dataset

110 ðœ–Ìƒ=16 ðœ–=16

90 PGM, Original

70 ðœ–=32 PGM, Dynamic Îµ

50 ðœ–Ìƒ=32

Index Size (KB) ðœ–=64

30 ðœ–Ìƒ=64

10 ðœ–Ìƒ=128 ðœ–=128 ðœ–Ìƒ=256 ðœ–=256

950 1000 1050 1100 1150

Querying Time (ns)

IoT Dataset

2,100
1,900 ðœ–=16
1,700 ðœ–Ìƒ=16 MET, Original
1,500 MET, Dynamic Îµ
1,300
1,100 ðœ–=32

900

Index Size (KB) 700500 ðœ–Ìƒ=32 ðœ–=64 ðœ–=128

300100 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–Ìƒ=256 ðœ–=256

1400 1500 1600 1700 1800 1900

Querying Time (ns)

1,000900 ðœ–=16 Lognormal Dataset

800 ðœ–Ìƒ=16
700 MET, Original
600 MET, Dynamic Îµ
500
400300 ðœ–=32

Index Size (KB) 2001000 ðœ–Ìƒ=32 ðœ–Ìƒ=64 ðœ–=64ðœ–Ìƒ=128 ðœ–=128ðœ–Ìƒ=256 ðœ–=256

1250 1350 1450 1550 1650 1750

Querying Time (ns)

IoT Dataset

2,100

1,900 ðœ–=16 Radix-Spline, Original

Radix-Spline, Dynamic Îµ

1,700

1,500 ðœ–Ìƒ=16 ðœ–=32

Index Size (KB) 1,3001,100 ðœ–Ìƒ=32 ðœ–=64 ðœ–=128 ðœ–=256

900 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–Ìƒ=256

700 900 1100 1300 1500 1700

Querying Time (ns)

Lognormal Dataset

ðœ–=16

1,540 Radix-Spline, Original

1,440 ðœ–Ìƒ=16 Radix-Spline, Dynamic Îµ

1,340

1,240

Index Size (KB) 1,140 ðœ–=32

1,040 ðœ–Ìƒ=32 ðœ–=64 ðœ–=128 ðœ–=256

940 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–Ìƒ=256

700 800 900 1000 1100 1200 1300 1400 1500 1600

Querying Time (ns)

IoT Dataset

640 ðœ–Ìƒ=16 ðœ–=16

540

PGM, Original

440

340 ðœ–=32 PGM, Dynamic Îµ

Index Size (KB) 240 ðœ–Ìƒ=32 ðœ–=64

14040 ðœ–Ìƒ=64 ðœ–Ìƒ=128 ðœ–=128ðœ–Ìƒ=256 ðœ–=256

1200 1250 1300 1350 1400 1450 1500

Querying Time (ns)

Lognormal Dataset

ðœ–=16

201 ðœ–Ìƒ=16

PGM, Original

151 PGM, Dynamic Îµ

101 ðœ–=32

Index Size (KB) 51 ðœ–Ìƒ=32 ðœ–=64

11000 1100 ðœ–Ìƒ=641200ðœ–Ìƒ=1281300 ðœ–=1281400 ðœ–Ìƒ=2561500ðœ–=2561600

Querying Time (ns)


Figure 10: Improvements in terms of querying time for learned index methods with dynamic Ïµ.


-----

**IoT Dataset** **Weblogs Dataset** **Lognormal Dataset**

**1.0** **_ai = 1/Âµi_** **1.00** **_ai = 1/Âµi_** **_ai = 1/Âµi_**

**FITing-Tree** **FITing-Tree** **0.35** **FITing-Tree**

**0.8** **RadixSpline** **RadixSpline** **RadixSpline**

**_ai_** **0.6** **PGM** **_ai_** **0.95** **PGM** **_ai_** **0.30** **PGM**

**0.90**

**0.4** **0.25**

**0.2** **0.85**

**0.2** **0.4** **0.6** **0.8** **1.0** **0.85** **0.90** **0.95** **1.00** **0.25** **0.30** **0.35**

**1/Âµi** **1/Âµi** **1/Âµi**


Figure 11: Learned slopes on the IoT, Weblogs and Lognormal datasets.





**Gamma, k = 1.0, Î¸ = 1.0** **Gamma, k = 2.0, Î¸ = 3.0** **Gamma, k = 3.0, Î¸ = 6.0**

**40** **40** **40**

**MET Upper Bound** **PGM** **MET Upper Bound** **PGM** **MET Upper Bound** **PGM**

**35** **MET** **RadixSpline** **35** **MET** **RadixSpline** **35** **MET** **RadixSpline**

**MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree**

**30** **30** **30**

**25** **25** **25**

**20** **20** **20**

**15** **15** **15**

**Log(SegErr)** **Log(SegErr)** **Log(SegErr)**

**10** **10** **10**

**5** **5** **5**

**0** **0** **0**

**100** **200** **300** **400** **100** **200** **300** **400** **100** **200** **300** **400**

**_Ïµ_** **_Ïµ_** **_Ïµ_**

**40** **Uniform, low = 0.0, high = 1.0** **40** **Uniform, low = 0.0, high = 10.0** **40Uniform, low = 10.0, high = 100.0**

**MET Upper Bound** **PGM** **MET Upper Bound** **PGM** **MET Upper Bound** **PGM**

**35** **MET** **RadixSpline** **35** **MET** **RadixSpline** **35** **MET** **RadixSpline**

**MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree**

**30** **30** **30**

**25** **25** **25**

**20** **20** **20**

**15** **15** **15**

**Log(SegErr)** **Log(SegErr)** **Log(SegErr)**

**10** **10** **10**

**5** **5** **5**

**0** **0** **0**

**100** **200** **300** **400** **100** **200** **300** **400** **100** **200** **300** **400**

**_Ïµ_** **_Ïµ_** **_Ïµ_**


Figure 12: Illustrations of the derived bounds on Gamma and Uniform datasets.


-----

