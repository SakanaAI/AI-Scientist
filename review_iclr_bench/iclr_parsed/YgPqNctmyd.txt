# TOWARDS BUILDING A GROUP-BASED UNSUPERVISED REPRESENTATION DISENTANGLEMENT FRAMEWORK

**Yang Tao[1][âˆ—], Xuanchi Ren[2]** **, Yuwang Wang[3][â€ ], Wenjun Zeng[4]** **, Nanning Zheng[1]**

1Xiâ€™an Jiaotong University, 2HKUST,, 3Microsoft Research Asia, 4EIT

ABSTRACT

Disentangled representation learning is one of the major goals of deep learning, and
is a key step for achieving explainable and generalizable models. A well-defined
theoretical guarantee still lacks for the VAE-based unsupervised methods, which
are a set of popular methods to achieve unsupervised disentanglement. The Group
Theory based definition of representation disentanglement mathematically connects
the data transformations to the representations using the formalism of group. In
this paper, built on the group-based definition and inspired by the n-th dihedral
_group, we first propose a theoretical framework towards achieving unsupervised_
representation disentanglement. We then propose a model, based on existing VAEbased methods, to tackle the unsupervised learning problem of the framework. In
the theoretical framework, we prove three sufficient conditions on model, group
structure, and data respectively in an effort to achieve, in an unsupervised way,
disentangled representation per group-based definition. With the first two of the
conditions satisfied and a necessary condition derived for the third one, we offer
additional constraints, from the perspective of the group-based definition, for the
existing VAE-based models. Experimentally, we train 1800 models covering the
most prominent VAE-based methods on five datasets to verify the effectiveness
of our theoretical framework. Compared to the original VAE-based methods,
these Groupified VAEs consistently achieve better mean performance with smaller
variances.

1 INTRODUCTION

Learning independent and semantic representations of which individual dimension has interpretable
meaning, usually referred to as disentangled representations learning, is critical for artificial intelligence research (Bengio et al., 2013). Such disentangled representations are useful for many tasks:
domain adaptation (Li et al., 2019; Zou et al., 2020), zero-shot learning (Lake et al., 2017), and
adversarial attacks (Alemi et al., 2016), etc. Intuitively, a disentangled representation should reflect
the factors of variations behind the observed data of the world, and one latent unit is only sensitive to
changes of an individual factor.

Due to the facts that obtaining the ground-truth labels requires significant human effort and humans
can learn those factors unsupervisedly, unsupervised representation disentanglement draws much
attention from researchers recently. A lot of methods are proposed base on some intuitions. Most of
the state-of-the-art methods (Higgins et al., 2017; Burgess et al., 2018; Kim & Mnih, 2018; Chen et al.,
2018; Kumar et al., 2017) are based on Variational Autoencoder (VAE) (Kingma & Welling, 2013).
These methods are fully unsupervised and can be applied to a variety of complex datasets (Lee et al.,
2020). However, these methods suffer from the unidentifiability problem (Locatello et al., 2019b)
due to a lack of theoretical guarantee. Another stream of works (Chen et al., 2016; Lin et al., 2020;
Khrulkov et al., 2021; Lee et al., 2020) leverage generative adversarial network (GAN) (Goodfellow
et al., 2014) to achieve disentanglement but are not interpretable. In general, a well-defined theoretical
guarantee is needed for those methods.

The research of symmetry in physics demonstrates that infinitesimal transformations that conform
to some symmetry groups on physical objects can reflect their nature (Anderson, 1972; Noether,

_âˆ—Work done during internships at Microsoft Research Asia._
_â€ Corresponding author_


-----

1915). Recently, inspired by this research on symmetry, Higgins et al. (2018) proposed a group-based
definition of disentangled representation. They argue that the symmetries, i.e., the transformations that
change certain aspects of data and keep other aspects unchanged, ideally reflect the underlying data
structure. The group-based definition is a formal and rigorous mathematical definition of faithful and,
ideally, interpretable representation of the generative factors of data, which is widely accepted (Greff
et al., 2019; Mathieu et al., 2019; Khemakhem et al., 2020). Subsequently, due to the fact that the
definition is defined by the world state (i.e., Ground Truth) and based on the assumption (CasellesDupre et al., 2019) that this definition should be useful for downstream tasks such as a ReinforcementÂ´
Learning, Caselles-Dupre et al. (2019), Quessard et al. (2020), Painter et al. (2020) proposeÂ´
environment-based (to provide world state) methods to learn such disentangled representations in
Reinforcement Learning settings. These inspire us to ask the following question: how would the
definition benefit unsupervised representation disentanglement, and how to learn such a disentangled
representation conforming to the definition in the setting of unsupervised representation learning?

In Group Theory[1], the n-th dihedral group (Judson, 2020) is a set of all permutations of polygons
vertices, forming a permutation group under the operation of composition (Miller, 1973). The
generators in an n-th dihedral group, i.e., flip and rotation, can be regarded as the disentangled factors
and also transformations. In this paper, inspired by the n-th dihedral group, we answer the above
questions and address the challenge by proposing a theoretical framework to make the definition
practically applicable for unsupervised representation disentanglement. We then propose a model to
tackle the learning problem of the framework and verify its effectiveness. We theoretically prove in
Section 3.2 the three sufficient conditions towards achieving disentangled representation per groupbased definition, which are referred to as model, group structure, and data constraint, respectively.
With these conditions, we offer additional constraints from the perspective of the definition. The
additional constraints encourage existing VAE-based models to satisfy the symmetry requirement
that comes from the nature of factors. Finally, we provide a learning model based on the existing
VAE-based methods in an effort to fulfill the three conditions (with the model and group structure
constraint and a necessary condition for the data constraint satisfied). As an intuitive understanding,
we introduce the additional constraints to reorganize the latent space to restrict its symmetry in an
unsupervised way. These additional constraints indeed narrow down the solution space of VAEbased models. Detailed discussion in Sec. 5.4. Our model consistently achieves statistically better
performance in prominent metrics (higher means and lower variances) than corresponding existing
VAE-based models on five datasets, demonstrating that the group-based definition together with our
proposed framework further encourages disentanglement.

Our main contributions are summarized as follows:

-  To our best knowledge, we are the first to provide a theoretical framework to make the
formal group-based mathematical definition of disentanglement practically applicable to
_unsupervised representation disentanglement._

-  Our theoretical framework provides additional constraints from the perspective of groupbased definition for the existing VAE-based methods.

-  We propose a learning model of the framework by deriving and integrating additional loss
into existing VAE-based models, in an effort to make the learned representation conform to
the group-based definition without relying on the environment (as done in Caselles-DupreÂ´
et al. (2019); Quessard et al. (2020); Painter et al. (2020)).

2 RELATED WORKS

Different definitions have been proposed for disentangled representation (Bengio et al., 2013; Higgins
et al., 2018; Suter et al., 2019). However, only the group-based definition proposed by Higgins et al.
(2018) focuses on the disentangled representation itself and is mathematically rigorous, which is well
accepted (Caselles-Dupre et al., 2019; Quessard et al., 2020; Painter et al., 2020; Diane Bouchacourt,Â´
2021). Nevertheless, Higgins et al. (2018) do not propose a specific learning method based on their
definition. Before this rigorous definition was proposed, there had been some success in identifying
generative factors in static datasets (without interaction with environment), e.g., Î²-VAE (Higgins et al.,

1We assume some basic familiarity with the fundamentals of Group Theory and Group Representation
Theory. Please refer to Appendix A for some basic concepts.


-----

2017), Anneal-VAE (Burgess et al., 2018), Î²-TCVAE (Chen et al., 2018), and FactorVAE (Kim &
Mnih, 2018). More recent works (Srivastava et al., 2020; Shao et al., 2020; Kim et al., 2019; Lezama,
2018; Rezende & Viola, 2018) also do not consider the group-based definition. Therefore, how
group-based definition will facilitate these methods is still an open question. Besides, all these works
suffer from the unidentifiability problem (Locatello et al., 2019b), which is a challenging problem
in this literature. From group-based definition, our framework points out that, the unidentifiability
problem could be solved once the data constraint is satisfied. However, in this work, we can only get
a necessary condition for data constraint, and we still can not solve this challenging problem.

As pointed out in Quessard et al. (2020), it is not straightforward to reconcile the probabilistic inference methods with the group-based definition framework. Caselles-Dupre et al. (2019), QuessardÂ´
et al. (2020), Painter et al. (2020) leverage the interaction with the environment (assuming it is
available) as supervision instead of minimizing the total correlation as the VAE-based methods do.
Consequently, the effectiveness of these methods is limited to the datasets with the environment
available. Our framework learns a representation conforming to the group-based definition without
_relying on the environment. Pfau et al. (2020) propose a non-parametric method to unsupervisedly_
learn linear disentangled planes in data manifold under a metric. However, as pointed out by the authors, the method does not generalize to held-out data and performs poorly when trying to disentangle
directly from pixels.

To summarize, the existing probabilistic inference methods lack theoretical support, while the
application scope of existing methods based on the group-based mathematical definition Higgins
et al. (2018) is very limited. To the best of our knowledge, our work is the first to reconcile the
_probabilistic generative methods with the inherently deterministic group-based definition framework_
_of Higgins et al. (2018)._

3 THE GROUP-BASED FRAMEWORK FOR UNSUPERVISED REPRESENTATION
DISENTANGLEMENT

Our goal is to explore the benefit of the group-based definition for unsupervised representation
disentanglement and learn such a disentangled representation. The background of the group-based
definition is provided in Section 3.1. Section 3.2 presents the theoretical framework towards achieving
_unsupervised disentanglement, in which we derive three sufficient conditions on the model, group_
structure, and data, respectively. The conditions on the model and group structure provide additional
constraints for the existing VAE-based models.

3.1 GROUP-BASED DEFINITION

We briefly review the group-based definition of disentangled representation Higgins et al. (2018).
Considering a group G acting on world state space W (can be understood as ground-truth) of data
space O and representation space Z via group action Â·W and group action Â·Z respectively. For a
mapping f = b â—¦ _h, where b and h denote the data generative process and encoding, we state: the_
mapping f is equivariant between the actions on W and Z if
_g Â· f_ (w) = f (g Â· w), âˆ€g âˆˆ _G, âˆ€w âˆˆ_ _W._ (1)

**Definition 1with respect to Assume G if: ( Gi) group action can be decomposed as of G on Z G exits. = G (1ii Ã—) G the mapping2 Ã— Â· Â· Â· Ã— G fm is equivariant between the. The set Z is disentangled**
_actions onaffected only by the corresponding W and Z. (iii) There is a decomposition Gi._ _Z = Z1 Ã— Z2 Ã— Â· Â· Â· Ã— Zm such that each Zi is_

It is challenging to apply the group-based definition to an unsupervised disentanglement setting in
practice because the definition refers to the world state space W, the group action of G on W, and
mapping b which are typically inaccessible in practice. We tackle the challenge by re-framing the
definition in a new framework in the following section.

3.2 PROPOSED THEORETICAL FRAMEWORK

Since when the representation is disentangled, one latent unit in the representation space is only
sensitive to changes of an individual generative factor, we make the following assumptions: G


-----

is a direct product of m cyclic groups (as suggested by Higgins et al. (2018) and for simplicity):
_G = (Z/nZ)[m]_ = Z/nZ Ã— Z/nZ Ã— Â· Â· Â· Ã— Z/nZ, where n is the assumed total number of possible
values for a factor and m is the total number of factors; we further assume Z is a set with the same
elements in G. Therefore, the group actions of G on Z can be set to be element-wise addition, i.e.,
_g Â· z = g + z, âˆ€z âˆˆ_ _Z, g âˆˆ_ _G. For the generator of dimension i of G, gi = (0, . . ., 1, . . ., 0), gi_
only affects the i-th dimension of z by gi + z. In addition, the action of each generator gi on w only
affects a single dimension of w.

As we can seen from Equation 1 above, the group action is defined on w, which is often not accessible,
making it difficult to apply the definition in practice. Therefore, for the unsupervised setting, we
would like to use permutations on the data space O (which only provides data without labels) to
substitute the group actions on W . Specifically, inspired by the n-th dihedral group (Dummit &
Foote, 1991), we construct a permutation group Î¦, serving the role of an â€œagentâ€ of G. The actions
of G on W can be performed by Ï†g Î¦ on O, which can be formulated as
_âˆˆ_

_f_ (g _w) = h(Ï†g_ _b(w)) = h(Ï†g_ _o),_ _w_ _W, g_ _G,_ (2)
_Â·_ _Â·_ _Â·_ _âˆ€_ _âˆˆ_ _âˆˆ_

where o denotes the data (e.g., image) corresponding to the world state w through the mapping
function b. If the above equation holds, we state that the â€œagentâ€ permutation group Î¦ exists. We first
give the conditions for the existence of this â€œagentâ€ permutation group Î¦, then derive the additional
condition to achieve such disentanglement. We accomplish these two objectives in Theorem 1 with
the proof provided in Appendix B. Theorem 1 states that a general permutation group Î¦ on O can
serve as an agent group (agent group exists) if and only if both (i) and (ii) are satisfied. If the agent
group exists, and its permutations (actions on O) can be defined by an autoencoder-like model as
shown in the equation in (iii), then Z is disentangled with respect to G.

**Theorem 1 For the group G = (Z/nZ)[m], a permutation group Î¦ on O, a representation space Z,**
_a World State space W_ _, and mapping b and h, Equation 2 holds if and only if (i) Î¦ is isomorphic to_
_G, and (ii) For each generator of dimension i of G, gi, there exists a Ï†i_ Î¦, i = 1, . . ., m, such
(thatiii Ï†) Ï†i Â·g b( bw(w) =) = b( hg[âˆ’]i Â·[1] w(g), f âˆ€(ww âˆˆ)) _Ww, andW, Ï† Ï†i is a generator ofg_ Î¦, then Z is disentangled with respect to Î¦; Further, if Equation 2 holds and âˆˆ _G, where_
_Ï†g is the corresponding element in Â·_ _Â·_ _âˆ€ Î¦ âˆˆ of g under the isomorphism. âˆˆ_

In Theorem 1, (i) states that the relation between the elements (i.e., group structure) is preserved
between Î¦ and G, and we denote it as the group structure constraint; (ii) actually indicates a data
constraint that all variations in the data can be generated by compositions of some basic permutation
_generators_ _Ï†i_ _i=1,...,m. We denote it as the data constraint; (iii) states that the permutations in_
_{_ _}_
the agent group Î¦ are defined by encoding, action, and decoding, which is referred to as the model
_constraint. Note that in Theorem 1, only the data constraint refers to the world state w._

Here is a sketch of the proof: data constraint is a special case of Equation 2 for a generator, and
_group structure constraint is a relation-preserving constraint on compositions of generators, and_
satisfying both constraints will thus result in that Equation 2 holds for any general element in Î¦, and
vice versa. Moreover, we can derive Equation 1 for disentanglement when combining the model
_constraint and Equation 2._

The model constraint specifies the way to permute the data. When the data is permuted, its world
state changes. Therefore, how the world states transit between each other is modeled by the model
_constraint applied on the data. The isomorphism between Î¦ and G ensures that the world state space_
_W and data space O have the same symmetry. In this way, the model applied on the data learns the_
transition of the world states. Note that we aim to bring this group-based definition, which requires
ground truth by default, into the unsupervised setting. Now only the data constraint refers to the
world states, and it seems almost impossible to derive a sufficient condition for it without the labels.
We thus make a trade-off in which we use a necessary condition in the next section.

4 GROUPIFIED VAE: A LEARNING METHOD OF THE FRAMEWORK

Letâ€™s look closer into the three constraints, respectively. Firstly, we consider the model constraint,
_Ï†g_ _o = h[âˆ’][1](g_ _h(o))_ _o_ _O, Ï†g_ Î¦, which suggests that the action of Î¦ on O can be
implemented using an autoencoder-like network that performs encoding, action on its representation Â· _Â·_ _âˆ€_ _âˆˆ_ _âˆˆ_
space, and decoding. Given an autoencoder-like network with an encoder h and a decoder d, since d


-----

Decoder

Encoder

Decoder

(a) (b)

Figure 1: Overview of the implementation (Groupified VAE). (a) Illustration of permutation group
Î¦Î¦ = are permutations on {Ï†g|g âˆˆ _G} defined on a VAE-based model, where O. Specifically, when optimized, G Ï† = ( andZ/n Ï†Z) are horizontal and vertical[m]. The generators Ï†i, Ï†j âˆˆ_

movements. Ï†i is defined as the solid orange arrows illustrate: encode an image o to representation z,
perform Î· on z to get z, add gi to z, and decode back to the image. This process can be regarded as an
exchange of images in dataset (permutation), as the dashed orange arrow shows. These permutations
form a group Î¦. (b) The Isomorphism Loss, which guarantees that Î¦ is isomorphic to G, includes
Abel Loss La constraining the commutativity, and Order Loss Lo constraining the cyclicity.

is approximately the inversion of h, the model constraint can be formulated as

_Ï†g_ _o = h[âˆ’][1](g_ _h(o)) =âˆ†_ _d(g_ _h(o)),_ _o_ _O, g_ _G,_ (3)
_Â·_ _Â·_ _Â·_ _âˆ€_ _âˆˆ_ _âˆˆ_

together with further implementation of Î¦ as described in Section 4.1, the model constraint can be
fulfilled. Secondly, The data constraint requires that all variations in the data can be generated by
compositions of some basic permutations generators. Previous VAE-based works (Higgins et al.,
2017; Burgess et al., 2018; Kim & Mnih, 2018; Chen et al., 2018; Kumar et al., 2017) aim to generate
the data with independent generative factors, which is in line with the data constraint. Intuitively, if
the VAE-based model can generate the data from statistical independent basic latent units and each
unit corresponds to the basic permutation generator, the data constraint may be satisfied. Based
on the intuition above, we prove that if the world state is independently sampled per dimension, the
minimization of total correlation is a necessary condition for the data constraint (see Appendix E).
Therefore, we can leverage existing VAE-based models to fulfill the data constraint to some extent for
the unsupervised setting. Lastly, to satisfy the group structure constraint, we derive a self-supervised
_Isomorphism Loss which can be incorporated into the VAE-based model as described in Section 4.2._

4.1 IMPLEMENTATION OF GROUP Î¦

The key is to implement the group actions of G on Z into the VAE-based models, we need to map
the representation z to a group that is isomorphic to G (cyclic representation space). Therefore, we
construct a function Î· to achieve this mapping. Moreover, this mapping is required to be differentiable,
in order for back-propagation to be adopted for optimization. According to Group Theory, there
is an isomorphism between G and the n-th root unity group: {exp((2Ï€iz)/n)|z âˆˆ Z[m]}, where
_n, m are the same as in G. Therefore, the representation z can be mapped to z by the function Î· as_
_z = Î·(z) = exp((2Ï€iz)/n) (see Figure 1 (a)). However, z can not be mapped to directly as it has_
complex numbers, but we can use Eulerâ€™s formula: exp((2Ï€iz)/n) = sin((2Ï€z)/n)+i cos((2Ï€z)/n)
to map z to its real and imaginary part, i.e., vector sin((2Ï€z)/n) and cos((2Ï€z)/n). The two vectors
are concatenated and fed to the decoder.

For ease of implementation, the permutation group Î¦ can be approximately generated by compositions
of generators, i.e., Î¦ =< Ï†1, Ï†2, . . ., Ï†m >. Recall that the generator Ï†i of group Î¦ is defined as
_Ï†in Figure 1 (a). Fori Â· o = d(gi Â· h(o)) = Ï†i, we implement d(h(o) + gi), âˆ€ goi âˆˆ hO(o, where) by adding gi is generator 1 (without loss of generality) to the of dimension i in G, as shown i-th_
_Â·_
dimension of h(o), then make it cyclic by function Î·. Similarly, for Ï†[âˆ’]i [1][, we add the value of][ n][ âˆ’] [1][.]


-----

4.2 IMPLEMENTATION OF THE ISOMORPHISM

In this section, to satisfy the group structure constraint (isomorphism), we derive two equivalent
constraints, which are then converted into an Isomorphism Loss _I_ . Many groups are uniquely
_L_
determined by the properties of the generators, e.g., group G =< a, b|a[2] = b[2] = e, ab = ba >. In
addition, since the group Î¦ is isomorphic to G, Î¦ is also expected to be commutative and cyclic. In
light of this, we derive two constraints on generators that are equivalent to the isomorphism condition,
as described in Theorem 2. Please refer to Appendix C for the proof.

**Theorem 2 The defined permutation group Î¦ =< Ï†1, Ï†2, . . ., Ï†m > is isomorphic to G =**
((Zii/n) âˆ€ZÏ†)i âˆˆ[m] _if and only if:Î¦, 1 â‰¤_ _i â‰¤_ _m (, we havei) for âˆ€_ _generators Ï†[n]i_ [=][ e][, where] Ï†i, Ï†[ e]j âˆˆ[ is the identity element of group]Î¦, 1 â‰¤ _i, j â‰¤_ _m, we have Ï†i[ Î¦]Ï†j[.] = Ï†jÏ†i, and_

The first constraint requires the group Î¦ to be an abelian group (Judson, 2020). Therefore, we denote
it as Abel constraint and the loss derived from it as the Abel Loss _a. The second is a constraint on_
_L_
the order of elements. We thus denote it as the Order constraint and the loss derived from it as the
Order Loss _o. See Appendix F for a more detailed implementation._
_L_

**Abel Loss.minimize** For the Abel constraint:Ï†i (Ï†j _o)_ _Ï†j_ (Ï†i _o) âˆ€,Ï†io, Ï†j âˆˆO to meet the Abel constraint, as shown in Figure 1Î¦, 1 â‰¤_ _i, j â‰¤_ _m, we have Ï†iÏ†j = Ï†jÏ†i. We_
(b). The Abel Loss is the sum of the losses of all combinations of two âˆ¥ _Â·_ _Â·_ _âˆ’_ _Â·_ _Â·_ _âˆ¥_ _âˆ€_ _âˆˆ_ _generators. Denote the set of_
combinations as C = {(i, j)|1 â‰¤ _i, j â‰¤_ _m}. The Abel Loss is defined as follows_


_Ï†i_ (Ï†j _o)_ _Ï†j_ (Ï†i _o)_ _._ (4)
_âˆ¥_ _Â·_ _Â·_ _âˆ’_ _Â·_ _Â·_ _âˆ¥_
(i,jX)âˆˆC


_La =_


_oâˆˆO_


**Order Loss.element in group For the Order constraint: Î¦ (identity mapping). Note that with âˆ€Ï†i âˆˆ** Î¦, 1 â‰¤ _i n â‰¤ times composition ofm, we have Ï†[n]i_ [=][ e] Ï†[, where]i, it is difficult for the[ e][ is the][ identity]
gradient to back-propagate. We thus use an approximation that uses 2 times of composition instead.
When the autoencoder can do the reconstruction well, this approximation holds, see appendix E
for details. Similar to Abel Loss, we minimize _Ï†i_ (Ï†i[n][âˆ’][1] _o)_ _o_ _,_ _o_ _O to satisfy the Order_
constraint. The whole process is illustrated in Figure 1 (b). However, the equation is not symmetrical âˆ¥ _Â·_ _Â·_ _âˆ’_ _âˆ¥_ _âˆ€_ _âˆˆ_
and leads to bias. Therefore, we use the following symmetrical form instead:


_Ï†i_ (Ï†[n]i _[âˆ’][1]_ _o)_ _o_ + _Ï†i[n][âˆ’][1]_ (Ï†i _o)_ _o_ _._ (5)
_âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_ _âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_



_Lo =_


_oâˆˆO_


1â‰¤iâ‰¤m


With the above two loss functions optimized, the isomorphism condition is satisfied, which can be
illustrated by Theorem 3. Please refer to Appendix D for the proof.

**Theorem 3Ï†and the Order Loss function (Equation 5) are optimized.iÏ†j = Ï†jÏ† The following two conditions are equivalent:i and âˆ€Ï†i âˆˆ** Î¦, 1 â‰¤ _i â‰¤_ _m, we have Ï†[n]i_ [=][ e][ (] ([ii]i)[)] âˆ€[ the Abel Loss function (Equation 4)]Ï†i, Ï†j âˆˆ Î¦, 1 â‰¤ _i, j â‰¤_ _m, we have_

Since the Abel Loss and Order Loss are equally important for satisfying the isomorphism condition,
we assign equal weight to them. Thus, the Isomorphism Loss is LI = Lo + La. With the
implementation of group Î¦, the model constraint is satisfied. We optimize the Isomorphism Loss to
satisfy the group structure constraint. To further satisfy the data constraint to some extent as described
in Section 4, we leverage VAE-based models and optimize their original loss (that minimizes the total
correlation), denoted as LV AE. Therefore, the Total Loss is L = LV AE + Î³I _LI_, where Î³I is the
weight of Isomorphism Loss. We denote the above VAE-based implementation as Groupified VAE.

5 EXPERIMENTS

We first verify the effectiveness of Groupified VAE quantitatively in learning disentangled representations on several datasets and several VAE-based models. Then, we show its effectiveness qualitatively
on two typical datasets. After that, we perform a case study on the dSprites dataset to analyze the
effectiveness, and conduct ablation studies on the losses and hyperparameters. For the performance
comparison of two downstream tasks (abstract reasoning Van Steenkiste et al. (2019) and fairness
evaluation Locatello et al. (2019a)), and more comprehensive results, please see Appendix I.


-----

5.1 DATASETS AND BASELINE METHODS

To evaluate our method, we consider several datasets: dSprites (Higgins et al., 2017), Shapes3D (Kim
& Mnih, 2018), Cars3D (Reed et al., 2015), and the variants of dSprites introduced by Locatello et
al. (Locatello et al., 2019b): Color-dSprites and Noisy-dSprites. Please refer to Appendix G for the
details of the datasets.

We choose the following four baseline methods as representatives of the existing VAE-based models,
which are denoted as Original VAEs. We verify the effectiveness of our implementation based on
those methods. Î²-VAE (Higgins et al., 2017) introduces a hyperparameter Î² in front of the KL
regularizer of the VAE loss. It constrains the VAE information capacity to learn the most efficient
representation. AnnealVAE (Burgess et al., 2018) progressively increases the bottleneck capacity
so that the encoder learns new factors of variation while retaining disentanglement in previously
learned factors. FactorVAE (Burgess et al., 2018) and Î²-TCVAE (Chen et al., 2018) both penalize
the total correlation (Watanabe, 1960), but estimate it with adversarial training (Nguyen et al., 2010;
Sugiyama et al., 2012) and Monte-Carlo estimator respectively.

DCI BetaVAE MIG FactorVAE
dSprits

Original Groupified Original Groupified Original Groupified Original Groupified

AnnealVAEFactorVAEÎ²-TCVAEÎ²-VAE 0000.35...233828 Â± Â± Â± Â± 0 0 0 0.065...101010 **0000...463941.36 Â± Â± Â± Â± 0 0 0 0...085056074.11** 0000....86897584 Â± Â± Â± Â± 0 0 0 0....026083050040 **0000....878618689 Â± Â± Â± Â± 0 0 0 0...0067051020.038** 0000....14271723 Â± Â± Â± Â± 0 0 0 0....09709206710 **0000....37343124 Â± Â± Â± Â± 0 0 0 0....089061061093** **0000....70517468 Â± Â± Â± Â± 0 0 0 0....098068098094** **0000....63687570 Â± Â± Â± Â± 0 0 0 0....058089075098**

DCI BetaVAE MIG FactorVAE
Cars3d

Original Groupified Original Groupified Original Groupified Original Groupified

AnnealVAEFactorVAEÎ²-TCVAEÎ²-VAE 0000....18222124 Â± Â± Â± Â± 0 0 0 0....059046054049 **0000....24252526 Â± Â± Â± Â± 0 0 0 0....041046040046** 000.99..99199. Â±0 Â± Â± Â± 1 1 4. 06eee âˆ’. âˆ’0 âˆ’443 **0.99111 Â±...000 Â± Â± Â± 1. 0 0 05e...000 âˆ’** **4** 0000....07107409810 Â± Â± Â± Â± 0 0 0 0....021032027016 **0000....10111111 Â± Â± Â± Â± 0 0 0 0....014032033033** 0000....81908882 Â± Â± Â± Â± 0 0 0 0....066039040062 **0000....93879393 Â± Â± Â± Â± 0 0 0 0....034028034034**


DCI BetaVAE MIG FactorVAE
Shapes3d

Original Groupified Original Groupified Original Groupified Original Groupified

AnnealVAEFactorVAEÎ²-TCVAEÎ²-VAE 0000..52..444766 Â± Â± Â± Â± 0 0 0 0..051..1761010 **0000....49726056 Â± Â± Â± Â± 0 0 0 0....06506107810** **0000....86978291 Â± Â± Â± Â± 0 0 0 0....076072055039** 0000....90898096 Â± Â± Â± Â± 0 0 0 0....045075042086 0000....48283340 Â± Â± Â± Â± 0 0 0 0....047181318 **0000....47504243 Â± Â± Â± Â± 0 0 0 0....0900521511** **0000....81827589 Â± Â± Â± Â± 0 0 0 0....074064056098** **0000....82839079 Â± Â± Â± Â± 0 0 0 0....066043066046**

Table 1: Performance (mean Â± std) on different datasets and different models with different metrics.
We evaluate Î²-VAE, AnnealVAE, FactorVAE, and Î²-TCVAE on dSprites, Cars3d, Shapes3d, NoisydSprites, and Color-dSprites for 1800 settings. These settings include different random seeds and
hyperparameters, refer to Appendix G for the details. We only show the first three datasets here. For
more results, please refer to Appendix I.

5.2 QUANTITATIVE EVALUATIONS

This section performs quantitative evaluations on the datasets and models introduced with different
random seeds and different hyperparameters. Then, we evaluate the performance of the Original
and Groupified VAEs in terms of several popular metrics: BetaVAE score (Higgins et al., 2017),
DCI disentanglement Eastwood & Williams (2018) (DCI in short), MIG (Chen et al., 2018), and
FactorVAE score (Kim & Mnih, 2018). We assign three or four hyperparameter settings for each
model on each dataset. We run it with ten random seeds for each hyperparameter setting to minimize
the influence of random seeds. Therefore, we totally run ((3 Ã— 10 Ã— 3 + 10 Ã— 3 Ã— 3) Ã— 2) Ã— 5 = 1800
models. We evaluate each metricâ€™s mean and variance for each model on each dataset to demonstrate
the effectiveness of our method. As shown in Table 1, these Groupified VAEs have better performance
(numbers marked bold in Table 1) than the Original VAEs on almost all the cases.

On Shapes3d, the Groupified VAEs outperform the Original ones on all the metrics except for
BetaVAE scores, suggesting some disagreement between BetaVAE scores and other metrics. Similar
disagreement is also observed between the variances of MIG and other metrics on Cars3d. Note that
the qualitative evaluation in Appendix J shows that the disentanglement ability of Groupified VAEs is
better on Shapes3d and Cars3d.


-----

(a) Original (b) Groupified


Figure 3: Traversal results of two factors (floor
color, scale) of Original and Groupified Î²TCVAE. The traversal results of Groupified
VAEs are cyclic.


Figure 2: Visual traversal comparison between
Original and Groupified Î²-TCVAE. The traversal
results of Groupified VAEs are less entangled.

5.3 QUALITATIVE EVALUATIONS


We qualitatively show the Groupified VAEs achieve better disentanglement than the Original ones.
As shown in Figure 2, the traversal results of Groupified Î²-TCVAE on Shape3d and Car3d are less
entangled. For more qualitative evaluation, please refer to Appendix J. To verify that the Groupified
VAEs learn a cyclic representation space (where n = 10), we provide the traversal results of [0,18]
with a step of 2 for both the Groupified and Original Î²-TCVAE on Shape3d in Figure 3. We observe
that the traversal results of Groupified VAEs are of high quality with a period of 10 (equal to n).
However, the Original VAEs generate low-quality images without cyclicity. For the comparison of
the results on CelebA (real-world datasets), please see appendix J.

5.4 VISUALIZATION OF THE LEARNED REPRESENTATION SPACE


To understand how our theoretical framework helps the existing VAE-based models to improve the
disentanglement ability, we take dSprites as an example, visualize the learned representation space,
and show the typical score distributions of the metrics. First, we visualize the space spanned by the
three most dominant factors (x position, y position, and scale).

As shown in Figure 5 (for more results, please refers to Appendix L), the spaces learned by the Original
VAEs collapse, while the spaces of the Groupified VAEs only bend a little bit. The main reason
is that the Isomorphism Loss, serving as a self-supervision signal, suppresses the representation
space distortion and encourages the disentanglement of the learned factors. As Figure 4 shows,
the Groupified VAEs consistently achieve better mean performance with smaller variances. The
isomorphism reduces the search space of the network so that the Groupified VAEs converge to the
ideal disentanglement solution.

(a) BetaVAE score (b) DCI disentanglement (c) MIG (d) FactorVAE score


Figure 4: Performance distribution of Original and Groupified AnnealVAE on dSprites (demonstrated
by the Violin Plot (Hintze & Nelson, 1998)). Variance is due to different hyperparameters and random
seeds. We observe that Groupified AnnealVAE improves the average performance with smaller
variance in terms of BetaVAE score (a), DCI disentanglement (b), and MIG (c), and has a comparable
mean performance with smaller variance in terms of FactorVAE score (d).

Groupified Factor Size n = 10
Original

_n = 5_ _n = 10_ _n = 15_ w/o Abel w/o Order Groupified


DCI 0.27 Â± 0.10 0.34 Â± 0.062 **0.38 Â± 0.055** **0.38 Â± 0.064** 0.28 Â± 0.11 0.34 Â± 0.056 **0.38 Â± 0.055**

Table 2: Ablation study on the factor size n and Isomorphism Loss. DCI disentanglement is listed
(mean Â± std).


-----

(a) C = 10, Groupified (b) C = 20, Groupified (c) C = 25, Groupified (d) C = 30, Groupified

(e) C = 10, Original (f) C = 20, Original (g) C = 25, Original (h) C = 30, Original

Figure 5: The representation space spanned by the learned factors by Original (bottom row) and
_Groupified AnnealVAE (top row). The position of each point is the disentangled representation of the_
corresponding image. An ideal result is all the points form a cube and color variation is continuous.
The increase of C (a hyperparameter of AnnealVAE) results in a collapse of representation space
of the Original VAE. The collapse is suppressed by the Isomorphism Loss, which leads to better
disentanglement.

5.5 ABLATION STUDY

We perform an ablation study on the assumed total number of possible values for a factor (factor size)
_n, Abel Loss_ _a, and Order Loss_ _o. We take the AnnealVAE trained on dSprites as an example._
_L_ _L_
We only consider the DCI disentanglement metric here. We investigate the influence of factor size n.
Besides, to evaluate the effectiveness of the two constraints, the models with the Abel Loss alone or
Order Loss alone added are also evaluated. In this setting, we fix n to 10. We compute the mean and
variance of the performance for 30 settings of hyperparameters and random seeds. Table 2 shows
that the isomorphism plays a role of cycle consistency in the representation space, leading to better
disentanglement. The performance is robust to the factor size n, as the models learn to adapt to
different n in the training process. The models with only the Abel Loss or Order Loss applied have
improved performance compared to the originals. The former (Abel Loss) performs better than the
latter, suggesting that commutativity plays a more important role. Note that the number of factors m
can be learned and is not a hyperparameter. See Appendix F for details. Î³I is empirically set to 1.

6 CONCLUSION

In this paper, we have opened the possibility of applying group-based definition to unsupervised
disentanglement by proposing a theoretical framework. The group structure and model constraint
in the framework are effective for existing VAE-based unsupervised disentanglement methods. In
addition, by establishing the feasibility of learning the representation conforming to the definition
in unsupervised settings, we have exhibited the consistently better mean performance with lower
variance attributed to the definition. We believe our work constitutes a promising step towards
_unsupervised disentanglement with theoretical guarantee. As to the limitation, we only provide_
a necessary condition for the data constraint, as a result, we can not address the unidentifiability
problem. Tackling the unidentifiability problem with the group-based definition is beyond the scope
of this work, we will leave it as future work. In addition, a natural extension of our framework is to
use lie group Hall (2015) (which is also a manifold) to extend our framework.


-----

REFERENCES

Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. Deep variational information
bottleneck. arXiv preprint arXiv:1612.00410, 2016.

Philip W Anderson. More is different. Science, 177(4047):393â€“396, 1972.

Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. TPAMI, 35(8):1798â€“1828, 2013.

Christopher P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. Understanding disentangling in beta -vae. arXiv preprint
_arXiv:1804.03599, 2018._

Hugo Caselles-Dupre, Michael Garcia Ortiz, and David Filliat. Symmetry-based disentangledÂ´
representation learning requires interaction with environments. In NeurIPS, pp. 4606â€“4615, 2019.

Ricky TQ Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. Isolating sources of
disentanglement in variational autoencoders. In NeurIPS, pp. 2610â€“2620, 2018.

Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan:
interpretable representation learning by information maximizing generative adversarial nets. In
_NeurPIS, 2016._

Stephane Deny Diane Bouchacourt, Mark Ibrahim. Addressing the topological defects of disentan[glement, 2021. URL https://openreview.net/forum?id=cbdp6RLk2r7.](https://openreview.net/forum?id=cbdp6RLk2r7)

David S Dummit and Richard M Foote. Abstract algebra, volume 1999. Prentice Hall Englewood
Cliffs, NJ, 1991.

Cian Eastwood and Christopher KI Williams. A framework for the quantitative evaluation of
disentangled representations. In ICLR, 2018.

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron C. Courville, and Yoshua Bengio. Generative adversarial networks. CoRR, abs/1406.2661,
[2014. URL http://arxiv.org/abs/1406.2661.](http://arxiv.org/abs/1406.2661)

Klaus Greff, Raphael Lopez Kaufman, Rishabh Kabra, Nick Watters, Chris Burgess, Daniel Zoran,Â¨
Loic Matthey, Matthew Botvinick, and Alexander Lerchner. Multi-object representation learning
with iterative variational inference. arXiv preprint arXiv:1903.00450, 2019.

Brian Hall. Lie groups, Lie algebras, and representations: an elementary introduction, volume 222.
Springer, 2015.

Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. ICLR, 2017.

Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende,
and Alexander Lerchner. Towards a definition of disentangled representations. arXiv preprint
_arXiv:1812.02230, 2018._

Jerry L Hintze and Ray D Nelson. Violin plots: a box plot-density trace synergism. The American
_Statistician, 52(2):181â€“184, 1998._

Thomas W Judson. Abstract algebra: theory and applications. Virginia Commonwealth University
Mathematics, 2020.

Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoencoders
and nonlinear ica: A unifying framework. In AISTATS, pp. 2207â€“2217, 2020.

Valentin Khrulkov, Leyla Mirvakhabova, Ivan Oseledets, and Artem Babenko. On disentangled
[representations extracted from pretrained gans, 2021. URL https://openreview.net/](https://openreview.net/forum?id=VCAXR34cp59)
[forum?id=VCAXR34cp59.](https://openreview.net/forum?id=VCAXR34cp59)


-----

Hyunjik Kim and Andriy Mnih. Disentangling by factorising. In ICML, 2018.

Minyoung Kim, Yuting Wang, Pritish Sahu, and Vladimir Pavlovic. Bayes-factor-vae: Hierarchical
bayesian deep auto-encoder models for factor disentanglement. In Proceedings of the IEEE/CVF
_International Conference on Computer Vision, pp. 2979â€“2987, 2019._

Diederik P Kingma and Max Welling. Auto-encoding variational bayes. _arXiv preprint_
_arXiv:1312.6114, 2013._

Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. Variational inference of disentangled
latent concepts from unlabeled observations. arXiv preprint arXiv:1711.00848, 2017.

Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building
machines that learn and think like people. Behavioral and brain sciences, 40, 2017.

Wonkwang Lee, Donggyun Kim, Seunghoon Hong, and Honglak Lee. High-fidelity synthesis with
disentangled representation. In ECCV, 2020.

Jose Lezama. Overcoming the disentanglement vs reconstruction trade-off via jacobian supervision.Â´
In International Conference on Learning Representations, 2018.

Yu-Jhe Li, Ci-Siang Lin, Yan-Bo Lin, and Yu-Chiang Frank Wang. Cross-dataset person reidentification via unsupervised pose disentanglement and adaptation. In ICCV, 2019.

Zinan Lin, Kiran Thekumparampil, Giulia Fanti, and Sewoong Oh. Infogan-cr and modelcentrality:
Self-supervised model training and selection for disentangling gans. In ICML, 2020.

Francesco Locatello, Gabriele Abbati, Thomas Rainforth, Stefan Bauer, Bernhard Scholkopf, andÂ¨
Olivier Bachem. On the fairness of disentangled representations. In NeurIPS, pp. 14611â€“14624,
2019a.

Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Scholkopf,Â¨
and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentangled representations. In ICML, pp. 4114â€“4124, 2019b.

Emile Mathieu, Tom Rainforth, N Siddharth, and Yee Whye Teh. Disentangling disentanglement in
variational autoencoders. In ICML, pp. 4402â€“4412, 2019.

Willard Miller. Symmetry groups and their applications. Academic Press, 1973.

Alexander McFarlane Mood. Introduction to the Theory of Statistics. McGraw-hill, 1950.

XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals
and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory,
56(11):5847â€“5861, 2010.

Emmy Noether. Der endlichkeitssatz der invarianten endlicher gruppen. Mathematische Annalen, 77
(1):89â€“92, 1915.

Matthew Painter, Adam Prugel-Bennett, and Jonathon Hare. Linear disentangled representations and
unsupervised action estimation. NeurIPS, 33, 2020.

Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. NeurIPS 2017 workshop, 2017.

David Pfau, Irina Higgins, Alex Botev, and Sebastien RacaniÂ´ ere. Disentangling by subspace diffusion.`
_NeurIPS, 33, 2020._

Robin Quessard, Thomas D Barrett, and William R Clements. Learning group structure and disentangled representations of dynamical environments. arXiv preprint arXiv:2002.06991, 2020.

Scott E. Reed, Yi Zhang, Yuting Zhang, and Honglak Lee. Deep visual analogy-making. In NeurIPS,
2015.


-----

Danilo Jimenez Rezende and Fabio Viola. Taming vaes. arXiv preprint arXiv:1810.00597, 2018.

Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin Liu, Jun Wang,
and Tarek Abdelzaher. Controlvae: Controllable variational autoencoder. In International Confer_ence on Machine Learning, pp. 8655â€“8664. PMLR, 2020._

Akash Srivastava, Yamini Bansal, Yukun Ding, Cole Hurwitz, Kai Xu, Bernhard Egger, Prasanna
Sattigeri, Josh Tenenbaum, David D Cox, and Dan Gutfreund. Improving the reconstruction of
disentangled representation learners via multi-stage modelling. arXiv preprint arXiv:2010.13187,
2020.

Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density-ratio matching under the bregman
divergence: a unified framework of density-ratio estimation. Annals of the Institute of Statistical
_Mathematics, 64(5):1009â€“1044, 2012._

Raphael Suter, Djordje Miladinovic, Bernhard Scholkopf, and Stefan Bauer. Robustly disentangledÂ¨
causal mechanisms: Validating deep representations for interventional robustness. In ICML, pp.
6056â€“6065. PMLR, 2019.

Sjoerd Van Steenkiste, Francesco Locatello, Jurgen Schmidhuber, and Olivier Bachem. Are dis-Â¨
entangled representations helpful for abstract visual reasoning? In NeurIPS, pp. 14245â€“14258,
2019.

Satosi Watanabe. Information theoretical analysis of multivariate correlation. IBM Journal of research
_and development, 4(1):66â€“82, 1960._

Nicholas Watters, Loic Matthey, Christopher P Burgess, and Alexander Lerchner. Spatial broadcast
decoder: A simple architecture for learning disentangled representations in vaes. arXiv preprint
_arXiv:1901.07017, 2019._

Xinqi Zhu, Chang Xu, and Dacheng Tao. Commutative lie group vae for disentanglement learning.
_arXiv preprint arXiv:2106.03375, 2021._

Yang Zou, Xiaodong Yang, Zhiding Yu, BVK Kumar, and Jan Kautz. Joint disentangling and
adaptation for cross-domain person re-identification. In ECCV, 2020.


-----

A PRELIMINARIES

**_Group: A set G together with a binary operation â—¦_** as: â—¦ : G Ã— G â†’ _G satisfying the following_
properties:

-  Associativity: âˆ€ _a, b, c âˆˆ_ _G, s.t.(a â—¦_ _b) â—¦_ _c = a â—¦_ (b â—¦ _c)._

-  Identity: âˆƒ _e âˆˆ_ _G, s.t. âˆ€_ _a âˆˆ_ _G, e â—¦_ _a = a â—¦_ _e = a._

-  Inverse: âˆ€ _a âˆˆ_ _G, âˆƒ_ _a[âˆ’][1]_ _âˆˆ_ _G : a â—¦_ _a[âˆ’][1]_ = a[âˆ’][1] _â—¦_ _a = e._


It is customary to represent a group with a set G and the binary operation â—¦ as a pair (G, â—¦). When
the binary operation is clear, we represent group (G, â—¦) as G and use multiplication to represent the
binary operation â—¦, i.e., a â—¦ _b = ab, âˆ€_ _a, b âˆˆ_ _G._

**_Group Action: Let (G, â—¦) be a group and P be a set. By the group actions of (G, â—¦) on P_**, we mean a
mapping:

_Â·P : G Ã— P â†’_ _P,_ (6)

such that

-  âˆ€a, b âˆˆ _G, p âˆˆ_ _P, (a â—¦_ _b) Â· p = a Â· (b Â· p)._

-  e Â· p = p, where e is the identity element of G.


**_Symmetry Group and Permutation Group: Let Î£ be a nonempty set, the bijections from Î£ to itself_**
are called Permutations. S(Î£) denotes the set containing all the permutations on Î£. S(Î£) forms a
group under the binary operation: composition of functions, which is called Symmetry Group. A
subgroup of S(Î£) is called Permutation Group.

**_Abelian Group: If the commutative law (âˆ€_** _a, b âˆˆ_ _G, a â—¦_ _b = b â—¦_ _a) holds in a group (G, â—¦), such a_
group is called an abelian group.

**_Subgroup: If a subset H of a group G is itself a group under the operation of G, we say that H is a_**

|Col1|Col2|2|
|---|---|---|
|1|||
||||
||||


|Col1|Col2|2|
|---|---|---|
|4|||
||||
||||


|Col1|Col2|2|
|---|---|---|
|3|||
||||
||||


|Col1|Col2|2|
|---|---|---|
|2|||
||||
||||


|Col1|Col2|2|
|---|---|---|
|1|||
||||
||||


|Col1|Col2|2|
|---|---|---|
|3|||
||||
||||


subgroup of G.

1 2 1 2 1 2 1 2

2 1 4 3
1 4 3 2

4 3 4 3 4 3 4 3

4 3 3 2 2 1 1 4

ğ‘–ğ‘‘= ğ‘“[à¬´]ğ‘Ÿ[à¬´] (1432) = ğ‘“[à¬´]ğ‘Ÿ[à¬µ] (13)(24) = ğ‘“[à¬´]ğ‘Ÿ[à¬¶] (1234) = ğ‘“[à¬´]ğ‘Ÿ[à¬·]

1 2 1 2 1 2 1 2

3 4 1 2
4 1 2 3

4 3 4 3 4 3 4 3

1 2 2 3 3 4 4 1

(14)(23) = ğ‘“[à¬µ]ğ‘Ÿ[à¬´] (24) = ğ‘“[à¬µ]ğ‘Ÿ[à¬µ] (12)(34) = ğ‘“[à¬µ]ğ‘Ÿ[à¬¶] (13) = ğ‘“[à¬µ]ğ‘Ÿ[à¬·]

Figure 6: 4-th Dihedral Group (D4): The groups of symmetries for square. Note that permutation
means 1 â†’ 2, 2 â†’ 3, 3 â†’ 1.


**_Equivalence Relation: An equivalence relation on a set B is a subset U âŠ‚_** _B Ã— B satisfying: (It is_
customary to represent (a, b) âˆˆ _U as a âˆ¼_ _b)_

-  Reflexive: âˆ€ _a âˆˆ_ _B, (a, a) âˆˆ_ _U_ .

-  Symmetric: (a, b) âˆˆ _U â‡â‡’_ (b, a) âˆˆ _U_ .

-  Transitive: (a, b) âˆˆ _U and (b, c) âˆˆ_ _U â‡’_ (a, c) âˆˆ _U_ .


-----

**_Equivalence Classequivalence class containing: Let âˆ¼_** be an equivalence relation on a set a is the subset a =âˆ† _{b âˆˆ_ _C|b âˆ¼_ _a} âŠ‚ B. We take anB._ _a âˆˆ_ _B, and then the_

**_Homomorphism Let (G, Â·) and (H, â—¦) be two groups. A homomorphism f_**, from G to H, is a
mapping f : G â†’ _H, such that f_ (x Â· y) = f (x) â—¦ _f_ (y), âˆ€x, y âˆˆ _G._

**_Isomorphism: A homomorphism f : G â†’_** _H which is bijective is called an isomorphism. Two_
groups are said to be isomorphic if there exists an isomorphism between them.

**Related Groups:**
(i) Additive group of integers modulo n: Let n denote a positive integer. We define an equivalence
relation on Z as a âˆ¼ _b â‡”_ _a = b (mod n) (a and b have the same remainder modulo n). The relation_
divides Z into n equivalent classes: 0, 1, . . ., n âˆ’ 1, where i represents the equivalent class containing
_i, i.e., i = {m âˆˆ_ Z|m = i (mod n)}. Let Zn = {0, 1, . . ., n âˆ’ 1}, and Zn forms a group under the
binary operation: a + b = a + b, denoted by Z/nZ.
2Ï€ia
(ii) Group of n-th root unity: Let n denote a positive integer and Cn = {e _n |0 â‰¤_ _a â‰¤_ _n âˆ’_ 1, a âˆˆ

Z be n roots of x[n] = 1, and then Cn forms a group under complex multiplication. For the mapping:
_}_ 2Ï€ia
_f : Cn_ (Zn, +) defined by f (e _n ) = a, we have_
_â†’_

2Ï€ia 2Ï€ib 2Ï€i(a+b) 2Ï€ia 2Ï€ib
_f_ _e_ _n_ _Â· e_ _n_ = f _e_ _n_ = a + b = a + b = f _e_ _n_ _Â· f_ _e_ _n_ (7)
       

Therefore, f is a homomorphism, and thus is an isomorphism.

**_Congruence Class: Let n denote a positive integer, and we define an equivalence relation on Z as_**
_a âˆ¼_ _b â‡”_ _a = b (mod n). The relation divides Z into n equivalent classes: 0, 1, . . ., n âˆ’_ 1, which
are congruence classes and the elements of the additive group of integers modulo n.

**_Subgroup Generated by B: If B is a nonempty subset of the group (G, â—¦), the set defined by_**
_< B >=_ _a_ _G_ _a = a1_ _a2_ _an with either ai_ _B or a[âˆ’]i_ [1] _B_ forms a subgroup of G,
which is called the subgroup generated by { _âˆˆ_ _|_ _â—¦_ _â—¦Â· Â· Â· â—¦_ _B, e.g., G =< a, b âˆˆ_ _|a[2]_ = e, abâˆˆ =} ba > in the toy example
of Section 1. Here a1, . . . an are called Generators, e.g., a, b in G.

**_Cyclic Group A group G is called cyclic if there is an element a âˆˆ_** _G such that G = {a[n]|n âˆˆ_ Z} =<
_a >, e.g., Z/nZ. Such an element a is called a generator of G._

**_Symmetry: A symmetry of a geometric figure is a rearrangement of the figure preserving the_**
arrangement of its sides and vertices as well as its distances and angles.

**_Dihedral Group: The permutation group formed by the symmetries of a regular n-sided polygon,_**
denoted by Dn.

_D4 as an example: The vertices of a square are numbered by {1, 2, 3, 4}, which is analogous to_
an image dataset, the symmetries are analogous to image transformations. We often abbreviate
permutation 1 â†’ 2, 2 â†’ 3, 3 â†’ 4, 4 â†’ 1 as (1234). The elements of group D4 are shown in Figure
6, from which we know that all of the transformations are compounded by two basic permutations:
horizontal flip f and rotate 90 degrees clockwise r. Please note that f and r are analogous to
disentangled factors. Whatâ€™s more, the Group can be generated by these basic permutations f, r with
some properties, i.e., D4 =< f, r|f [2] = 1, r[4] = 1, fr = r[âˆ’][1]f >. The constraints f [2] = 1, r[4] =
1, fr = r[âˆ’][1]f are analogous to the group constraints in this paper.

B PROOF FOR THEOREM 1

In our setting, the group-based definition is equivalent to the equivariant condition g Â· _f_ (w) = f (g Â· _w)_
for the following reason. Since the group actions of G on Z is the element wise addition, (a) the
group action of G on Z exists and (b) group actions of Gi only affect Zi (refer to Section 3.2). These
two conditions of the group-based definition thus hold.

_Proof. In the following, we prove in Step 1 that the necessary and sufficient conditions of Î¦ playing_
the â€œagentâ€ role, i.e., f (g Â· w) = h(Ï† Â· b(w)), are (i) Î¦ is isomorphic to G, and (ii) there exist
_Ï†i_ Î¦, s.t. Ï†i _b(w) = b(gi_ _w), i = 1, 2, . . ., m. We then prove in Step 2 that if equation_
_f_ ( âˆˆg Â· w) = h(Ï† Â· Â· b(w)) and the definition of Â· _Ï† âˆˆ_ Î¦ hold, then Z is disentangled per group-based
definition.


-----

**Step 1: In the following, we prove that the necessary and sufficient conditions of f** (gÂ·w) = h(Ï†Â·b(w))
are (i) and (ii) above. Note that this holds even without a specific definition of Î¦.

_â‡’b(g) For a general permutation groupi_ _w), i = 1, 2, . . ., m. Assume that there exists an isomorphism Î¦ on O, we assume there exist Ï„ Ï† :i such that G_ Î¦, where group Ï†i Â· b(w) =
_G = ( Â·_ Z/nZ)[m]. From Group Theory, we know that there exists Âµ âˆˆ _Aut(Î¦) such that the following â†’_
equation holds, where Aut(Î¦) denotes the group of automorphisms of Î¦, i.e., Âµ is an isomorphism
_Âµ : Î¦ â†’_ Î¦. We denote the composition of Âµ, Ï„ as Ïƒ, and have

_Ïƒ(gi) = Âµ(Ï„_ (gi)) = Ï†i, i = 1, 2, . . ., m. (8)

Since we have Ï†i _b(w) = b(gi_ _w), i = 1, 2, . . ., m, the following equation holds,_
_Â·_ _Â·_

_Ïƒ(gi)_ _b(w) = Ï†i_ _b(w) = b(gi_ _w), i = 1, 2, . . ., m._ (9)
_Â·_ _Â·_ _Â·_

Since both Âµ, Ï„ are isomorphism, Ïƒ = Âµ â—¦ _Ï„ is also an isomorphism, which indicates that Ï†i is_
a generator of Î¦. For âˆ€Ï† âˆˆ Î¦, since Ïƒ is a bijection, there exists g âˆˆ _G = (Z/nZ)[m], such that_
_Ïƒ(g) = Ï† and g =_ _i_ _[k][i][g][i][, k][i][ âˆˆ]_ [Z][, where][ g][i][, i][ = 1][,][ 2][, . . ., m][ denotes the generators in][ G][. In order]

to calculate Ï† Â· b(w), we consider a specific example Ïƒ(g1 + g2).

_Ïƒ(g1+g2)_ _b(w) =[P] Ïƒ(g1)_ (Ïƒ(g2) _b(w)) = Ïƒ(g1)_ _b(g2_ _w) = b(g1_ (g2 _w)) = b((g1+g2)_ _w). (10)_

_Â·_ _Â·_ _Â·_ _Â·_ _Â·_ _Â·_ _Â·_ _Â·_

Therefore, for the general element Ï†, we have


_kigi_ _w) = b(g_ _w)._ (11)
_Â·_ _Â·_


_Ï† Â· b(w) = Ïƒ(_


_kigi)_ _b(w) = b(_
_Â·_


In general, we have Ï† Â· b(w) = b(g Â· w) and thus we have h â—¦ _b(g Â· w) = f_ (g Â· w) = h(Ï† Â· b(w))
when taking h on both sides.

_â‡b(g)i Here we prove thatw), i = 1, 2, . . ., m ( are two necessary conditions of equationi) G is isomorphic to Î¦ and (ii) there exists f_ (g _w Ï†) =i such that h(Ï†_ _b(w Ï†)) =i Â· b h((wÏ†) =x)._
We take Â· _f_ _[âˆ’][1]_ on both sides of the equation. For convenience, we rewrite Â· _g Â· w, Ï† Â·Â· b(w) as g(w) andÂ·_
_Ï†(b(w)), then we have_

_g(w) = f_ _[âˆ’][1]_ _â—¦_ _h â—¦_ _Ï† â—¦_ _b(w) = b[âˆ’][1]_ _â—¦_ _Ï† â—¦_ _b(w)._ (12)

Note that the notation â—¦ here denotes the composition of functions. We define the mapping Ï„ between
Î¦ and G as follows:
_Ï„_ (Ï†) = g = b[âˆ’][1] _â—¦_ _Ï† â—¦_ _b._ (13)

Note that b is a bijection, thus Ï„ is a bijection. We take Ï†i, Ï†j Î¦ and we have
_âˆˆ_

_Ï„_ (Ï†i _Ï†j)_ = b[âˆ’][1] _Ï†i_ _Ï†j_ _b_
_â—¦_ = (b[âˆ’][1]â—¦ _Ï† â—¦i_ _b) â—¦_ (b[âˆ’][1] _Ï†j_ _b)_ (14)
= Ï„ (Ï†i)â—¦ _Ï„ â—¦(Ï†j) â—¦._ _â—¦_ _â—¦_
_â—¦_

Therefore, Ï„ is a homomorphism and thus is an isomorphism. i.e., Î¦ is isomorphic to G. Recall that
group G has the form of G = (Z/nZ)[m], where it is a direct product of m cyclic groups. For âˆ€Ï† âˆˆ Î¦,
we have
_Ï† Â· b(w) = h[âˆ’][1]_ _â—¦_ _f_ (g(w)) = b(g(w)). (15)

For generatorsderived from the above equation: gi âˆˆ _G, i = 1, 2, . . ., m and the corresponding Ï†i = Ï„_ _[âˆ’][1](gi), we have a specific one_

_Ï†i_ _b(w) = b(gi(w)) = b(gi_ _w)._ (16)
_Â·_ _Â·_


Q.E.D.

**Step 2: As discussed in Section 1 and Section 3, we define Ï† as Ï† Â· x = Ï† Â· b(w) = h[âˆ’][1](Ïƒ[âˆ’][1](Ï†) Â·**
_h(x)) = h[âˆ’][1](g Â· f_ (w)), where Ïƒ is the same as in Step 1. Since Ïƒ is a bijection, for âˆ€Ï† âˆˆ Î¦, Ïƒ[âˆ’][1](Ï†)
uniquely exists, and thus Ï† is well-defined. We bring it into f (g Â· w) = h(Ï† Â· b(w)), and derive
_f_ (g _Â·_ _w) = g_ _Â·_ _f_ (w), i.e., the representation space Z is disentangled with respect to G. Specifically, for
the existing Ï†i, i = 1, 2, . . ., m, from equation 8, we have Ïƒ[âˆ’][1](Ï†i) = gi and Ï†i Â· _x = h[âˆ’][1](gi Â·_ _f_ (w)).

Q.E.D.


-----

C PROOF FOR THEOREM 2

In order to easily distinguish a general element and a generator, we use Ï• to stand for the general
element in Î¦ and Ï†i to stand for generators in Î¦. In addition, for mapping Ï„ : G â†’ Î¦, notation
_ker(Ï„_ ) is generally the inverse image of e, i.e., ker(Ï„ ) = {g âˆˆ _G|Ï„_ (g) = e}, where e is the identity
element in Î¦.

_Proof. Note that Section 3.4 describes the implementation of the elements in Î¦, but there is no guaran-_
tee that Î¦ is a group. Therefore, here we first prove in Step 1 that set Î¦ =< Ï†1, Ï†2, . . ., Ï†m|Ï†iÏ†j =
_Ï†jÏ†i, Ï†[n]i_ [=][ e, i][ = 1][,][ 2][, . . ., m][ and][ j][ = 1][,][ 2][, . . ., m >][ forms a group under the composition of]
functions, where e satisfies that eÏ†i = Ï†i, then prove in Step 2 the necessary and sufficient condition
for the isomorphism is to meet both the Abel constraint and the Order constraint.

**Step 1: To prove a set forms a group under some operation, we only need to verify that the elements**
of the set satisfy the following three properties: 1. Associativity 2. Identity 3. Inverse.

1. We first verify the Associativity property: âˆ€ _Ï•s, Ï•t, Ï†l âˆˆ_ Î¦, s.t. (Ï•sÏ•t)Ï•l = Ï•s(Ï•tÏ•l).

Recall that in Section 3.2, the representation space is a set with the same elements in G. The
group action of G on Z is the addition. We have g Â· z âˆˆ _Z, âˆ€g âˆˆ_ _G, z âˆˆ_ _Z, and then we have_
_dS((gO Â·) z is the symmetry group on images set) âˆˆ_ _O, âˆ€g âˆˆ_ _G, z âˆˆ_ _Z. Therefore, Ï† Oi is a permutation:, then for_ _Ï†i, Ï† Ï†j, Ï†i :k O â†’Ï†O1, Ï†, i.e.,2, . . . Ï† Ï†i âˆˆmS, we have(O), where_
_âˆ€_ _âˆˆ{_ _}_

(Ï†iÏ†j)Ï†k = Ï†i(Ï†jÏ†k), (17)

the generators of Î¦ thus satisfy the Associativity property. However, whether the general elements of
Î¦ satisfy the Associativity property is unknown. We take âˆ€ _Ï•s, Ï•t, Ï•l âˆˆ_ Î¦, where Ï•t = _i_ _[Ï†]i[t][i]_ _[, Ï•][s][ =]_

_i_ _[Ï†]i[s][i]_ _[, Ï•][l][ =][ Q]i_ _[Ï†]i[l][i]_ [and][ t][i][, s][i][, l][i][ âˆˆ] [Z][, and we have]

[Q]

Q

(Ï•tÏ•s)Ï•l = _Ï†[t]i[i]_ _Ï†[s]i_ _[i]_ _Ï†[l]i[i]_ [=] _Ï†[t]i[i]_ _Ï†[s]i_ _[i]_ _Ï†[l]i[i]_ = Ï•t(Ï•sÏ•l). (18)

_i_ _i_ _i_ _i_ _i_ _i_ !

Y Y ! Y Y Y Y

Therefore, the set of mappings Î¦ satisfies the Associativity property under the composition of
functions.

2. We then verify the Identity property: âˆƒ _e âˆˆ_ Î¦, s.t. âˆ€ _Ï• âˆˆ_ Î¦, eÏ• = Ï•e = Ï•.

For generators Ï†i, Ï†j âˆˆ{Ï†1, Ï†2, . . . Ï†m}, we have Ï†[n]i _[Ï†][j][ =][ eÏ†][j][ =][ Ï†][j][. Therefore, for general]_
elements, we take âˆ€ _Ï• âˆˆ_ Î¦, Ï• = _i_ _[Ï†]i[k][i]_ [, and we have:]

_Ï†[n]i_ _[Ï•][ =][ e]_ _Ï†[k]i_ _[i]_ [= (][eÏ†][j][)][Ï†]j[k][j] _[âˆ’][1]_ _Ï†[k]i_ _[i]_ [=][ Ï†]j[k][j] _Ï†[k]i_ _[i]_ [=] _Ï†[k]i_ _[i]_ [=][ Ï•.] (19)

[Q]

Yi _i{Yi=Ì¸_ _j}_ _i{Yi=Ì¸_ _j}_ Yi

This states that the identity element of Î¦ is e = Ï†[n]i
the Identity property. _[âˆˆ]_ [Î¦][. Therefore, the set of mappings][ Î¦][ satisfies]

3. We finally verify the Inverse property: âˆ€ _Ï• âˆˆ_ Î¦, âˆƒ _Ï•[âˆ’][1]_ _âˆˆ_ _G : Ï•Ï•[âˆ’][1]_ = Ï•[âˆ’][1]Ï• = e.

For the generators Ï†i âˆˆ{Ï†1, Ï†2, . . . Ï†m}, we have Ï†[k]i _[Ï†]i[n][âˆ’][k]_ = Ï†[n]i [=][ e,][ 1][ â‰¤] _[k][ â‰¤]_ _[n, k][ âˆˆ]_ [Z][. For any]
general element Ï• âˆˆ Î¦, Ï• = _i_ _[Ï†]i[k][i]_ [, we have:]

_Ï•_ _Ï†[n]i_ _[âˆ’][k][i]_ = _Ï†[k]i_ _[i]_ [(][Ï†]j[k][j] _[Ï†]j[n][âˆ’][k][j]_ ) _Ï†[n]i_ _[âˆ’][k][i]_ = = e, (20)

[Q] _Â· Â· Â·_

Yi _i{Yi=Ì¸_ _j}_ _i{Yi=Ì¸_ _j}_

we denote _i_ _[Ï†][n]i_ _[âˆ’][k][i]_ as Ï•[âˆ’][1] and have Ï•Ï•[âˆ’][1] = e. Similarly, we also have Ï•[âˆ’][1]Ï• = e. These

two equations state that for any general element Ï• âˆˆ Î¦, Ï• = _i_ _[Ï†]i[k][i][, we have an inverse element]_
_Ï•[âˆ’][1]_ = _i_ _[Ï†][Q][n]i_ _[âˆ’][k][i]_ in Î¦. Therefore, the set of mappings Î¦ satisfies the Inverse property.

[Q]

To summarize, Î¦ is a group.

[Q]

Q.E.D.

**Step 2: In this step, we prove that the necessary and sufficient condition for the isomorphism**
(Z/nZ)[m] _âˆ¼< Ï†1, Ï†2, . . ., Ï†m > is the satisfaction of Ï†iÏ†j = Ï†jÏ†i, i = 1, 2, . . ., m and j =_
1, 2, . . ., m, and Ï†[n]i [=][ e, i][ = 1][,][ 2][, . . ., m][.]


-----

_â‡’) Assume the isomorphism is Ï„ : G = (Z/nZ)[m]_ _â†’_ Î¦ =< Ï†1, Ï†2, . . ., Ï†m >, for generators

_Ï†Ï†ji, Ï†, wherej âˆˆ{ gÏ†i1, i, Ï† = 12, . . . Ï†, 2, . . ., mm}, there exist denotes the generators in gÎ± =_ _i_ _[Î±][i][g][i][, g] G[Î²][ =], which is the m-dimensional one-hot vector[ P]i_ _[Î²][i][g][i][ âˆˆ]_ _[G, s.t. Ï„]_ [(][g][Î±][) =][ Ï†][i][, Ï„] [(][g][Î²][) =]
(0, . . ., 1, . . ., 0) _G with 1 in position i and 0 elsewhere, and[P]_ _Î±i, Î²i_ Z. Since G is an Abelian
group, we have _âˆˆ_ _âˆˆ_

_Ï†iÏ†j = Ï„_ (gÎ±)Ï„ (gÎ²) = Ï„ (gÎ±gÎ²) = Ï„ (gÎ²gÎ±) = Ï„ (gÎ²)Ï„ (gÎ±) = Ï†jÏ†i. (21)

For generatorscomposition of itself is Ï†i âˆˆ{Ï†1, Ï†2, . . . Ï†m}, we have gÎ± = _i_ _[Î±][i][g][i][ âˆˆ]_ _[G, s.t. Ï„]_ [(][g][Î±][) =][ Ï†][i][, the][ n][ times]

_Ï†[n]i_ [=][ Ï„] [(][g][Î±][)][n][ =][ Ï„] [(][ng][Î±][) =][ Ï„] [(] _Î±ingi) =[P] Ï„_ ( _Î±ieG) = Ï„_ (eG) = e, (22)

_i_ _i_

X X

where eG, e are identity elements of G and Î¦ respectively. In Equation 22, Ï„ (eG) = e holds because
_Ï„ is an isomorphism, and ker(Ï„_ ) = _eG_ . The sufficiency is proven.
_{_ _}_

_â‡) In the following, we prove that when two conditions are satisfied simultaneously, the mapping Ï„_
we define is an isomorphism. Considering the mapping Ï„ : Î¦ â†’ _G, defined as_
_Ï„ : Ï†i 7â†’_ _gi;_ (23)
_Ï„ : Ï†iÏ†j_ _gi + gj._
 _7â†’_

For general elements Ï•t, Ï•s âˆˆ Î¦, where Ï•t = _i_ _[Ï†]i[t][i]_ _[, Ï•][s][ =][ Q]i_ _[Ï†]i[s][i]_ [and][ t][i][, s][i][ âˆˆ] [Z][, we have]

_Ï„_ (Ï•tÏ•s) = Ï„ _Ï†[t]i[i]_ _Ï†[s]i_ _[i]_ [Q]= Ï„ _Ï†[t]i[i][+][s][i]_ = (ti + si)gi. (24)

_i_ _i_ ! _i_ ! _i_

Y Y Y X

Note that these terms can be merged since Ï†iÏ†j = Ï†jÏ†i. The summation on the right side of
Equation 24 is partitioned into two parts as follows


_Ï†[t]i[i]_


_Ï†[s]i_ _[i]_


= Ï„ (Ï•t) + Ï„ (Ï•s). (25)


(ti + si)gi =


_tigi +_


_sigi = Ï„_


+ Ï„


Consequently, we have Ï„ (Ï•tÏ•s) = Ï„ (Ï•t) + Ï„ (Ï•s), which states that Ï„ is a homomorphism. Then, we
only need to prove that mapping Ï„ is bijective. First, we prove Ï„ is injective, i.e., ker(Ï„ ) = _eG_,
_{_ _}_
after that, we prove Ï„ is surjective, i.e., one can find the inverse image of any element.

Since it is not hard to obtain Ï„ (Ï•) = Ï„ (e _Ï•) = Ï„_ (e) + Ï„ (Ï•), we have Ï„ (e) = (0, . . ., 0) = eG, i.e.,
_Â·_
_e âˆˆ_ _Ï„_ _[âˆ’][1](eG). Assume there is Ï•l =_ _i_ _[Ï†]i[l][i]_ _[, s.t. Ï„]_ [(][Ï•][l][) =][ e][G][, we have]

_Ï„_ (Ï•l) = _i_ _ligi = eG â‡’_ _li[Q]|n (li are divisible by n) â‡’_ _Ï•l =_ _i_ _Ï†[l]i[i]_ [=] _i_ _e = e._ (26)
X Y Y

The equation above states that Ï„ (eG) = _e_ (Ï„ : Î¦ Î¦) and mapping Ï„ is injective. We take

_[âˆ’][1]_ _{_ _}_ _â†’_
_âˆ€_ _g âˆˆ_ _G, g = (k1, k1, . . ., km) âˆˆ_ (Z/nZ)[m], and have


_Ï†[k]i_ _[i]_


(27)


_g = (k1, . . ., 0) +_ + (0, . . ., km) =
_Â· Â· Â·_


_kigi = Ï„_


Hence, we haveÏ„ is bijective and homomorphism, Ï„ _[âˆ’][1](g) =_ _i_ _[Ï†]i[k][i]_ _Ï„[âˆˆ] is an isomorphism.[Î¦][, which indicates that mapping][ Ï„][ is surjective. Since mapping]_

Q.E.D. [Q]

D PROOF FOR THEOREM 3

_Proof. In the following, we prove that the necessary and sufficient condition for satisfying Abel and_
Order constraints is that both Abel and Order Loss are minimized.

_â‡’image) For the condition: o âˆˆ_ _O can be obtained by âˆ€_ _Ï†i, Ï†j âˆˆ_ Î¦, 0 â‰¤ _i, j â‰¤_ _m, we have Ï†iÏ†j = Ï†jÏ†i. The constraint on any_

_Ï†i(Ï†j(o)) = Ï†j(Ï†i(o))_ _Ï†i(Ï†j(o))_ _Ï†j(Ï†i(o)) = 0._ (28)
_â‡’_ _âˆ’_


-----

For the set of combinations of factors C = {(i, j)|1 â‰¤ _i, j â‰¤_ _m} and the set containing images O,_
we have
_La =_ _oXâˆˆO_ (i,jX)âˆˆC _âˆ¥Ï†i Â· (Ï†j Â· o) âˆ’_ _Ï†j Â· (Ï†i Â· o)âˆ¥_ is minimized. (29)

We obtain the Abel loss. For the Order loss, we first consider n times composition of the same
mapping Ï†i, we have
_Ï†[n]i_ [=][ e][ â‡’] _[Ï†]i[n][âˆ’][1]Ï†i = Ï†iÏ†i[n][âˆ’][1]_ = e. (30)

Therefore, we then have Ï†[âˆ’]i [1] = Ï†[n]i _[âˆ’][1]. For a single image o_ _O, we have_
_âˆˆ_

_Ï†i(Ï†[n]i_ _[âˆ’][1](o)) = Ï†i(Ï†[âˆ’]i_ [1][(][o][)) =][ o][ â‡’] _[Ï†][i][(][Ï†]i[âˆ’][1][(][o][))][ âˆ’]_ _[o][ = 0][.]_ (31)

Thus, for the set of factors and the set containing all images O, we have


_Ï†i_ (Ï†[âˆ’]i [1] _o)_ _o_ is minimized. (32)
0â‰¤Xiâ‰¤m _âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_


_oâˆˆO_


To eliminate the bias of optimization, we optimize the symmetry form of the Order Loss, and we have


( _Ï†i_ (Ï†[âˆ’]i [1] _o)_ _o_ + _Ï†[âˆ’]i_ [1] (Ï†i _o)_ _o_ ) is optimized. (33)
0â‰¤Xiâ‰¤m _âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_ _âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_


_Lo =_


_oâˆˆO_


The Order Loss is obtained.

_â‡)When the Abel Loss La is optimized, for âˆ€_ _o âˆˆ_ _O, we have_

_Ï†i(Ï†j(o))_ _Ï†j(Ï†i(o)) = 0_ _Ï†i(Ï†(o)) = Ï†j(Ï†i(o))._ (34)
_âˆ’_ _â‡’_

Therefore, forobtain the Abel constraint. When the Order Loss âˆ€ _Ï†i, Ï†j âˆˆ_ Î¦, i = 1, 2, . . ., m and L j = 1o is minimized, for, 2, . . ., m, we have âˆ€ _o âˆˆ Ï†Oi, we haveÏ†j = Ï†jÏ†i, and we_

_Ï†i(Ï†[âˆ’]i_ [1][(][o][))][ âˆ’] _[o][ = 0][ â‡’]_ _[Ï†][i][(][Ï†]i[âˆ’][1][(][o][)) =][ o.]_ (35)

This implies that
_Ï†[n]i_ [=][ Ï†][i] _i_ = Ï†i _Ï†[âˆ’]i_ [1] = e. (36)

_[â—¦]_ _[Ï†][n][âˆ’][1]_ _â—¦_

Therefore, we obtain the Order constraint. The Group constraints are satisfied.


-----

E THE DATA CONSTRAINT

In this section, we prove that if each dimension of the world state is independently sampled (p(w) =
Î ip(wi), where p denotes the probability mass function (for discrete random variable) or probability
density function (for continuous random variable)), then the minimization of total correlation (p(z) =
Î ip(zi)) is a necessary condition to satisfy the data constraint (see Theorem 4 and Theorem 5 below).

Our goal is to learn a representation z conforming to the group-based definition of disentanglement
with an encoder h and a decoder d. Then the data constraint can be formulated as follows. For a
generatorcorresponding permutation of gi âˆˆ _G, we have b g(ig under the isomorphism betweeni Â· w) = Ï†i Â· b(w) = h[âˆ’][1](gi Â· G z) and, where Î¦. We reorganize the formula z = f_ (w) and Ï†i is the
and have h _b(gi_ _w) = f_ (gi _w) = gi_ _z._
_â—¦_ _Â·_ _Â·_ _Â·_

**Theorem 4and the action of each generator Assume that the action of generator gi on w only affects a single dimension of gi on z is gi Â· z = z + g wi (element-wise addition), (see the assumptions in**
_Section 3.2). Then the equation f_ (gi _w) = gi_ _z,_ _w_ _W is equivalent to: for each i = 1, 2, . . ., n,_
_there exists a bijective function Î³i s.t. z Â·_ _i = Î³i Â·(wj âˆ€) for some âˆˆ_ _j._

_Proof. â‡’) Without loss of generality, we assume gi only affects the j-th dimension of w. If the_
equation f (gi _w) = gi_ _z,_ _w_ _W holds, itâ€™s obvious that, for each i, there exists a bijective_
function Î³i s.t. Â· zi = Î³i(w Â·j). _âˆ€_ _âˆˆ_

_â‡for) In the following, we use i = 1, . . ., n, the functions (g zi Â·iw =)i Î³ ((i(gwi Â·j)z hold for some)i) to denote the j, by using an index permutation i-th dimension of vector gi Â·_ _w ( jg =i Â·_ _z Ï€). If(i)_
we can rewrite the function as zi = Î³i(wÏ€(i)). Therefore, z can be formulated as follows

_f_ (w1, . . ., wn) = z = (z1, . . ., zn) = (Î³1(wÏ€(1)), . . ., Î³n(wÏ€(n))). (37)

Please note that how the world state transits on dimension i dose not affect how disentangled the
representation is. Therefore, we define action of generator gi on w as follows.

_gi_ _w = gi_ (w1, . . ., wn) = (w1, . . ., (gi _w)j, . . ., wn) = (w1, . . ., Î³i[âˆ’][1]((gi_ _z)i), . . ., wn), (38)_
_Â·_ _Â·_ _Â·_ _Â·_

Then, we take f on both sides of the above equation, and apply Equation 37, and have

_f_ (gi _w)_ = f (w1, . . ., Î³i[âˆ’][1]((gi _z)i), . . ., wn) = (Î³1(wÏ€(1)), . . ., Î³i(Î³i[âˆ’][1]((gi_ _z)i)), . . ., Î³n(wÏ€(n)))_
_Â·_ _Â·_ = (z1, . . ., (gi _z)i, . . ., zn) = gi_ _z_ _Â·_
_Â·_ _Â·_ (39)
Q.E.D.

Note that it is obvious that the following theorem (Theorem 5) holds for discrete random variables
and bijective functions. However, since the world state space is dense and the encoder h and decoder
_d are differentiable in general, we also prove for the case where w and z are treated as continuous_
random variables. Theorem 5 states that the minimization of total correlation (p(z) = Î ip(zi)) is a
necessary condition to make equations zi = Î³i(wÏ€(i)) satisfied, where i = 1, 2, . . ., n and Ï€(i) is an
index permutation.


**Theorem 5 For the independent random variables w1, w2, . . ., wn, considering the functions zi =**
_Î´i(w1, w2, . . ., wn), where i = 1, 2, . . ., n and each Î´i is a bijective, differentiable function. For_
_i = 1, . . ., n, if there exists an index permutation Ï€(i) s.t., we have_ _âˆ‚zâˆ‚wÏ€(ii)_ = 0Ì¸ _and_ _âˆ‚zâˆ‚wÏ€(ki)_ [= 0][, where]

_k = 1, 2 . . ., n but k Ì¸= i, then the new random variables z1, z2, . . ., zn are independent._

_Proof. We treat the random variables w1, w2, . . ., wn as an n-dimensional random vector W =_
(w1, w2, . . ., wn). Similarly, we write Z = (zÏ€(1), zÏ€(2), . . ., zÏ€(n)), which is rearranged by index
permutation Ï€(i). According to Change of Variable Theorem For Random Vectors (Mood, 1950), we
have

_p(Z)_ _J(W_ ) = p(W ) = Î ip(wi) (40)
_|_ _|_

where J(W ) is the jacobian matrix of Z w.r.t. W, the (i, j)-th entry of it is _âˆ‚zâˆ‚wÏ€(ji)_ [. Since for each]

_i = 1, . . ., n, we have_ _âˆ‚zâˆ‚wÏ€(ii)_ = 0Ì¸ and _âˆ‚zâˆ‚wÏ€(ki)_ [= 0][, where][ k][ = 1][,][ 2][ . . ., n][ but][ k][ Ì¸][=][ i][, then the jacobian]


-----

matrix can be formulated as follows


_âˆ‚zÏ€(i)_
_J(W_ ) = Î i (41)

_âˆ‚wi_

According to Change of Variable Theorem For Random Variable ( Mood (1950)), we have


_p(zÏ€(i))|_ _[âˆ‚z]âˆ‚w[Ï€][(]i[i][)]_ _| = p(wi)_ (42)

Bring Equation 41 and Equation 42 into Equation 40, we have


Î ip(zÏ€(i))Î i _âˆ‚zâˆ‚wÏ€(ii)_

_p(Z) = Î [Î ]i[i][p]âˆ‚zâˆ‚w[(][w]Ï€(i[i]i)[)]_ = Î i _âˆ‚zâˆ‚wÏ€(ii|)_ _[|]_ = Î ip(zÏ€(i)) = Î ip(zi) (43)

_|_ _[|]_ _|_ _[|]_


Q.E.D.


Please note that the inverse proposition of the theorem above does not hold. As a counterexample, for
zero mean independent gaussian random variables w1, w2 with common variance Ïƒ[2], new random
variables z1 = _w1[2]_ [+][ w]2[2] [(the norm of vector][ (][w][1][, w][2][)][),][ z][2][ = tan][âˆ’][1][(][w][2][/w][1][)][ (the angle between]

vector (w1, w2)p and (0, 1)) are independent (Mood, 1950) but _âˆ‚wâˆ‚zij_

addition, the sufficiency would be satisfied for some specific settings, e.g., there are only two[Ì¸][= 0][ for all][ i, j][ âˆˆ{][1][,][ 2][}][. In]
independent uniformly distributed random variables w1, w2, and the functions z1, z2 are linear
functions.

Combining Theorems 4 and 5, we have that the minimization of total correlation (p(z) = Î ip(zi)) is
a necessary condition to satisfy the data constraint.

F DETAILS OF IMPLEMENTATION

F.1 ABEL LOSS DETAILS

As mentioned in the main paper, the Abel Loss of the VAE-based models is as follows:

_La =_ _oXâˆˆO_ (i,jX)âˆˆC _âˆ¥Ï†i Â· (Ï†j Â· o) âˆ’_ _Ï†j Â· (Ï†i Â· o)âˆ¥,_ (44)

where Ï†i (Ï†j _o) = Ï†i(Ï†j(o)) represents the top path of Figure 7 (a), and Ï†j_ (Ï†i _o) = Ï†j(Ï†i(o))_
represents the bottom path of Figure 7 (a). For better optimization, we constrain such consistency on Â· _Â·_ _Â·_ _Â·_
their representation (straight dotted double arrow in Figure 7 (a)) instead of the reconstructed images.
Besides, we constrain the consistency between the representations of intermediate images (curved
dotted double arrow in Figure 7 (a)).

Encoder Decoder Encoder Decoder Encoder Decoder Encoder Decoder

|Encoder|Decoder|
|---|---|



Encoder Decoder Encoder Decoder Encoder Decoder Encoder Decoder

(a) Abel Loss (b) Order Loss

Encoder Decoder Encoder Decoder

Encoder Decoder Encoder Decoder

(b) Order Loss

Encoder Decoder Encoder Decoder

Encoder Decoder Encoder Decoder

(a) Abel Loss

Figure 7: Overview of the Isomorphism Loss. The Abel Loss and Order Loss constrain the commutativity and cyclicity of permutation group Î¦, respectively. The dotted lines in the figure represents
reconstruction loss.
F.2 ORDER LOSS DETAILS

As mentioned in the main paper, the Order Loss of VAE-based models is as follows:


_Ï†i_ (Ï†[âˆ’]i [1] _o)_ _o_ + _Ï†[âˆ’]i_ [1] (Ï†i _o)_ _o_ _,_ (45)
_âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_ _âˆ¥_ _Â·_ _Â·_ _âˆ’_ _âˆ¥_



_Lo =_


_oâˆˆO_


_iâˆˆI_


-----

where Ï†i (Ï†[âˆ’]i [1] _o) represents the lower path of Figure 7 (b), and Ï†[âˆ’]i_ [1] (Ï†i _o) represents the_
upper path of Figure 7 (b). Similar to the Abel Loss, we do not constrain such consistency on the Â· _Â·_ _Â·_ _Â·_
reconstructed images for better optimization but on their representations instead (the long curved
dotted line in Figure 7 (b)). Besides, we constrain the consistency between the representations of
intermediate images (short curved dotted lines in Figure 7 (b)).

F.3 THE NUMBER OF FACTORS m

For the given VAE-based models, dimensional KL divergence (indicating the meaningful dimensions)
increases during the training process. Therefore, we use m dimensions of which the corresponding
dimensional KL divergence KLi _T_, where T is a hyperparameter, which is empirically set to 30
in our experiments. _â‰¥_


-----

G DETAILS OF EXPERIMENTS

G.1 DATASET DETAILS

In all the experiments, we resize the images to 64 Ã— 64 resolution. We introduce all the datasets used
in our paper in detail.

**dSprites Higgins et al. (2017): dSprites contains 737,280 binary 2D shapes (heart, oval and square)**
images with five ground truth factors: shape (3 values), scale (6 values), orientation (40 values),
x-position (32 values), y-position (32 values). Then we introduce the variants of dSprites (Color
dSprites and Noisy dSprites) created by Locatello et al. Locatello et al. (2019b).

**Color dSprites, the shapes of the images in dSprites are randomly colored.**

**Noisy dSprites, the background of the images in dSprites is noise.**

**Shapes3D Kim & Mnih (2018): Shapes3D contains 480,000 images of 3D shapes with 6 ground**
truth factors: shape (4 values), scale (8 values), orientation (15 values), floor color (10 values), wall
color (15 values), object color (10 values).

**Cars3D Reed et al. (2015): This dataset consists of 183 car CAD models, each rendered from 24**
azimuth directions and 4 elevations.

Encoder Decoder

Input: 64Ã—64 Ã— number of channels Input: 10 or 20
4 Ã— 4 conv, 32 ReLU, stride 2 FC, 256 ReLU
4 Ã— 4 conv, 32 ReLU, stride 2 FC, 256 ReLU
4 Ã— 4 conv, 32 ReLU, stride 2 FC, 4 Ã— 4 Ã— 32 ReLU
4 Ã— 4 conv, 32 ReLU, stride 2 4 Ã— 4 deconv, 32 ReLU, stride 2
FC 256 ReLU 4 Ã— 4 deconv, 32 ReLU, stride 2
FC 256 ReLU 4 Ã— 4 deconv, 32 ReLU, stride 2
FC 2Ã— 10 4 Ã— 4 deconv, number of channels, stride 2

Table 3: Architecture of the encoder and decoder of VAEs. For Original VAE, the dimension of input
of the decoder is 10. For Groupified VAE, the dimension is 20. Note that the number of representation
dimensions of Groupified VAE is still 10, which is the same as Original VAE, the comparison with
Original VAE is fair Watters et al. (2019).

G.2 ARCHITECTURE FOR ENCODER AND DECODER

We follow Locatello et al. Locatello et al. (2019b) to use the same architecture of VAEs in all of the
experiments: the activation function used is ReLU except for the last layer of decoder, as shown in
Table 3. For the details of the Discriminator in FactorVAE, please refer to Table 5 (a) and (c).

Model Parameter Value

_Î²-VAE_ _Î²_ [10; 20; 30;]
AnnealedVAE C [10; 20; 30;]
start [3e4; 4e4; 5e4;]
end [2e4; 3e4; 4e4;]
FactorVAE _Î³_ [5; 10; 15]
_Î²-TCVAE_ _Î²_ [6; 9; 12]
random seed [1; 2; 3; 4; 5; 6; 7; 8; 9;]
group [True; False]

Table 4: Hyperparameters and random seeds for every model.


-----

(c) Architecture of Discriminator

Discriminator

FC, 1000 LReLU
FC, 1000 LReLU
FC, 1000 LReLU
FC, 1000 LReLU
FC, 1000 LReLU
FC, 1000 LReLU
FC, 2


(a) Optimizer for Discriminator

Parameter Values

Batch size 64
Optimizer Adam
Adam: beta1 0.9
Adam: beta2 0.999
Adam: epsilon 1.0e-8
Adam: learning rate 0.0001


(b) General hyperparameters for VAE

Parameter Values

Batch size 64
Representation dimension 10
Optimizer Adam
Adam: beta1 0.9
Adam: beta2 0.999
Adam: epsilon 1.0e-8
Adam: learning rate 0.0001
Decoder type Bernoulli


Table 5: Shared hyperparameters in all experiments. LReLU stands for leaky ReLU.

G.3 EXPERIMENT SETTINGS

We run using different hyperparameters and random seeds for every VAE-based model implemented
by Pytorch Paszke et al. (2017). As shown in Table 4, for Î²-VAE, we assign 3 choices for Î² and 10
random seeds for both the Original and Groupified VAEs: 3 Ã— 10 Ã— 2 = 60 settings for each dataset.
Similarly, we also assign 60 settings for FactorVAE and Î²-TCVAE. For AnnealVAE, we assign three
choices for C and 3 choices for the start and end pair, also assign 10 random seeds. In summary,
for all 5 datasets, we run (((3 Ã— 10 Ã— 2) Ã— 3) + 3 Ã— 3 Ã— 10 Ã— 2) Ã— 5 = 1800 models. For other
hyperparameters, please refer to Table 5 (b).

H RELATION TO SOME PREVIOUS WORKS

H.1 SYMMETRY-BASED DISENTANGLEMENT

Caselles-Dupre et al. (2019) argue that the symmetry-based disentanglement requires interactionÂ´
with the environments. Specifically, for a given disentangled representation z w.r.t. a world with
some group action on W, there are multiple other worlds (same world states and symmetry) of
a static dataset that have different group actions on each dimension of W . For those worlds, the
representation z is not disentangled, per the group-based definition. However, in our work, we do
not assume that a static dataset has a world equipped with some specific fixed group action on W in
advance, instead we use permutation group Î¦ as an agent to learn a world with proper group actions.
For this learned world, there is only one representation that satisfies the definition. Therefore, we
do not need an environment to provide group actions on W to determine which world it is. Please
see our proof in Theorem 1. In the testing phase, since we input the images to the model directly
to derive their representation, the disentanglement of the representation does not rely on how the
world state transitions between each other (i.e., as a result of group actions on W ). Therefore, our
framework can learn such a disentangled representation without interaction with the environments.

H.2 LIE GROUP VAE

Zhu et al. (2021) argue that the representation space being a vector space is sub-optimal since it
requires the model to learn to discard different scales of variations. They propose to use lie group
as the representation space instead and use Hessian Penalty to encourage disentanglement. Our
framework is complimentary to their proposed method. The lie group representation can be applied
to extend our framework. Here we leave it for future work. In addition, our proposed representation
mapped by the sine and cosine function (exp((2Ï€iz)/n) for a real vector z) is also a lie group.


-----

I MORE QUANTITATIVE RESULTS AND SCORE DISTRIBUTION

I.1 QUANTITATIVE RESULTS

The performance of the Original and Groupified VAEs on all five datasets is shown in Table 6. Our
method outperforms the original one on most of the datasets in terms of nearly all the metrics.

DCI BetaVAE MIG FactorVAE
dSprits

Original Groupified Original Groupified Original Groupified Original Groupified

AnnealVAEFactorVAEÎ²-TCVAEÎ²-VAE 0000....35232838 Â± Â± Â± Â± 0 0 0 0....065101010 **0000...463941.36 Â± Â± Â± Â± 0 0 0 0...085056074.11** **0000....89758486 Â± Â± Â± Â± 0 0 0 0....083050026040** **0000....878618689 Â± Â± Â± Â± 0 0 0 0...0067051020.038** 0000....14271723 Â± Â± Â± Â± 0 0 0 0....09709206710 **0000....37343124 Â± Â± Â± Â± 0 0 0 0....089061061093** **0000....70517468 Â± Â± Â± Â± 0 0 0 0....098068098094** **0000....63687570 Â± Â± Â± Â± 0 0 0 0....058089075098**

DCI BetaVAE MIG FactorVAE
Cars3d

Original Groupified Original Groupified Original Groupified Original Groupified

AnnealVAEFactorVAEÎ²-TCVAEÎ²-VAE 0000....18222124 Â± Â± Â± Â± 0 0 0 0....059046054049 **0000....24252526 Â± Â± Â± Â± 0 0 0 0....041046040046** 000.99..99199. Â±0 Â± Â± Â± 1 1 4. 06eee âˆ’. âˆ’0 âˆ’443 **0.99111 Â±...000 Â± Â± Â± 1. 0 0 05e...000 âˆ’** **4** 0000....07107409810 Â± Â± Â± Â± 0 0 0 0....021032027016 **0000....10111111 Â± Â± Â± Â± 0 0 0 0....014032033033** 0000....81908882 Â± Â± Â± Â± 0 0 0 0....066039040062 **0000....93879393 Â± Â± Â± Â± 0 0 0 0....034028034034**

Noisy DCI betaVAE MIG FactorVAE
dSprits Original Groupified Original Groupified Original Groupified Original Groupified

Anneal VAEFactorVAEÎ²BetaVAE-TCVAE **0000....114056053081 Â± Â± Â± Â± 0 0 0 0....018013036062** **0000....099087060111 Â± Â± Â± Â± 0 0 0 0....057051022053** 0000....682624631605 Â± Â± Â± Â± 0 0 0 0....090036081053 **0000....647644684635 Â± Â± Â± Â± 0 0 0 0....055031070050** **0000....077030035040 Â± Â± Â± Â± 0 0 0 0....022027030046** **0000....066065047068 Â± Â± Â± Â± 0 0 0 0....046055032042** 0000....355434353437 Â± Â± Â± Â± 0 0 0 0....093080091098 **0000....407468481431 Â± Â± Â± Â± 0 0 0 0....071098087097**

DCI BetaVAE MIG FactorVAE
Shapes3d

Original Groupified Original Groupified Original Groupified Original Groupified

AnnealVAEFactorVAEÎ²-TCVAEÎ²-VAE 0000....44526647 Â± Â± Â± Â± 0 0 0 0....1760511010 **0000....49726056 Â± Â± Â± Â± 0 0 0 0....06506107810** **0000....86978291 Â± Â± Â± Â± 0 0 0 0....076072055039** 0000....90898096 Â± Â± Â± Â± 0 0 0 0....045075042086 0000....48283340 Â± Â± Â± Â± 0 0 0 0....047181318 **0000....47504243 Â± Â± Â± Â± 0 0 0 0....0900521511** **0000....81827589 Â± Â± Â± Â± 0 0 0 0....074064056098** **0000....82839079 Â± Â± Â± Â± 0 0 0 0....066043066046**


Color DCI betaVAE MIG FactorVAE
dSprits Original Groupified Original Groupified Original Groupified Original Groupified

Anneal VAEFactorVAEÎ²BetaVAE-TCVAE 0000....174268294338 Â± Â± Â± Â± 0 0 0 0....097103101052 **0000....328337322395 Â± Â± Â± Â± 0 0 0 0....130114104082** 0000....798843861876 Â± Â± Â± Â± 0 0 0 0....094038038024 **0000....844856862881 Â± Â± Â± Â± 0 0 0 0....050031029031** 0000....103219203169 Â± Â± Â± Â± 0 0 0 0....058084080040 **0000....243252236269 Â± Â± Â± Â± 0 0 0 0....118104091090** **0000....718739591711 Â± Â± Â± Â± 0 0 0 0....148086065068** **0000....648786692730 Â± Â± Â± Â± 0 0 0 0....094080092050**

Table 6: Performance (mean Â± std) on different datasets and different models with different metrics.
We evaluate Î²-VAE, AnnealVAE, FactorVAE, and Î²-TCVAE on dSprites, Cars3d, Shapes3d, NoisydSprites, and Color-dSprites for 1800 settings. These settings include different random seeds and
hyperparameters.

I.2 ABSTRACT REASONING & FAIRNESS
Abstract reasoningâ†‘ Unfairness scoresâ†“

As pointed out by Locatello et al. Locatello et al. Original 0.948 Â± 0.031 0.023 Â± 0.007
(2019b), the disentangled representationâ€™s down- Groupified **0.954 Â± 0.028** **0.018 Â± 0.008**
stream tasks should also be verified. Therefore, we verify the effectiveness of the repre- Table 7: Downstream task performance on the
sentations learned by the Groupified VAEs on models trained on the representation learned by
Shapes3d in two downstream tasks: abstract rea- original and groupified FactorVAE.
soning Van Steenkiste et al. (2019) and fairness evaluation Locatello et al. (2019a). As Table 7
shows, the performance of the abstract reasoning models fine-tuned on the representation learned by
the Groupified FactorVAEs is better than the original ones. In terms of fairness evaluation, we can
observe that the unfairness scores of the representation learned by the Groupified FactorVAEs are
lower than the Original ones.


I.3 SCORE DISTRIBUTION

The detailed distribution of the performance is shown in this section (demonstrated by the Violin
Plot Hintze & Nelson (1998)). The performance distributions on dSprits, Car3d, Noisy dSprites,


-----

Color-dSprites, and Shapes3d are shown in Figure 8, Figure 9, Figure 10, Figure 11 and Figure 12,
respectively.

I.4 COMPARISON WITH METHOD INTERACTION WITH THE ENVIRONMENT

Our work considers an unsupervised setting, which is a more practical one. To understand the price
to pay, we compare our unsupervised Groupified models to the methods that use the interaction with
the environment as supervision. Here we provide the comparison between RGrVAE (Painter et al.,
2020) and our Groupified Î²-TCVAE on dSprites, Shapes3D, and Color dSprites as shown in Table 8.

DCI BetaVAE MIG FactorVAE
Datasets

RGrVAE Groupified RGrVAE Groupified RGrVAE Groupified RGrVAE Groupified

Color dSpritesShapes3DdSprites 000...528311 Â± Â± Â± 0 0 0...058056072 000...367240 Â± Â± Â± 0 0 0...110061082 010...970053 Â± Â± Â± 0 0 0...039000294 000...869688 Â± Â± Â± 0 0 0...038042031 000...082503 Â± Â± Â± 0 0 0...042031028 000...244727 Â± Â± Â± 0 0 0...093090090 000...869831 Â± Â± Â± 0 0 0...073032309 000...709079 Â± Â± Â± 0 0 0...098046050

Table 8: Performance (mean Â± variance) on different datasets of RGrVAE and Groupified Î²-TCVAE
with different metrics. These settings include different random seeds and hyperparameters.

Since there are no results reported on Shapes3D and Color dSprites, we conduct experiments on
these two datasets with the official implementation[2] using the recommended hyper-parameters. In
addition, the results reported in Painter et al. (2020) are of models trained with 16 latent units and
3 random seeds. We also conduct experiments on dSprites with 10 latent units and 10 random
seeds, which is our setting. From Table 8, we observe that there is still a gap between RGrVAE and
_Groupified Î²-TCVAE, especially on Shapes3D. However, the latent learned by RGrVAE is not as_
pure as Groupified Î²-TCVAE (lower MIG). Additionally, RGrVAE performs poorly because a factor
(color) is not modeled in the environment of Color dSprites.

I.5 COMPARISON WITH CONTROLVAE

In this section, we provide a comparison between Original and Groupified ControlVAE (Shao
et al., 2020). For ControlVAE, we use the official implementation[3] and follow the default setting,
_Cmax = 25. We follow Locatello et al. (2019b) to set the hyperparameter interval to 10. For other_
parameters, we follow Shao et al. (2020). The results on dSprites, Shapes3D, and Color dSprites are
presented in Table 9.

DCI BetaVAE MIG FactorVAE
Datasets

Original Groupified Original Groupified Original Groupified Original Groupified

Color dSpritesShapes3DdSprites 000...315947 Â± Â± Â± 0 0 0...093144111 000...468554 Â± Â± Â± 0 0 0...115165055 000...838694 Â± Â± Â± 0 0 0...084142045 000...929796 Â± Â± Â± 0 0 0...061149024 000...162128 Â± Â± Â± 0 0 0...062212095 000...277235 Â± Â± Â± 0 0 0...123151055 000...625980 Â± Â± Â± 0 0 0...087174070 000...748884 Â± Â± Â± 0 0 0...110171022

Table 9: Performance (mean Â± variance) on different datasets of ControlVAE and Groupified ControlVAE with different metrics. These settings include different random seeds and hyperparameters.

From Table 9, we observe that our method consistently improved the performance of ControlVAE
under the same hyper-parameters, especially on Shapes3D.

I.6 DETAILED RESULTS UNDER DIFFERENT HYPER-PARAMETERS

In order to provide a more convincing comparison, we compare our method and the original one at
different levels of regularization parameters. We take Î²-TCVAE as an example. As Table 10, 11, and
12 show, our method consistently improves the performance of the original methods on most of the
metrics, especially on MIG and DCI.

2
[https://github.com/MattPainter01/UnsupervisedActionEstimation](https://github.com/MattPainter01/UnsupervisedActionEstimation)
3
[https://github.com/shj1987/ControlVAE-ICML2020](https://github.com/shj1987/ControlVAE-ICML2020)


-----

Regulize DCI BetaVAE MIG FactorVAE
strength

Original Groupified Original Groupified Original Groupified Original Groupified

_Î²Î²Î² = 12 = 6 = 9_ 000...333735 Â± Â± Â± 0 0 0...079051057 000...343638 Â± Â± Â± 0 0 0...106103114 000...868587 Â± Â± Â± 0 0 0...025028024 000...858786 Â± Â± Â± 0 0 0...032026051 000...151720 Â± Â± Â± 0 0 0...042053071 000...202430 Â± Â± Â± 0 0 0...093097098 000...686371 Â± Â± Â± 0 0 0...100092084 000...687071 Â± Â± Â± 0 0 0...105072104


Table 10: Performance (mean Â± variance) on dSprites of Original and Groupified Î²-TCVAE with
different metrics. The results under different regularize strength are reported.

Regulize DCI BetaVAE MIG FactorVAE
strength

Original Groupified Original Groupified Original Groupified Original Groupified

_Î²Î²Î² = 12 = 6 = 9_ 000...566775 Â± Â± Â± 0 0 0...080089053 000...687673 Â± Â± Â± 0 0 0...071048026 000...989796 Â± Â± Â± 0 0 0...028037044 000...979693 Â± Â± Â± 0 0 0...036048048 000...313851 Â± Â± Â± 0 0 0...123196151 000...425151 Â± Â± Â± 0 0 0...098084082 000...889092 Â± Â± Â± 0 0 0...046078059 000...908990 Â± Â± Â± 0 0 0...052045040


Table 11: Performance (mean Â± variance) on Shapes3D of Original and Groupified Î²-TCVAE with
different metrics. The results under different regularize strength are reported.

Regulize DCI BetaVAE MIG FactorVAE
strength

Original Groupified Original Groupified Original Groupified Original Groupified

_Î²Î²Î² = 12 = 6 = 9_ 000...353631 Â± Â± Â± 0 0 0...051019061 000...434035 Â± Â± Â± 0 0 0...073077081 000...898986 Â± Â± Â± 0 0 0...009013031 000...898887 Â± Â± Â± 0 0 0...016019020 000...171716 Â± Â± Â± 0 0 0...038037044 000...292724 Â± Â± Â± 0 0 0...073104083 000...737466 Â± Â± Â± 0 0 0...094077060 000...827975 Â± Â± Â± 0 0 0...027048051


Table 12: Performance (mean Â± variance) on Color dSprites of Original and Groupified Î²-TCVAE
with different metrics. The results under different regularize strength are reported.

-VAE
_Î²_

(a) BetaVAE score (b) DCI disentanglement (c) MIG (d) FactorVAE score


(e) BetaVAE score (f) DCI disentanglement (g) MIG (h) FactorVAE score

(i) BetaVAE score (j) DCI disentanglement (k) MIG (l) FactorVAE score


(m) BetaVAE score (n) DCI disentanglement (o) MIG (p) FactorVAE score

Figure 8: Performance distribution on dSprites. Variance is due to different hyperparameters and
random seeds. We consider four metrics: BetaVAE score, DCI disentanglement, MIG, and FactorVAE
score. We observe that Groupified VAEs outperform the original ones.


-----

(a) BetaVAE score (b) DCI disentanglement (c) MIG (d) FactorVAE score

(e) BetaVAE score (f) DCI disentanglement (g) MIG (h) FactorVAE score


(i) BetaVAE score (j) DCI disentanglement (k) MIG (l) FactorVAE score


(m) BetaVAE score (n) DCI disentanglement (o) MIG (p) FactorVAE score

Figure 9: Performance distribution on Cars3d. Variance is due to different hyperparameters and
random seeds. We observe that Groupified models outperform the Original ones.


-----

(a) BetaVAE score (b) DCI disentanglement (c) MIG (d) FactorVAE score

(e) BetaVAE score (f) DCI disentanglement (g) MIG (h) FactorVAE score


(i) BetaVAE score (j) DCI disentanglement (k) MIG (l) FactorVAE score


(m) BetaVAE score (n) DCI disentanglement (o) MIG (p) FactorVAE score

Figure 10: Performance distribution on Noisy dSprites. Variance is due to different hyperparameters
and random seeds. We observe that Groupified VAEs outperform the Original ones.


-----

(a) BetaVAE score (b) DCI disentanglement (c) MIG (d) FactorVAE score

(e) BetaVAE score (f) DCI disentanglement (g) MIG (h) FactorVAE score


(i) BetaVAE score (j) DCI disentanglement (k) MIG (l) FactorVAE score


(m) BetaVAE score (n) DCI disentanglement (o) MIG (p) FactorVAE score

Figure 11: Performance distribution on Color dSprites. Variance is due to different hyperparameters
and random seeds. We observe that Groupified VAEs outperform the Original ones.


-----

(a) BetaVAE score (b) DCI disentanglement (c) MIG (d) FactorVAE score

(e) BetaVAE score (f) DCI disentanglement (g) MIG (h) FactorVAE score


(i) BetaVAE score (j) DCI disentanglement (k) MIG (l) FactorVAE score


(m) BetaVAE score (n) DCI disentanglement (o) MIG (p) FactorVAE score

Figure 12: Performance distribution on Shapes3d. Variance is due to different hyperparameters and
random seeds. We observe that Groupified models outperform the Original ones.


-----

MORE QUALITATIVE RESULTS


We evaluate our methods qualitatively on two typical datasets: Cars3d and Shapes3d. We visualize
the traversal results of the Original and Groupified FactorVAE and Î²-TCVAE. For every factor, we
traverse five randomly sampled representations. As shown in Figure 13 and Figure 14, the traversal
results of the Groupified FactorVAE and Î²-TCVAE show that these models learn less entangled
representations on Shapes3D (e.g., Orientation of FactorVAE and Scale and Shape of Î²-TCVAE).

Similarly, as shown in Figure 15 and Figure 16, the Groupified FactorVAE and Î²-TCVAE achieve
better disentanglement ability on Car3d (e.g., Rotation of FactorVAE and Yaw of Î²-TCVAE).

For the real-world dataset, we show the qualitative comparison of the Groupified and original
AnnealVAE trained on CelebA. As Figure 17 shows, for most of the factors, our model can extract
cleaner semantics than the original model. For example, the hair color is entangled with the face
shape in the original model, but cleaner in the Groupified model.

Original

Groupified

(a) Orientation (b) Wall color (c) Object color (d) Floor color (e) Scale (f) Shape


Figure 13: Learned latent variables using Original and Groupified FactorVAE on Shapes3d dataset.
The traversal range is (-2, 2).

Original

Groupified

(a) Orientation (b) Wall color (c) Object color (d) Floor color (e) Scale (f) Shape


Figure 14: Learned latent variables using Original and Groupified Î²-TCVAE on Shapes3d dataset.
The traversal range is (-2, 2).


-----

(a) Yaw (b) Color (c) Whiten (d) Rotation

Figure 15: Learned latent variables using Original and Groupified FactorVAE on Car3d dataset. The
traversal range is (-2, 2).


(a) Azimuth (b) Yaw (c) Color (d) Whiten (e) Rotation


Figure 16: Learned latent variables using Original and Groupified Î²-TCVAE on Car3d dataset. The
traversal range is (-2, 2).

(a) Original (b) Groupified


hair length

gender


skin color

azimuth


hair style

skin color2

face shape


smile


glasses

Figure 17: Learned latent variables using Original and Groupified AnnealVAE on CeleBa dataset.
The traversal range is (-2, 2). The factors learned by Groupified model are less entangled.


-----

K MEANINGFUL DIMENSION VISUALIZATIONS

When we assign some dimensions to Isomorphism Loss for Groupified AnnealVAEs, e.g., the first-5
dimensions, we have an interesting observation that the assigned dimensions are meaningful in
_Groupified AnnealVAEs. The KL divergence increases continuously on these assigned dimensions_
after the Isomorphism Loss is applied to them. Note that the KL divergence loss in AnnealVAE
indicates the amount of information encoded. As Figure 18 shows, the KL divergence of assigned
dimensions increases at the beginning of training, which means Isomorphism Loss results in that
the assigned dimensions become meaningful. Finally, the assigned first-five dimensions learn to
encode the semantics of x position, y position, scale, and orientations. The possible reason is that
the latent factors are learned and disentangled in the assigned dimensions due to the punishment of
the Isomorphism Loss. To illustrate that controllable dimensions in Groupified AnnealVAE are not
an exception, we provide more visualizations. The results of covering all hyperparameters settings
with two random seeds are shown in Figure 18 to Figure 26, suggesting that their dimensions are
controllable.

(a) Dimensional KL in training (b) Dimensional KL in 3e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 3e5 steps (f) Images traversal of dimensions

Figure 18: Meaningful dimensions visualization for C = 10, end = 30000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.


-----

(a) Dimensional KL in training (b) Dimensional KL in 4e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 4e5 steps (f) Images traversal of dimensions

Figure 19: Meaningful dimensions visualization for C = 10, end = 40000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different amounts after training (b). As the image
traversal results (c) show, the meaningful dimensions are learned in 0-4 dims. So as (d), (e), and (f),
which are results of a run with a different random seed.

(a) Dimensional KL in training (b) Dimensional KL in 5e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 5e5 steps (f) Images traversal of dimensions

Figure 20: Meaningful dimensions visualization for C = 10, end = 50000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.


-----

(a) Dimensional KL in training (b) Dimensional KL in 3e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 3e5 steps (f) Images traversal of dimensions

Figure 21: Meaningful dimensions visualization for C = 20, end = 30000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different amounts after training (b). As the image
traversal results (c) show, the meaningful dimensions are learned in 0-4 dims. So as (d), (e), and (f),
which have a different random seed.

(a) Dimensional KL in training (b) Dimensional KL in 4e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 4e5 steps (f) Images traversal of dimensions

Figure 22: Meaningful dimensions visualization for C = 20, end = 40000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.


-----

(a) Dimensional KL in training (b) Dimensional KL in 5e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 5e5 steps (f) Images traversal of dimensions

Figure 23: Meaningful dimensions visualization for C = 20, end = 50000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.

(a) Dimensional KL in training (b) Dimensional KL in 3e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 3e5 steps (f) Images traversal of dimensions

Figure 24: Meaningful dimensions visualization for C = 30, end = 30000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.


-----

(a) Dimensional KL in training (b) Dimensional KL in 4e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 4e5 steps (f) Images traversal of dimensions

Figure 25: Meaningful dimensions visualization for C = 30, end = 40000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.

(a) Dimensional KL in training (b) Dimensional KL in 5e5 steps (c) Images traversal of dimensions

(d) Dimensional KL in training (e) Dimensional KL in 5e5 steps (f) Images traversal of dimensions

Figure 26: Meaningful dimensions visualization for C = 30, end = 50000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.


-----

L MORE REPRESENTATION SPACE VISUALIZATIONS

To illustrate that the Isomorphism Loss suppresses the representation space collapse in VAE-based
methods is not an exception, we provide more visualizations of the representation space visualization
of Groupified VAEs. The Original and Groupified Î²-VAEs, AnnealVAEs, FactorVAEs, and Î²TCVAEs are shown in Figure 27, Figure 28, Figure 29, and Figure 30, respectively, which implies
that the representation space of Groupified VAEs are organized better than the original ones.

(a) Î² = 10, Groupified (b) Î² = 10, Original (c) Î² = 10, Groupified (d) Î² = 10, Original

(e) Î² = 20, Groupified (f) Î² = 20, Original (g) Î² = 20, Groupified (h) Î² = 20, Original

(i) Î² = 30, Groupified (j) Î² = 30, Original (k) Î² = 30, Groupified (l) Î² = 30, Original

Figure 27: The representation space span by the Groupified and Original Î²-VAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. Higher hyper-parameter Î² results
in the collapse of representation space. The collapse is suppressed by the Isomorphism Loss, which
leads to better disentanglement.


-----

(a) C = 10, Groupified (b) C = 10, Original (c) C = 10, Groupified (d) C = 10, Original

(e) C = 20, Groupified (f) C = 20, Original (g) C = 20, Groupified (h) C = 20, Original

(i) C = 30, Groupified (j) C = 30, Original (k) C = 30, Groupified (l) C = 30, Original

Figure 28: The representation space span by the Groupified and Original AnnealVAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. Higher hyper-parameter C results
in the collapse of representation space. The collapse is suppressed by the Isomorphism Loss, which
leads to better disentanglement.


-----

(a) Î³ = 5, Groupified (b) Î³ = 5, Original (c) Î³ = 5, Groupified (d) Î³ = 5, Original

(e) Î³ = 10, Groupified (f) Î³ = 10, Original (g) Î³ = 10, Groupified (h) Î³ = 10, Original

(i) Î³ = 15, Groupified (j) Î³ = 15, Original (k) Î³ = 15, Groupified (l) Î³ = 15, Original

Figure 29: The representation space span by the Groupified and Original FactorVAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. The collapse is suppressed by the
Isomorphism Loss, which leads to better disentanglement.


-----

(a) Î² = 6, Groupified (b) Î² = 6, Original (c) Î² = 6, Groupified (d) Î² = 6, Original

(e) Î² = 9, Groupified (f) Î² = 9, Original (g) Î² = 9, Groupified (h) Î² = 9, Original

(i) Î² = 12, Groupified (j) Î² = 12, Original (k) Î² = 12, Groupified (l) Î² = 12, Original

Figure 30: The representation space span by the Groupified and Original Î²-TCVAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. Higher hyper-parameter C results
in the collapse of representation space. The collapse is suppressed by the Isomorphism Loss, which
leads to better disentanglement.


-----

