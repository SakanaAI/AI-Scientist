# SELF-CONSISTENT GRADIENT-LIKE EIGEN DECOM## POSITION IN SOLVING SCHR Â¨ODINGER EQUATIONS

**Anonymous authors**
Paper under double-blind review

ABSTRACT

The SchrÂ¨odinger equation is at the heart of modern quantum mechanics. Since
exact solutions of the ground state are typically intractable, standard approaches
approximate SchrÂ¨odingerâ€™s equation as forms of nonlinear generalized eigenvalue problems F (V )V = SV Î› in which F (V ), the matrix to be decomposed, is a function of its own top-k smallest eigenvectors V, leading to a â€œselfconsistency problemâ€. Traditional iterative methods heavily rely on high-quality
initial guesses of V generated via domain-specific heuristics methods based on
quantum mechanics. In this work, we eliminate such a need for domain-specific
heuristics by presenting a novel framework, Self-consistent Gradient-like Eigen
Decomposition (SCGLED) that regards F (V ) as a special â€œonline data generatorâ€, thus allows gradient-like eigendecomposition methods in streaming k-PCA
to approach the self-consistency of the equation from scratch in an iterative way
similar to online learning. With several critical numerical improvements, SCGLED is robust to initial guesses, free of quantum-mechanism-based heuristics
designs, and neat in implementation. Our experiments show that it not only can
simply replace traditional heuristics-based initial guess methods with large performance advantage (achieved averagely 25x more precise than the best baseline in
similar wall time), but also is capable of finding highly precise solutions independently without any traditional iterative methods.

1 INTRODUCTION

While the many-body SchrÂ¨odinger equation governs all quantum-mechanical systems, it can be
solved analytically only for extremely simple ones like an isolated hydrogen atom. Nonetheless, a
series of important approximation theories are developed so that it can be solved numerically for
many relevant molecules and materials including tens to thousands of electrons, making it possible
for physicists and chemists to explore the properties of matters in an ab-initio or first-principle way,
serving as a foundation of computational physics, chemistry and material science research.

Among those approximation theories, two mainstream directions involve the Hartree-Fock (Hartree,
1928; Hartree & Hartree, 1935) and density functional theories (Hohenberg & Kohn, 1964) that
either approximate the SchrÂ¨odinger equation as a â€œHartree-Fockâ€ equation or as a â€œKohn-Sham
equationâ€ (Kohn & Sham, 1965). While very different in nature, both approximated equations are
finally formed as a nonlinear, generalized eigenvalue problem F (V )V = SV Î› in which F (V ) and
_S are N_ _N real symmetric matrices, Î› = diag(Î»1,_ _, Î»k) is a k_ _k matrix containing the_
_Ã—_ _Â· Â· Â·_ _Ã—_
top-k smallest eigenvalues, and V = [v1, _, vk] is an N_ _k matrix containing the corresponding_
_Â· Â· Â·_ _Ã—_
top-k eigenvectors. Interestingly, the matrix F which we aim to decompose is explicitly defined as
a given function of the eigenvectors V (denoted as F (V ) : R[N] _[Ã—][k]_ _â†’_ R[N] _[Ã—][N]_ ), leading to a â€œcauseand-effect dilemmaâ€ or â€œself-consistency problemâ€. That is, the form of the equation is defined by
its final solution, but how does one know the solution if the form of the equation is not determined?

The dominant method in solve such equations is generally referred to as Self-Consistent Fields
(SCFs). SCFs are the main component of nearly all mainstream quantum chemistry and solid-state
physics software. The general idea is to perform a fixed-point iteration, that is, guess an initial
solution V0 from scratch, then solve F (Vk 1)Vk = SVkÎ›k repeatedly to obtain eigenvectors Vk at
_âˆ’_
the kth iteration, k = 1, 2, Â· Â· Â·, until âˆ¥F (Vk) _âˆ’_ _F_ (Vkâˆ’1)âˆ¥ is less than a given convergence threshold.
Unfortunately, there is no guarantee that such an iteration can always lead to a converged solution


-----

(Froese Fischer, 1987). Actually, SCFs are extremely sensitive to the selection of initial guess V0.
Without a high-quality initialisation, SCFs easily fail and oscillate between two or more different
results.

Till now, all popular choices for the initial guess are heuristics-based, highly reliant on specialized
prior knowledge of quantum mechanics. For example, the SAD method (Van Lenthe et al., 2006)
applies the physical intuition that molecular electron densities can be approximated via the sum of
atomic electron densities. Here, the core Hamiltonian method ignores all interactions between electrons, which simplifies the equation to a standard eigen-decomposition problem. More methods and
details can be found in (Lehtola, 2019). Besides the prerequisite of domain-specific theories, such
methods are also sophisticated in implementation to achieve satisfactory convergence performance,
which is a main barrier for practitioners to build high-performance solvers from scratch.

Meanwhile, in the machine learning community, researchers are facing the challenge of analyzing
real-time, online data represented as streams. In contrast to the normal case that data is fully available offline, online data is received sequentially and may even change over time, thus specialized
methods are developed to dynamically adapt to new patterns in the data stream, which is called
stochastic, streaming or online algorithms. Specially, a series of works (Oja, 1982; Tang, 2019;
Allen-Zhu & Li, 2017; Gemp et al., 2021) focus on stochastic k-PCA, which aim to estimate the
top-k principal components of a data stream in a real-time manner. To handle the stochasticity
of data, such stochastic k-PCA methods usually contain gradient-like eigen decomposition. When
a new data sample is available, the eigenvectors will be updated towards a gradient-like direction
computed by the new sample, with a small learning rate.

In this work, we noticed that F (V ) in the aforementioned eigen-decomposition problem is sub
ject to concurrent update during the sequential update of V towards self-consistency: V1 _F =F (V1)_

_V2_ _F =F (V2)_ . In this case F (V ) can be regarded as a special â€œonline data generatorâ€, whichâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
_âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’Â· Â· Â·_
shares similarities with the online learning setting that online data is concurrently updated during
the sequential learning process. In this way, we explore the possibility of applying gradient-like
eigen-decomposition in stochastic k-PCA methods to handle the self-consistency of approximated
SchrÂ¨odinger equations. Together with several numerical improvements to enhance the smoothness
of optimization, we developed Self-consistent Gradient-like Eigen Decomposition (SCGLED), an
efficient solver for the self-consistent approximated SchrÂ¨odinger equations, SCGLED is robust to
initial guesses V0, free of quantum-mechanism-based heuristics design, and neat in implementation.
While it can simply replace traditional heuristics-based initial guess methods with performance advantage, it is also capable of finding highly precise solutions without any traditional SCF iteration.

2 RELATED WORK

The computational theories for quantum many-body systems, especially for determining the wave
function of SchrÂ¨odinger equations, has a long history starting from 1920s. There are three mainstream theories: Hartree-Fock theory (Hartree, 1928; Hartree & Hartree, 1935), density functional
theory (Hohenberg & Kohn, 1964) and quantum Monte Carlo. With the prosperity of deep learning
and differentiable optimization in recent years, there are a series of works focusing on deep-learningaided wave function representation of quantum Monte Carlo methods such as FermiNet (Pfau et al.,
2020) and PauliNet (Hermann et al., 2020). For density functional theory, there are also some works
using neural networks to learn the exchange-correlation functional (Li et al., 2021; Kasim & Vinko,
2021). However, these works focus more on improving simulation accuracy towards physical reality by using neural networks as a better functional approximator, while our workâ€™s focus is very
different, stressing on the optimization efficiency while the equation is completely given. There
are also works on direct optimization for Kohn-Sham equations by total energy minimization (Yang
et al., 2006), which model the problem as a constrained optimization problem instead, and more
domain-specific knowledge is involved, while our work tries to solve the equation from a purely
optimization-based aspect.

For gradient-like eigen-decomposition, most of the works focus on stochastic k-PCA, which estimates the top-k principal components of a data stream. Let x âˆˆ R[d] denote a random data sample at
time step t, vi âˆˆ R[d], i = 1, 2, Â· Â· Â·, k denote the estimate of ith principal component (eigenvector of


-----

ğ¹(ğ‘‰)


Generalized Eigendecomposition

â€œSelf-consistentâ€

Definition of ğ¹(ğ‘‰)

|ğœ†1|Col2|
|---|---|
||ğœ†2|


ğœ†1 < ğœ†2 < â‹¯

|Col1|Col2|
|---|---|
|ğ‘£|ğ‘£|
|1|2|
|||

|Col1|Col2|
|---|---|
|ğ‘£|ğ‘£|
|1|2|
|||

|Col1|Col2|Col3|Col4|
|---|---|---|---|
|||||
||ğ¹(|ğ‘‰|)|
|||||

|Col1|Col2|Col3|Col4|
|---|---|---|---|
|||||
|||ğ»||
|||||

|Col1|Col2|Col3|Col4|
|---|---|---|---|
||2ğ‘‰|ğ‘‰|âŠ¤|
|||||
|||||


Figure 1: An visualization of the problem. S, H âˆˆ R[N] _[Ã—][N]_ and Ueff : R[N] _[Ã—][N]_ _â†’_ R[N] _[Ã—][N]_ are given
input. The solution V _[âˆ—]_ should obey both the generalized eigen-decomposition and the definition of
_F_ (V ), which leads to a â€œself-consistentâ€ problem.

E[XX _[âŠ¤]]) at time t, corresponding to the ith largest eigenvalue. Î· denotes the learning rate._

Ojaâ€™s algorithm: vi[â€²] [+][ Î·][(][xx][âŠ¤][v][i][)][,][ âˆ€][i][ = 1][,][ Â· Â· Â·][, k][ and][ (][v][1][,][ Â· Â· Â·][, v][k][)][ â†] _[QR][(][v]1[â€²]_ _[,][ Â· Â· Â·][, v]k[â€²]_ [)]

_[â†]_ _[v][i]_

Here QR(v1, Â· Â· Â·, vk) is the Gram-Schmidt decomposition that orthonormalizes v1[t] _[,][ Â· Â· Â·][, v]k[t]_ [. There]
are also several follow-up works (Sanger, 1989; Tang, 2019) that improve the performance, in which
a most recent one is EigenGame (Gemp et al., 2021)


_x[âŠ¤]vi, x[âŠ¤]vj_

EigenGame: _vi_ 2x _x[âŠ¤]vi_ _âŸ¨_ _âŸ©_ _,_ _i = 1,_ _, k_
_âˆ‡_ _â†_ h _âˆ’_ Xj<i _âŸ¨x[âŠ¤]vj, x[âŠ¤]vjâŸ©_ _[x][âŠ¤][v][j]i_ _âˆ€_ _Â· Â· Â·_

_vi_ _vi_ _vi, vi_ _vi, vi[â€²]_ [+][ Î·][âˆ‡][R][v][i] [and][ v][i] _vi[â€²]_
_âˆ‡[R]_ _â†âˆ‡_ _âˆ’âŸ¨âˆ‡_ _âŸ©_ _[â†]_ _[v][i]_ _[â†]_ _âˆ¥viâˆ¥_ _[,][ âˆ€][i][ = 1][,][ Â· Â· Â·][, k.]_


EigenGame: _vi_ 2x _x[âŠ¤]vi_
_âˆ‡_ _â†_ _âˆ’_
h


_j<i_


3 PROBLEM DESCRIPTION

In this paper, while what we want to solve is the approximated SchrÂ¨odinger Equations, whose physical background is elaborated in Appendix A, we abstract it mathematically as the following type of
nonlinear generalized eigenvalue problem[1]

_F_ (V )V = SV Î›, (1)

where

-  F (V ): an N Ã— N real symmetric matrix to be decomposed, which is defined in equation 2
as a function of V .

-  S: an N Ã— N positive semi-definite matrix, which is a constant input in the problem.

-  Î›: Î› = diag(Î»1, _, Î»k) is a k_ _k diagonal matrix containing the top-k smallest eigen-_
_Â· Â· Â·_ _Ã—_
values.

-  V : V = [v1, _, vk] is an N_ _k matrix containing k column eigenvectors corresponding_
_Â· Â· Â·_ _Ã—_
to the top-k smallest eigenvalues.

The definition of F (V ) : R[N] _[Ã—][k]_ _â†’_ R[N] _[Ã—][N]_ is as follows:

def
_F_ (V ) = H + Ueff(2V V ), (2)

_[âŠ¤]_

in which H is an N Ã— N real symmetric matrix, which is given in this problem. Ueff : R[N] _[Ã—][N]_ _â†’_
R[N] _[Ã—][N]_ is a given function. We also define P (V ) = 2V V _[âŠ¤]_ for convenience. To conclude, the input

1While the regular eigenvalue problem can be described as finding V that obeys AV = V Î› in which A is
an N Ã— N matrix to be decomposed, Î› = diag(Î»1, Â· Â· Â·, Î»N ) contains all eigenvalues and V = (v1, Â· Â· Â·, vN )
contains the corresponding eigenvectors, a generalized eigenvalue problem adds an additional matrix B with
the form AV = BV Î›. When B = I, it degenerates to a regular eigenvalue problem.


-----

of the problem is S, H, Ueff( ) and k, and the output of the problem is the eigenvectors V that

_Â·_ _[âˆ—]_
obeys both equation 1 and equation 2. The top-k smallest eigenvalues of F (V _[âˆ—]) are guaranteed to_
be negative.

To make it more clear, a toy example is provided as follows:


0.6953 1.1204 0.9584

_, H =_ _âˆ’_ _âˆ’_

1.0  âˆ’0.9584 _âˆ’1.1204_

_PÎ»ÏƒEuvÎ»Ïƒ_ _PÎ»ÏƒEuÎ»Ïƒv,_
_Î»,Ïƒ_ _âˆ’_ 2[1] _Î»,Ïƒ_

X X


1.0 0.6953
_S =_
0.6953 1.0



_, k = 1_



[Ueff(P )]uv =


0.7746 0.4441
_E11 =_
0.4441 0.5697



0.4441 0.2970
_, E12 = E21 =_
0.2970 0.4441



0.5697 0.4441
_, E22 =_
0.4441 0.7746



in which P = 2V V _[âŠ¤], Ueff(P_ ) âˆˆ R[2][Ã—][2], E is a 2 Ã— 2 Ã— 2 Ã— 2 tensor. The solution of the toy example

0.3655 0.5939
should be V _[âˆ—]_ = (0.5489, 0.5489)[âŠ¤], in this case F (V _[âˆ—]) =_ âˆ’âˆ’0.5939 _âˆ’âˆ’0.3655, and the result of_

top-1 eigen-decomposition

0.3655 0.5939 1.0 0.6953
_âˆ’_ _âˆ’_ _V =_ _V Î›_
âˆ’0.5939 _âˆ’0.3655_ 0.6953 1.0 

will happen to be exactly V _[âˆ—]_ = (0.5489, 0.5489)[âŠ¤] with the smallest eigenvalue Î»1 = âˆ’0.5782,
while the other one is [1.2115, âˆ’1.2115][âŠ¤] with eigenvalue Î»2 = 0.6703.

4 SOLVING APPROXIMATED SCHR Â¨ODINGER EQUATIONS USING
SELF-CONSISTENT GRADIENT-LIKE EIGEN DECOMPOSITION

First, notice that the stochastic k-PCA methods usually can be generalized to decompose a real
symmetric matrix M . For Ojaâ€™s algorithm (Oja & Karhunen, 1985), that is

_vi[â€²]_ [+][ Î·Mv][i] _i = 1,_ _, k and (v1,_ _, vk)_ _QR(v1[â€²]_ _[,][ Â· Â· Â·][, v]k[â€²]_ [)][,] (3)

_[â†]_ _[v][i]_ _âˆ€_ _Â· Â· Â·_ _Â· Â· Â·_ _â†_

in which vi[t] [is the eigenvector corresponding to the][ i][th largest eigenvalue.]

Due to the lack of efficiency, such decomposition methods are not favorable for traditional eigendecomposition (M is a given constant input) compared with classical algorithms such as QR iteration. However, as stochastic algorithms, they have a unique advantage that they can adapt to dynamic
change of M, which suits the sticking point in equation 1 that F (V ) is subject to concurrent update
when V changes. This motivates us to apply them to tackle the approximated SchrÂ¨odinger equations.

Together with the orthogonalization technique introduced in Appendix B which transforms the generalized eigenvalue problem into a standard one, we replace M in equation 3 with F _[â€²]_ = X _[âŠ¤]F_ (V )X,
and update F _[â€²]_ in each time step immediately after each update of V to maintain the self-consistency,
which forms the initial version of our proposed algorithm, self-consistent gradient-like eigen decomposition (SCGLED), shown in Algorithm 1. Note that we need the eigenvectors corresponding to
top-k smallest eigenvalues rather than the largest ones, so we decompose âˆ’F _[â€²]_ instead of F _[â€²]. Dif-_
ferent from traditional SCF method shown in Appendix B where Vt[â€²] [is purely a temporary variable]
that should be discarded after each iteration, Vt[â€²] [in our proposed algorithm is more likely a â€œtraining]
variableâ€ that is first randomly initialized and then trained during the whole iterative process.

While the convergence analysis of Algorithm 1 is heavily blocked by the intrinsic nonlinearity of
approximated Schrodinger equations, which is fundamentally complex in computational physics, we
instead use heuristics to boost the empirical convergence performance in later paragraphs, and prove
the correctness of our algorithm under some robustness assumption of F (V ) on the convergence
point, with the following proposition
**Proposition 1. If Algorithm 1 converges to a stable convergence point V** _[âˆ—]_ _and for a small pertur-_
_bation Ïµ towards V_ _[âˆ—], [X_ _[âŠ¤]F_ (V _[âˆ—])X âˆ’_ _X_ _[âŠ¤]F_ (V _[âˆ—]_ + Ïµ)X](V _[âˆ—]_ + Ïµ) = O(Ïµ[2]), then V _[âˆ—]_ _is the solution_
_of equation 1._

The proof is deferred to Appendix C.


-----

**Algorithm 1 The vanilla version of self-consistent gradient-like eigen decomposition (SCGLED)**

**Input: H, S, Ueff(Â·) in equation 1 and equation 2, learning rate Î· > 0**
**Output: V** _[âˆ—], the solution of equation 1_

1: Initialize V _[â€²]_ _âˆˆ_ R[N] _[Ã—][k]_ randomly.
2: Find X satisfying X _[âŠ¤]SX = I._
3: while V _[â€²]_ is not converged do
4: _V â†_ _XV_ _[â€²]_

5: _F_ _[â€²]_ _â†_ _X_ _[âŠ¤]F_ (V )X following equation 2

6: Update V _[â€²]_ for one-step decomposition of âˆ’F _[â€²]_ using equation 3.

7: end while
8: V _[âˆ—]_ _â†_ _XV_ _[â€²]_


However, this initial version is of poor efficiency and stability. The computational efficiency is
blocked by the Gram-Schmidt process which is highly order-preserving thus cannot be decentralized/vectorized. Also, due to the existence of F (V ) = H +Ueff(P (V )) that is sensitive to the change
of V, the iteration process is highly nonlinear. In this case oscillation will easily occur which hinders
the iteration process toward convergence. To tackle these problems, we made several improvements
to Algorithm 1 as follows.

First, we replace the classical Ojaâ€™s algorithm with the decentralized version of EigenGame (Gemp
et al., 2021). EigenGame replaces the time-consuming QR decomposition by a generalized GramSchmidt step in its gradient _vi, which makes it theoretically harder to analyse (since the orthonor-_
_âˆ‡_
mality of eigenvectors is not guaranteed during the iteration), but with better empirical performance
due to its decentralized nature. Its procedure is as follows:


_vi[âŠ¤][Mv][j]_

_vj_ _,_ _vi_ _vi_ _vi, vi_ _vi_ _i = 1,_ _, k_ (4)
_vj[âŠ¤][Mv][j]_ _âˆ‡[R]_ _â†âˆ‡_ _âˆ’âŸ¨âˆ‡_ _âŸ©_ _âˆ€_ _Â· Â· Â·_
i


_vi_ 2M _vi_
_âˆ‡_ _â†_ _âˆ’_
h


_j<i_


_vi[â€²]_ _[â†]_ _[v][i]_ [+][ Î·][âˆ‡][R][v][i][,][ and][ v][i] _[â†]_ _âˆ¥vvii[â€²][â€²][âˆ¥]_ _âˆ€i = 1, Â· Â· Â·, k_ (5)

Second, to reduce oscillation during the iteration process, we introduce the damping technique for
the update of F . That is,
_Ft = (1_ _Î±)Ft_ 1 + Î±F (Vt), (6)
_âˆ’_ _âˆ’_
in which Î± is the mixing hyperparameter between 0 and 1. Here we set it as 0.2.

Third, the selection of learning rate Î· is highly tricky for different molecule inputs. To enhance
the robustness of the algorithm towards learning rate, we introduce the momentum method for the
update of V _[â€²]_ as follows:

_mt = Î²mtâˆ’1 + Î·âˆ‡V_ _[â€²],_ (7)

_V_ = V + mt, (8)

_[â€²]_ _[â€²]_

in which the momentum term Î² is set to 0.9.

Fourth, instead of updating F in every iteration, we control the update interval of F via a parameter IF . The first reason is for efficiency, since V _[â€²]_ only update slightly in each time step with a
small learning rate Î·, it may not be necessary to do a fresh computation of F (V ) in each time step,
especially considering that the computation of Ueff(P (V )) is relatively time-consuming. The second reason is for stability, since the damping technique in equation 6 will degenerate if previously
updated Ft 1 and current F (V ) are too close.
_âˆ’_

Summarizing all considerations above, our proposed algorithm is shown in Algorithm 2

5 EXPERIMENTS

In this section, we perform extensive performance benchmarks on W4-17 dataset(Karton et al.,
2017), which is also applied in prior benchmark work (Lehtola, 2019). All the 160 singlet molecules
in the W4-17 dataset are used to evaluate the performance of our proposed algorithm. Our algorithm


-----

**Algorithm 2 Self-consistent gradient-like eigen decomposition (SCGLED)**

**Input: H, S, Ueff(Â·) in equation 1 and equation 2, total number of iterations T**, learning rate Î·, F â€™s
update ratio IF

**Output: V** _[âˆ—], the solution of equation 1_

1: Initialize V _[â€²]_ _âˆˆ_ R[N] _[Ã—][k]_ randomly.
2: F â† _H_
3: m â† **0[N]** _[Ã—][k]_

4: Find X satisfying X _[âŠ¤]SX = I._
5: for t = 0, 1, 2, Â· Â· Â·, T do
6: **if t mod IF = 0 then**

7: _V â†_ _XV_ _[â€²]_

8: _F â†_ (1 âˆ’ _Î±)F + Î±F_ (V )

9: _F_ _[â€²]_ _â†_ _X_ _[âŠ¤]FX_

10: **end if**

11: Obtain âˆ‡[R]V _[â€²]_ for one-step decomposition of âˆ’F _[â€²]_ using equation 4.

12: _m â†_ _Î²m + Î·âˆ‡[R]V_ _[â€²]_

13: _V_ _V_ + mt

_[â€²]_ _â†_ _[â€²]_

14: Normalize all column vectors in V _[â€²]_ following equation 5.

15: end for
16: V _[âˆ—]_ _â†_ _XV_ _[â€²]_


is implemented in Python with NumPy, and optimized via Numba (Lam et al., 2015). The learning
rate Î· is set to be 10[âˆ’][2]. The effective potential matrix function Ueff(Â·) in Algorithm 2 is based on
Hartree-Fock theory and provided by PySCF (Sun et al., 2018). We use the standard 6-31G basis
set (Ditchfield et al., 1971) for the computation of all molecules. All experiments are run on a AMD
Ryzen 7 5800H CPU (8 cores, 16 threads, 3.2-4.4GHz) with 16GB memory. For the reproducibility


of the result, in all experiments we initialize V _[â€²]_ in Algorithm 2 by

matrix.

5.1 SCGLED AS AN INITIAL GUESS METHOD


where I is a k Ã— k identity


A direct application of our proposed method is to provide an initial guess for the traditional SCF
method shown in Algorithm 3. We compare with the following popular initial guess methods that
are widely applied in quantum chemistry and solid-state physics software. All of them highly rely
on domain-specific heuristics.

-  Hcore: Core Hamiltonian method, which obtains the guess orbitals from the diagonalization
of the core Hamiltonian H, ignoring all interelectronic interactions.

-  atom (Van Lenthe et al., 2006): Superposition of atomic HF density matrices.

-  minao: Superposition of atomic densities projected in a minimal basis obtained from the
first contracted functions in the cc-pVTZ or cc-pVTZ-PP basis set.

-  huckel (Karton et al., 2017): Parameter-free HÂ¨uckel guess.

In the experiment, we use PySCFâ€™s integrated implementation for all the initial guess baselines.
PySCF (Python-based Simulations of Chemistry Framework, (Sun et al., 2018)) is an open-source,
highly popular quantum chemistry software in Python, whose computationally critical parts are
implemented and optimized in C to guarantee efficiency.

We evaluate the performance of an initial guess method from two aspects

-  Precision: the distance between the initial guess and the final converged solution of equation 1, measured by the averaged energy error over 160 molecules. (expected to be as small
as possible)

-  Convergence: the ratio that the initial guess can successfully lead to a converged solution
via traditional SCF iteration, measured by the number of molecules that failed to converge
in SCF iteration with a certain initial guess method. (expected to be as few as possible)


-----

T = 200 100

10[0]

T = 500

10 2 T = 1000 80 T = 200

60

10 4 T = 2000

SCGLED 40 SCGLED

10 6 Hcore Hcore

Energy error (Hartree) 10 8 10 3 minaoatomhuckel 10 2 T = 5000T = 1000010 1 #(molecules that are not converged) 20 10 3 minaoatomhuckel T = 50010T = 10002 T = 2000T = 5000T = 1000010 1

Wall Time (s) Wall Time (s)


(a) Time-precision evaluation


(b) Time-convergence evaluation


Figure 2: Performance evaluation of initial guess methods

Initial guess methods are expected to be very rapid compared with main SCF iterations, so we restrict
the range of T from 200 to 10,000, corresponding to 5-250 milliseconds, while traditional methods
take around 30 milliseconds. We also set F â€™s update interval IF = 50 in this experiment.

The result of performance evaluation is shown in Figure 2. While traditional initial guess methods are parameter-free heuristics, SCGLED is iterative thus the performance and time cost are directly influenced by the number of iterations T . As a result, SCGLED is shown as a curve in timeperformance space while traditional methods are shown as points. In both Figure 2a and Figure 2b,
SCGLEDâ€™s curve lies at the lower-left direction of traditional methods, indicating that our method
achieves better results for both precision and convergence ability. Comparing the result of the best
baseline â€œminaoâ€ and SCGLED at T = 1000 in Figure 2a, we can find that averagely SCGLED
is 25x more precise than minao (0.013379 Hartree vs. 0.343194 Hartree in energy error) while the
wall time are very close (26.3 ms vs. 28.6 ms). Our proposed method not only performs better or
close to traditional methods given the same time, but also provides more flexible options, such as
paying more time to achieve better performance in time-rich tasks, or sacrificing performance to satisfy rigorous time limitation, which is inconceivable for traditional methods due to their heuristics
nature. A more detailed, per-molecule result is shown in Appendix E.


T = 200 100 T = 200

10[0] T = 500 T = 500

T = 1000 80 T = 1000

10 2 T = 2000T = 5000 T = 2000T = 5000

60

T = 10000 T = 10000

10 4

40

10 6

Energy error (Hartree)

20

10 8

#(molecules that are not converged)

0

1 5 10 25 50 100 1 5 10 25 50 100

The update interval of F (IF) The update interval of F (IF)


(a) IF -precision relation


(b) IF -convergence relation


Figure 3: IF -performance relation of SCGLED

For SCGLED, we also study the influence of IF, the parameter to control F â€™s update interval, to
the performance, shown in Figure 3. The IF -performance relation is shown as a U-shaped curve,
which indicates that IF should be set to a moderate value, neither too large nor too small. The best
value of IF (the bottom of the U-shaped curve) is relevant to the total number of iterations T : IF
should be smaller for small T so F can be updated for reasonable times in very limited iterations,
and should be moderately larger for large T so that the convergence acceleration technique (such as
the damping technique in equation 6) works better.


-----

5.2 SCGLED AS A FULL SOLVER

While gradient-based methods are widely used in machine learning in ways that do not require
extreme precision, it is usually computationally intractable in other fields that require high precision,
especially scientific computing, due to its low convergence rate. However, a counterintuitive result
is that our proposed gradient-like method can produce highly precise solutions of equation 1 in a
reasonable number of iterations.

160

140

120

100

80

60

40

#(molecules that are not solved) 20 SCGLED

SCGLED (with DIIS)

0

10[3] 10[4] 10[5] 10[6] 10[7]

#(iterations)


Figure 4: Performance of SCGLED for solving molecules independently.


(a) Benzene
(C6H6)


(b) n-Pentane
(C5H12)


(c) Chloroethane
(C2ClH5)


(d) Formonitrile
oxide (HCNO)


Figure 5: Visualization of electron density for some molecules, solved via SCGLED.

The result that our proposed method acts as a full solver (without any traditional SCF iteration)
is shown in Figure 4. The convergence criterion is selected as the default setting in PySCF. That
is, the difference of a moleculeâ€™s total energy before and after a single-step SCF iteration should
be less than 10[âˆ’][10], which is extremely strict. IF is set as 100 since T is relatively large in this
scenario. It shows that our proposed method successfully solved more than half of the molecules
within 20,000 iterations, and 155 out of 160 molecules within 1 million iterations. If we replace the
simple damping technique in Algorithm 2 with a more powerful DIIS method (Pulay, 1980) for the
last 10% iterations[2], we can successfully solve all 160 molecules with very high precision. Some of
the highly precise solutions are visualized in Figure 5 by VMD (Humphrey et al., 1996), in which
the coordinate and type of atoms are given for each molecule, and the electron densities are solved
by SCGLED, represented as isosurfaces shown as grey surface around the molecule.

6 CONCLUSION

In this work, we solve the approximated SchrÂ¨odinger equations from scratch with gradient-like
eigen-decomposition. This work contributes to both the field of computational physics and machine
learning as follows:

2E.g., for T = 10000, damping is applied for the first 9000 iterations, and we apply DIIS for the last 1000
iterations (10 actual DIIS computations are done since IF = 100).


-----

-  For computational physics, beside the performance advantage, this work shows the possibility to solve the approximated SchrÂ¨odinger equations from a purely optimization-based
aspect, without any heuristics method based on prior quantum mechanism knowledge to
bootstrap the solving stage. In this way the solving of approximated SchrÂ¨odinger equations
can be stripped out from its physical background, studied independently as a mathematical
optimization problem.

-  For machine learning, this work explores a brand new area of â€œself-consistentâ€ eigenvalue problems, especially approximated SchrÂ¨odinger equations, for stochastic eigendecomposition methods such as Ojaâ€™s algorithm and EigenGame, which are previously
regarded as specialized methods for k-PCA. While such methods can properly handle
stochasticity, this work shows that they are also capable of handling self-consistency, which
leads to a potential of application in a broader field of scientific computing.

REFERENCES

Zeyuan Allen-Zhu and Yuanzhi Li. First efficient convergence for streaming k-pca: A global, gapfree, and near-optimal rate. In 2017 IEEE 58th Annual Symposium on Foundations of Computer
Science (FOCS), pp. 487â€“492, 2017. doi: 10.1109/FOCS.2017.51.

R. Ditchfield, W. J. Hehre, and J. A. Pople. Self-consistent molecular-orbital methods. ix. an extended gaussian-type basis for molecular-orbital studies of organic molecules. The Journal of
[Chemical Physics, 54(2):724â€“728, 1971. doi: 10.1063/1.1674902. URL https://doi.org/](https://doi.org/10.1063/1.1674902)
[10.1063/1.1674902.](https://doi.org/10.1063/1.1674902)

Charlotte Froese Fischer. General hartree-fock program. Computer Physics Communications,
43(3):355â€“365, 1987. ISSN 0010-4655. doi: https://doi.org/10.1016/0010-4655(87)
90053-1. URL [https://www.sciencedirect.com/science/article/pii/](https://www.sciencedirect.com/science/article/pii/0010465587900531)
[0010465587900531.](https://www.sciencedirect.com/science/article/pii/0010465587900531)

Ian M. Gemp, Brian McWilliams, Claire Vernade, and Thore Graepel. Eigengame: PCA as a nash
equilibrium. In 9th International Conference on Learning Representations, ICLR 2021, Virtual
[Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/](https://openreview.net/forum?id=NzTU59SYbNq)
[forum?id=NzTU59SYbNq.](https://openreview.net/forum?id=NzTU59SYbNq)

D. R. Hartree. The wave mechanics of an atom with a non-coulomb central field. part i. theory
and methods. Mathematical Proceedings of the Cambridge Philosophical Society, 24(1):89â€“110,
1928. doi: 10.1017/S0305004100011919.

Douglas Rayner Hartree and W. Hartree. Self-consistent field, with exchange, for beryllium. Proceedings of the Royal Society of London. Series A - Mathematical and

Physical Sciences, 150(869):9â€“33, 1935. doi: 10.1098/rspa.1935.0085. [URL https://](https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1935.0085)
[royalsocietypublishing.org/doi/abs/10.1098/rspa.1935.0085.](https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1935.0085)

Jan Hermann, Zeno SchÂ¨atzle, and Frank NoÂ´e. Deep-neural-network solution of the electronic
SchrÂ¨odinger equation. Nature Chemistry, 12(10):891â€“897, October 2020. ISSN 1755[4349. doi: 10.1038/s41557-020-0544-y. URL https://www.nature.com/articles/](https://www.nature.com/articles/s41557-020-0544-y)
[s41557-020-0544-y. Number: 10 Publisher: Nature Publishing Group.](https://www.nature.com/articles/s41557-020-0544-y)

John Hertz, Anders Krogh, and Richard G Palmer. Introduction to the theory of neural computation.
CRC Press, 2018.

P. Hohenberg and W. Kohn. Inhomogeneous electron gas. Phys. Rev., 136:B864â€“B871, Nov
[1964. doi: 10.1103/PhysRev.136.B864. URL https://link.aps.org/doi/10.1103/](https://link.aps.org/doi/10.1103/PhysRev.136.B864)
[PhysRev.136.B864.](https://link.aps.org/doi/10.1103/PhysRev.136.B864)

William Humphrey, Andrew Dalke, and Klaus Schulten. VMD â€“ Visual Molecular Dynamics.

Journal of Molecular Graphics, 14:33â€“38, 1996.

Amir Karton, Nitai Sylvetsky, and Jan M. L. Martin. W4-17: A diverse and high-confidence
dataset of atomization energies for benchmarking high-level electronic structure methods. Journal
of Computational Chemistry, 38(24):2063â€“2075, 2017. doi: https://doi.org/10.1002/jcc.24854.
[URL https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.24854.](https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.24854)


-----

M. F. Kasim and S. M. Vinko. Learning the exchange-correlation functional from nature
with fully differentiable density functional theory. Phys. Rev. Lett., 127:126403, Sep 2021.
[doi: 10.1103/PhysRevLett.127.126403. URL https://link.aps.org/doi/10.1103/](https://link.aps.org/doi/10.1103/PhysRevLett.127.126403)
[PhysRevLett.127.126403.](https://link.aps.org/doi/10.1103/PhysRevLett.127.126403)

W. Kohn and L. J. Sham. Self-consistent equations including exchange and correlation effects.

[Phys. Rev., 140:A1133â€“A1138, Nov 1965. doi: 10.1103/PhysRev.140.A1133. URL https:](https://link.aps.org/doi/10.1103/PhysRev.140.A1133)
[//link.aps.org/doi/10.1103/PhysRev.140.A1133.](https://link.aps.org/doi/10.1103/PhysRev.140.A1133)

Siu Kwan Lam, Antoine Pitrou, and Stanley Seibert. Numba: A llvm-based python jit compiler. In

Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC, LLVM â€™15,
New York, NY, USA, 2015. Association for Computing Machinery. ISBN 9781450340052. doi:
[10.1145/2833157.2833162. URL https://doi.org/10.1145/2833157.2833162.](https://doi.org/10.1145/2833157.2833162)

Susi Lehtola. Assessment of Initial Guesses for Self-Consistent Field Calculations. Superposition
of Atomic Potentials: Simple yet Efficient. Journal of Chemical Theory and Computation, 15
[(3):1593â€“1604, March 2019. ISSN 1549-9618. doi: 10.1021/acs.jctc.8b01089. URL https:](https://doi.org/10.1021/acs.jctc.8b01089)
[//doi.org/10.1021/acs.jctc.8b01089. Publisher: American Chemical Society.](https://doi.org/10.1021/acs.jctc.8b01089)

Li Li, Stephan Hoyer, Ryan Pederson, Ruoxi Sun, Ekin D. Cubuk, Patrick Riley, and Kieron Burke.
Kohn-sham equations as regularizer: Building prior knowledge into machine-learned physics.
[Phys. Rev. Lett., 126:036401, Jan 2021. doi: 10.1103/PhysRevLett.126.036401. URL https:](https://link.aps.org/doi/10.1103/PhysRevLett.126.036401)
[//link.aps.org/doi/10.1103/PhysRevLett.126.036401.](https://link.aps.org/doi/10.1103/PhysRevLett.126.036401)

Richard M. Martin. Electronic Structure: Basic Theory and Practical Methods. Cambridge University Press, 2004. doi: 10.1017/CBO9780511805769.

Erkki Oja. Simplified neuron model as a principal component analyzer. Journal of mathematical

biology, 15(3):267â€“273, 1982.

Erkki Oja and Juha Karhunen. On stochastic approximation of the eigenvectors and eigenvalues of
the expectation of a random matrix. Journal of Mathematical Analysis and Applications, 106(1):
[69â€“84, February 1985. ISSN 0022-247X. doi: 10.1016/0022-247X(85)90131-3. URL https:](https://www.sciencedirect.com/science/article/pii/0022247X85901313)
[//www.sciencedirect.com/science/article/pii/0022247X85901313.](https://www.sciencedirect.com/science/article/pii/0022247X85901313)

David Pfau, James S. Spencer, Alexander G. D. G. Matthews, and W. M. C. Foulkes. Ab initio solution of the many-electron schrÂ¨odinger equation with deep neural networks. Phys. Rev.

Research, 2:033429, Sep 2020. doi: 10.1103/PhysRevResearch.2.033429. [URL https:](https://link.aps.org/doi/10.1103/PhysRevResearch.2.033429)
[//link.aps.org/doi/10.1103/PhysRevResearch.2.033429.](https://link.aps.org/doi/10.1103/PhysRevResearch.2.033429)

PÂ´eter Pulay. Convergence acceleration of iterative sequences. the case of scf iteration.

Chemical Physics Letters, 73(2):393â€“398, 1980. ISSN 0009-2614. doi: https://doi.org/
[10.1016/0009-2614(80)80396-4. URL https://www.sciencedirect.com/science/](https://www.sciencedirect.com/science/article/pii/0009261480803964)
[article/pii/0009261480803964.](https://www.sciencedirect.com/science/article/pii/0009261480803964)

Terence D. Sanger. Optimal unsupervised learning in a single-layer linear feedforward neural network. Neural Networks, 2(6):459â€“473, 1989. ISSN 0893-6080. doi: https://doi.org/
[10.1016/0893-6080(89)90044-0. URL https://www.sciencedirect.com/science/](https://www.sciencedirect.com/science/article/pii/0893608089900440)
[article/pii/0893608089900440.](https://www.sciencedirect.com/science/article/pii/0893608089900440)

Qiming Sun, Timothy C. Berkelbach, Nick S. Blunt, George H. Booth, Sheng Guo, Zhendong Li,
Junzi Liu, James D. McClain, Elvira R. Sayfutyarova, Sandeep Sharma, Sebastian Wouters, and
Garnet Kin-Lic Chan. Pyscf: the python-based simulations of chemistry framework. WIREs
Computational Molecular Science, 8(1):e1340, 2018. doi: https://doi.org/10.1002/wcms.1340.
[URL https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1340.](https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1340)

Attila Szabo and Neil S Ostlund. Modern quantum chemistry: introduction to advanced electronic

structure theory. Dover Publications, Inc., 1996.

Cheng Tang. Exponentially convergent stochastic k-pca without variance reduction. In
H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÂ´e-Buc, E. Fox, and R. Garnett
(eds.), Advances in Neural Information Processing Systems, volume 32. Curran Asso[ciates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/](https://proceedings.neurips.cc/paper/2019/file/38faae069a1371784081ea9ad9b279d0-Paper.pdf)
[38faae069a1371784081ea9ad9b279d0-Paper.pdf.](https://proceedings.neurips.cc/paper/2019/file/38faae069a1371784081ea9ad9b279d0-Paper.pdf)


-----

JH Van Lenthe, R Zwaans, Huub JJ Van Dam, and MF Guest. Starting scf calculations by superposition of atomic densities. Journal of computational chemistry, 27(8):926â€“932, 2006.

Chao Yang, Juan C. Meza, and Lin-Wang Wang. A constrained optimization algorithm for total energy minimization in electronic structure calculations. Journal of Computational Physics, 217(2):
[709â€“721, 2006. ISSN 0021-9991. doi: https://doi.org/10.1016/j.jcp.2006.01.030. URL https:](https://www.sciencedirect.com/science/article/pii/S0021999106000325)
[//www.sciencedirect.com/science/article/pii/S0021999106000325.](https://www.sciencedirect.com/science/article/pii/S0021999106000325)

A PHYSICAL BACKGROUND

In this section, we briefly introduce the physical background of the problem in section 3. We refer
to (Szabo & Ostlund, 1996; Martin, 2004) for more details.

In computational physics, a foundation problem is to solve the SchrÂ¨odinger equation of a many-body
quantum system
_H |Î¨âŸ©_ = E |Î¨âŸ©

where H is the Hamilton operator for a system of M nuclei and N electrons described by their
coordinates RA and ri. With the Born-Oppenheimer approximation (nuclei are much heavier than
electrons), we consider the electrons to be moving in the field of fixed nuclei, thus the kinetic energy
of the nuclei (approximated as zero) and the repulsion between the nuclei (approximated to be
constant) can be neglected. In this case we write H as


_N_ _M_

_ZA_

_ri_ _RA_

Xi=1 _AX=1_ _|_ _âˆ’_ _|_

coulomb attraction be
tween electrons and nu
{z }

clei


1

_âˆ’_ 2 _[âˆ‡]i[2]_

_i=1_

X

kinetic energy of the

electrons

| {z }


_H =_


_ri_ _rj_

Xi=1 _j=Xi+1_ _|_ _âˆ’_ _|_

repulsion between elec
trons

{z }


and Î¨(r1, _, rN_ ) the electronic wave function, which should be normalized (i.e., Î¨ Î¨ =
_Â· Â· Â·_ _âŸ¨_ _|_ _âŸ©_
Î¨M[âˆ—](r1, Â· Â· Â·ZA, rN )Î¨(r1, Â· Â· Â·, rN )dr1 Â· Â· Â· drN = 1). For convenience, let operatorN 1 _h(i) = âˆ’_ [1]2 _[âˆ‡]i[2]_ _[âˆ’]_
R _A=1_ _|riâˆ’RA|_ [so][ H][ can be rewritten as][ H][ =][ P]i[N]=1 _[h][(][i][) +][ P]i[N]=1_ _j=i+1_ _|riâˆ’rj_ _|_ [. According to]

the variational principle, the problem of finding solution Î¨ for the ground state energy E0 can be

P P

transformed to the following constrained optimization problem

min âŸ¨Î¨| H |Î¨âŸ© _s.t. âŸ¨Î¨|Î¨âŸ©_ = 1

Since the multi-electron wave function Î¨(r1, _, rN_ ) is computationally intractable when
_Â· Â· Â·_
_N is large, a basic way is to approximate it as the product of N orbital wave function_
_Ïˆ1(r1)Ïˆ2(r2) Â· Â· Â· ÏˆN_ (rN ) satisfying âŸ¨Ïˆi|ÏˆiâŸ© = _Ïˆi[âˆ—][(][r][)][Ïˆ][i][(][r][)][dr][ = 1][,][ âˆ€][i][ âˆˆ]_ [1][ Â· Â· Â·][ N] [, which is called]
â€œHartree approximationâ€. We also expand Ïˆi(rR) = _u=1_ _[C][ui][Ï†][(][r][)][ as a linear combination of][ K]_
â€œbasis functionsâ€ which is fixed and given, in this case our task becomes to determine the value of
all Cui so as to determine the approximated wave function. To construct a Lagrange multiplier

[P][K]


_L = âŸ¨Î¨| H |Î¨âŸ©âˆ’_


_Ïµi(_ _Ïˆi_ _Ïˆi_ 1)
_âŸ¨_ _|_ _âŸ©âˆ’_
_i=1_

X


we have

_âŸ¨Î¨| H |Î¨âŸ©_ =


Î¨[âˆ—](r1, _, rN_ )h(i)Î¨(r1, _, rN_ )dr1 _drN_
_Â· Â· Â·_ _Â· Â· Â·_ _Â· Â· Â·_


_i=1_

+
Z

_N_

_i=1_

X


Î¨[âˆ—](r1, _, rN_ )
_Â· Â· Â·_


_ri_ _rj_
_|_ _âˆ’_ _|_ [Î¨(][r][1][,][ Â· Â· Â·][, r][N] [)][dr][1][ Â· Â· Â·][ dr][N]


_i=1_ _j=i+1_


_Ïˆi[âˆ—][(][r][)][h][(][i][)][Ïˆ][i][(][r][)][dr][ + 1]_

2


_Ïˆi[âˆ—][(][r][i][)][Ïˆ]j[âˆ—][(][r][j][)]_


_ri_ _rj_
_|_ _âˆ’_ _|_ _[Ïˆ][i][(][r][i][)][Ïˆ][j][(][r][j][)][dr][i][dr][j]_


_i=1_


_j=Ì¸_ _i_


-----

_CuiCvi_ _Ï†[âˆ—]u[(][r][)][h][(][i][)][Ï†][v][(][r][)][dr]_

_i=1_ _u,v_ Z

X X

_N_ _N_

+ [1] _CuiCÎ»jCÏƒjCvi_

2

Xi=1 Xj=Ì¸ _i_ _u,v,Î»,ÏƒX_ Z


_Ï†[âˆ—]u[(][r][i][)][Ï†][âˆ—]Î»[(][r][j][)]_


_ri_ _rj_
_|_ _âˆ’_ _|_ _[Ï†][Ïƒ][(][r][j][)][Ï†][v][(][r][i][)][dr][i][dr][j]_


and


_Ïµi(_ _Ïˆi[âˆ—][(][r][)][Ïˆ][i][(][r][)][dr][ âˆ’]_ [1)]
_i=1_ Z

X


_Ïµi(_ _Ïˆi_ _Ïˆi_ 1) =
_âŸ¨_ _|_ _âŸ©âˆ’_
_i=1_

X


_Ï†[âˆ—]u[(][r][)][Ï†][v][(][r][)][dr][ âˆ’]_ [1)]


_Ïµi(_ _CuiCvi_
_i=1_ _u,v_

X X


Let _Huv_ = _Ï†[âˆ—]u[(][r][)][h][(][i][)][Ï†][v][(][r][)][dr][,]_ _Suv_ = _Ï†[âˆ—]u[(][r][)][Ï†][v][(][r][)][dr]_ and _EuvÎ»Ïƒ_ =
_Ï†[âˆ—]u[(][r][1][)][Ï†][âˆ—]Î»[(][r][2][)]_ _r1_ 1 _r2_

_|_ _âˆ’_ R| _[Ï†][Ïƒ][(][r][2][)][Ï†][v][(][r][1][)][dr][1][dr][2][ which are all constants since]R_ _[ {][Ï†][i][}][ are given functions,]_
we have

R


_CuiCviHuv + [1]_

2

_u,v_

X


_L =_


_CuiCÎ»jCÏƒjCviEuvÎ»Ïƒ_

_u,v,Î»,Ïƒ_

X


_i=1_


_i=1_


_j=Ì¸_ _i_


_Ïµi(_
_i=1_

X


_CuiCviSuvdr_ 1)
_âˆ’_
_u,v_

X


_âˆ‚L_

=2
_âˆ‚Cui_


_CÎ»jCÏƒjEuvÎ»Ïƒ_ _ÏµiSuv)_
_Î»,Ïƒ_ _âˆ’_

X


_Cvi(Huv +_


_j(=Ì¸_ _i)_


Let _âˆ‚Câˆ‚Lui_ [= 0][,][ âˆ€][i][ = 1][ Â· Â· Â·][ N, u][ = 1][ Â· Â· Â·][ K][ and we have]


_Cvi(Huv +_ _CÎ»jCÏƒjEuvÎ»Ïƒ) = Ïµi_ _CviSuv, âˆ€i = 1 Â· Â· Â· N, u = 1 Â· Â· Â· K_

Xv _jX(=Ì¸_ _i)_ XÎ»,Ïƒ Xv

Let PÎ»Ïƒ = _j(=i)_ _[C][Î»j][C][Ïƒj][,][ [][U][eff][(][P]_ [)]][uv][ =][ P]Î»,Ïƒ _[P][Î»Ïƒ][E][uvÎ»Ïƒ][,][ F][uv][ =][ H][uv][ + [][U][eff][(][P]_ [)]][uv][ and][ Î› =]

_Ì¸_

diag(Ïµ1, Â· Â· Â·, ÏµN ), P, Ueff(P ), F âˆˆ R[K][Ã—][K], we have the matrix form of the above equation

[P] _FC = SCÎ›_

which is a generalized eigenvalue problem where the matrix F to be decomposed is defined by the
eigenvectors C.

Actually, there are several improved approximation theories based on the Hartree approximation
mentioned above, in which the definitions of P and Ueff(P ) are different. A most influential one
is the Hartree-Fock theory in which the multi-electron wave function is approximated by a slater
determinant

_Ï‡1(x1)_ _Ï‡2(x1)_ _Ï‡N_ (x1)

_Â· Â· Â·_

Î¨(x1, _, xN_ ) = 1 _Ï‡1(.x2)_ _Ï‡2(.x2)_ _Â· Â· Â·_ _Ï‡N_ (.x2)
_Â· Â· Â·_ _âˆšN_ ! .. .. ... ..

_Ï‡1(xN_ ) _Ï‡2(xN_ ) _Ï‡N_ (xN )

_Â· Â· Â·_

to conform to the antisymmetry principle Î¨( _, xi,_ _, xj,_ ) = Î¨( _, xj,_ _, xi,_ )

_Â· Â· Â·_ _Â· Â· Â·_ _Â· Â· Â·_ _âˆ’_ _Â· Â· Â·_ _Â· Â· Â·_ _Â· Â· Â·_
whose famous representation is Pauli exclusion principle. In this way Puv = 2 _i_ _CÎ»jCÏƒj (or in_
matrix form, P = 2CC _[âŠ¤]) and [Ueff(P_ )]uv = _Î»,Ïƒ_ _[P][Î»Ïƒ][E][uvÎ»Ïƒ][ âˆ’]_ 2[1] _Î»,Ïƒ_ _[P][Î»Ïƒ][E][uÎ»Ïƒv][, in which an]_

â€œexchange termâ€ âˆ’ [1]2 _Î»,Ïƒ_ _[P][Î»Ïƒ][E][uÎ»Ïƒv][ is added.]_ P [P][N/][2]

[P]

P

B SELF-CONSISTENT FIELD (SCF) METHOD

Self-Consistent Field (SCF) is a standard method to solve equation 1. An initial density matrix
_P0 is generated via heuristics based on prior quantum mechanism knowledge, then the generalized_


-----

eigen-decomposition problem F (Pt 1)Vt = SVtÎ›t is repeatedly solved to obtain eigenvectors Vt
_âˆ’_
and density matrixconvergence threshold. The detailed routine is shown in Algorithm 3. Pt = 2VtVt[âŠ¤] at the t-th iterations, t = 1, 2, Â· Â· Â·, until |Pt âˆ’ _Ptâˆ’1| is less than the_

To solve the generalized eigen-decomposition problem, it should be transformed to standard form
first. To achieve this, the orthogonalization technique introduced in (Szabo & Ostlund, 1996) is
applied to eliminate the overlap matrix S. First, find a linear transformation X so that X _[âŠ¤]SX = I._
There are several ways to achieve this, a popular one is named â€œcanonical orthogonalizationâ€
which lets X = U diag(s[âˆ’][1][/][2]), where U and s are all eigenvectors and eigenvalues of S. Note
that all eigenvalues of S are positive so there is no difficulty of taking square roots. Then let
_V_ _[â€²]_ = X _[âˆ’][1]V (V = XV_ _[â€²]), we have F_ (V )XV _[â€²]_ = SXV _[â€²]Î›. Multiply X_ _[âŠ¤]_ on the left and we
have X _[âŠ¤]F_ (V )XV _[â€²]_ = X _[âŠ¤]SXV_ _[â€²]Î›. Let F_ _[â€²](V ) = X_ _[âŠ¤]F_ (V )X, we have

_F_ _[â€²](V )V_ _[â€²]_ = V _[â€²]Î›_ (9)

which is a standard eigen-decomposition problem.

**Algorithm 3 Self-Consistent Field (SCF) method**

**Input: H, S, Ueff(Â·) in equation 1 and equation 2. Converge threshold Ïµ.**
**Output: V** _[âˆ—], the solution of equation 1_

Obtain initial density matrix P0 via initial guess methods (e.g., SAD or core Hamiltonian).
Find X satisfying X _[âŠ¤]SX = I._
_t â†_ 0
**while** _Pt_ _Pt_ 1 _< Ïµ do_

_tFF â†tt |[â€²] â†[â†]t âˆ’ + 1H[X] +[âŠ¤][F] Uâˆ’[t][X]eff|_ (Pt)
Obtain precise eigenvectors Vt[â€²] [of][ F][ â€²]tâˆ’1 [corresponding to the top-][k][ smallest eigenvalues via]
classical eigen-decomposition methods such as QR iteration.

_VPtt â† â†_ _XV2VttV[â€²]_ _t[âŠ¤]_

**end while**
_V_ _Vt_

_[âˆ—]_ _â†_

C PROOF

Proof of Proposition 1:

_Proof. V_ _[âˆ—]_ being the solution of equation 1 means that V _[âˆ—]_ contains the generalized eigenvectors
corresponding to the top-k smallest generalized eigenvalues of [F (V _[âˆ—]), S]. In Algorithm 1, we_
denote the converged V _[â€²]_ in the final step as V _[âˆ—â€²]. With the orthogonalization technique introduced in_
Appendix B, V _[âˆ—]_ being the solution of equation 1 is equivalent to

1. V _[âˆ—â€²]_ = X _[âˆ’][1]V_ _[âˆ—]_ contains the eigenvectors corresponding to the top-k smallest eigenvalues
of F _[âˆ—â€²]._

2. F _[âˆ—â€²]_ = X _[âŠ¤]F_ (V _[âˆ—])X._

When V _[â€²]_ in the iteration of Algorithm 1 is equal to the converged solution V _[âˆ—â€²], F_ _[âˆ—â€²]_ = X _[âŠ¤]F_ (V _[âˆ—])X_
holds. Since V _[âˆ—â€²]_ is already converged, the one-step decomposition of âˆ’F _[âˆ—â€²]_ will produce no update for V _[âˆ—â€²]. For Ojaâ€™s algorithm equation 3, letting M = âˆ’F_ _[âˆ—â€²], this means (v1[âˆ—][,][ Â· Â· Â·][, v]k[âˆ—][) =]_
_QR(v1[âˆ—]_ [+][ Î·Mv]1[âˆ—][,][ Â· Â· Â·][, v]k[âˆ—] [+][ Î·Mv]k[âˆ—][)][, Î· >][ 0][. Note that][ v]1[âˆ—][,][ Â· Â· Â·][, v]k[âˆ—] [are orthonormal guaranteed by the]
QR decomposition. Considering that the QR decomposition is implemented via the Gram-Schmidt
process, starting from i = 1, we have


_Î²1v1[âˆ—]_ [=][ v]1[âˆ—] [+][ Î·Mv]1[âˆ—] 1 [=][ Î²][1][ âˆ’] [1] _v1[âˆ—]_

_[â‡’]_ _[Mv][âˆ—]_ _Î·_

_Î²2v2[âˆ—]_ [=][ v]2[âˆ—] [+][ Î·Mv]2[âˆ—] _[âˆ’]_ [[(][v]2[âˆ—] [+][ Î·Mv]2[âˆ—][)][âŠ¤][v]1[âˆ—][]][v]1[âˆ—]


-----

= v2[âˆ—] [+][ Î·Mv]2[âˆ—] _[âˆ’]_ [[][v]2[âˆ—âŠ¤][v]1[âˆ—] [+][ Î·v]2[âˆ—âŠ¤][M][ âŠ¤][v]1[âˆ—][]][v]1[âˆ—]

_Î²1_ 1
= v2[âˆ—] [+][ Î·Mv]2[âˆ—] 2 _âˆ’_ _v1[âˆ—][]][v]1[âˆ—]_

_[âˆ’]_ [[][Î·v][âˆ—âŠ¤] _Î·_

= v2[âˆ—] [+][ Î·Mv]2[âˆ—] 2 [=][ Î²][2][ âˆ’] [1] _v2[âˆ—]_

_[â‡’]_ _[Mv][âˆ—]_ _Î·_

_Â· Â· Â·_

factors. Therefore,in which Î²1 = âˆ¥v1[âˆ—] v[+]1[âˆ—][ Î·Mv][,][ Â· Â· Â·][, v]1[âˆ—][âˆ¥]k[âˆ—][, Î²][are all eigenvectors of][2] [=][ âˆ¥][v]2[âˆ—] [+][ Î·Mv]2[âˆ—] _[âˆ’][ âˆ’][[(][v][F]2[âˆ—][ âˆ—â€²][+][.]_ _[ Î·Mv]2[âˆ—][)][âŠ¤][v]1[âˆ—][]][v]1[âˆ—][âˆ¥][,][ Â· Â· Â·][ are normalization]_

To show that v1[âˆ—][,][ Â· Â· Â·][, v]k[âˆ—] [are eigenvectors corresponding to the top-][k][ eigenvalues, we mainly follow]
(Oja & Karhunen, 1985) and (Hertz et al., 2018). We start from k = 1 to show that v1[âˆ—] [should]
correspond to the largest eigenvalue Î»1 of âˆ’F _[âˆ—â€²]_ to be a stable convergence point.

First, for v1, the QR decomposition degenerates to normalization, that is

_F_ _[â€²]_ _â†_ _X_ _[âŠ¤]F_ (v1)X, _v1[â€²]_ _[â†]_ _[v][1]_ [+][ Î·][(][âˆ’][F][ â€²][)][v][1][,] _v1 â†_ _âˆ¥vv11[â€²][â€²]_ _[âˆ¥]_

Assuming Î· is small enough, it can be expanded as a power series of Î·. By ignoring O(Î·[2]) terms,
we have
_F_ _[â€²]_ _â†_ _X_ _[âŠ¤]F_ (v1)X, _v1 â†_ _v1 + Î·âˆ†v1,_ âˆ†v1 = (âˆ’F _[â€²])v1 âˆ’_ [v1[âŠ¤][(][âˆ’][F][ â€²][)][v][1][]][v][1]
While we have a converged solution v1[âˆ—][, we already know that it is an eigenvector but do not know]
which eigenvalue it corresponds to. In this case, we assume that after a series of iterations, v1 is
very close to the eigenvector corresponding to the Î±th largest eigenvalue (denoted as v[Î±]) of the final
converged matrix âˆ’F _[âˆ—â€²]_ = âˆ’X _[âŠ¤]F_ (v1[âˆ—][)][X][, that is]
_v1 = v[Î±]_ + Ïµ
where Ïµ is a very small perturbation vector. Since we already know that v1[âˆ—] [is an eigenvector, we]
have v1[âˆ—] [=][ v][Î±][.]

Let M = âˆ’F _[âˆ—â€²]_ = âˆ’X _[âŠ¤]F_ (v1[âˆ—][)][X][ and][ E][ =][ X] _[âŠ¤][F]_ [(][v]1[âˆ—][)][X][ âˆ’] _[X]_ _[âŠ¤][F]_ [(][v][1][)][X][ =][ âˆ’][F][ â€²][ âˆ’] _[M][ â‡’âˆ’][F][ â€²][ =]_
_M + E. From the assumption in the proposition, we have Ev1 = O(Ïµ[2]). Then we do one-step_
iteration as follows:
âˆ†v1 = (âˆ’F _[â€²])v1 âˆ’_ [v1[âŠ¤][(][âˆ’][F][ â€²][)][v][1][]][v][1]
= (M + E)v1 [v1[âŠ¤][(][M][ +][ E][)][v][1][]][v][1]
_âˆ’_
= M (v[Î±] + Ïµ) âˆ’ [(v[Î±] + Ïµ)[âŠ¤]M (v[Î±] + Ïµ)](v[Î±] + Ïµ) + O(Ïµ[2])

= (M + E)(v[Î±] + Ïµ) âˆ’ [(v[Î±] + Ïµ)[âŠ¤](M + E)(v[Î±] + Ïµ)](v[Î±] + Ïµ)

= Î»[Î±]v[Î±] + MÏµ âˆ’ (v[Î±][âŠ¤]Mv[Î±])v[Î±] _âˆ’_ (Ïµ[âŠ¤]Mv[Î±])v[Î±] _âˆ’_ (v[Î±]MÏµ)v[Î±] _âˆ’_ (v[Î±][âŠ¤]Mv[Î±])Ïµ + O(Ïµ[2])

= MÏµ âˆ’ 2Î»[Î±](Ïµ[âŠ¤]v[Î±])v[Î±] _âˆ’_ _Î»[Î±]Ïµ + O(Ïµ[2])_

Now we want to analyse the direction of âˆ†v1 to see whether it can conquer the perturbation Ïµ and
converge to v1[âˆ—] [=][ v][Î±][ stably. We do it by multiplying another eigenvector][ v][Î²][âŠ¤] [on the left (ignoring]
the O(Ïµ[2]) term)

_v[Î²][âŠ¤]âˆ†v1 = (M_ _[âŠ¤]v[Î²])[âŠ¤]Ïµ âˆ’_ 2Î»[Î±](Ïµ[âŠ¤]v[Î±])Î´Î±Î² âˆ’ _Î»[Î±]v[Î²][âŠ¤]Ïµ_

= (Î»[Î²] _Î»[Î±])v[Î²][âŠ¤]Ïµ_ 2Î»[Î±](Ïµ[âŠ¤]v[Î±])Î´Î±Î²
_âˆ’_ _âˆ’_
We notice that, if Î² > Î± (i.e., Î»[Î²] _> Î»[Î±]), there will always exist a direction Ïµ so that both v[Î²][âŠ¤]Ïµ and_
_v[Î²][âŠ¤]âˆ†v1 are larger than zero. In this case v1 will flip to the other eigenvector thus cannot converge_
to v[Î±] stably. Therefore, Î± should be 1 so that v1[âˆ—] [=][ v][Î±][ corresponds to the largest eigenvalue of]
_âˆ’F_ _[âˆ—â€²]._

For top-k case, take k = 2 as an example, notice that the Gram-Schmidt process not only normalize
the eigenvector v2 but also orthogonalize it towards v1, so (v2 + âˆ†v2)[âŠ¤]v1 = (âˆ†v2)[âŠ¤]v1 = 0, and
we already know that v1 will converge to the eigenvector corresponding to the largest eigenvalue.
Therefore we can only select other eigenvectors out of v[1] to analyse the direction of âˆ†v2, which
shows that v2 will converge to the eigenvector corresponding to the second largest eigenvalue.


-----

D FULL-SOLVER PERFORMANCE BENCHMARK

While SCGLED is not targeted to be an extremely precise (convergence threshold less than 10[âˆ’][10]),
end-to-end solving technique due to its first-order nature, we still compare its performance toward
traditional SCF methods in a full-solver setting for reference.

We test three full-solving schemes

-  Independent SCGLED: applying our proposed method, SCGLED, as a full solver without
any tranditional SCF methods.

-  SCF + minao: applying the traditional SCF method with â€œminaoâ€ as the initial guess
method, which performs best within traditional methods as shown in subsection 5.1, and
acts as the default setting in PySCF.

-  SCF + SCGLED: applying the traditional SCF method with SCGLED as the initial guess
method.

with three settings for heuristics convergence acceleration techniques

-  Vanilla: no convergence acceleration method is applied.

-  Damping: the damping technique shown in equation 6 is applied in SCGLED or SCF
iteration.

-  DIIS: the DIIS technique (Pulay, 1980) is applied in independent SCGLED or SCF iteration. Note that DIIS is not applied when SCGLED is served as an initial guess method.

So excluding vanilla SCGLED in Algorithm 1 whose empirical performance is too poor for benchmarking, we have 8 test methods in total to be benchmarked. In Table 1, we evaluate these methods
from two aspects

-  Convergence: evaluated via the number of successfully solved molecules within the total
160 singlet molecules in W4-17 dataset.

-  Efficiency: evaluated via the averaged[3] end-to-end time cost of the method along the
molecules that are successfully solved.

For the parameter setting, when SCGLED is served as an initial method, we set T = 5000 and
_IF = 50 for Vanilla and Damping cases, which is relatively large since their performance are more_
sensitive to the quality of initial guess. For the DIIS case which are relatively not so sensitive to
the initial guess, we set T = 200 and IF = 25. When SCGLED is running independently without
traditional SCF iterations, the parameter setting stays the same as in subsection 5.2.

|Col1|Vanilla Damping DIIS|
|---|---|
|Independent SCGLED SCF + minao SCF + SCGLED|â€” 155 / 574.3 ms 160 / 657.9 ms 141 / 332.6 ms 159 / 244.3 ms 160 / 160.9 ms 149 / 190.3 ms 159 / 207.1 ms 160 / 148.7 ms|



Table 1: Benchmark results for three full-solving schemes with three heuristics convergence acceleration settings. In each cell, the former is the number of successfully solved molecules within 160
test molecules, and the latter is the averaged time cost.

The benchmark result is shown in Table 1 and Figure 6. While independent SCGLED works in the
full-solver setting, there is still a performance gap with other methods that target for full-solving
performance. Instead, SCF + SCGLED works best, especially in the Vanilla case that both the
convergence performance (unsolved molecules from 19 to 11) and efficiency performance (averaged time cost from 332.6 ms to 190.3 ms) are significantly improved. For the Damping and DIIS
case, the performance advantages are narrowed since the heuristics convergence acceleration techniques themselves become a more dominant factor for end-to-end performance. Also note that, as an

3Note that the time cost grows exponentially towards the size of the molecule, so the distribution of time
cost is quite skewed along different size of molecules. For this reason we take the logarithm of the time cost
before the average.


-----

|160|SCGLED (Damping) SCGLED (DIIS) SCF + minao (Vanilla) SCF + minao (Damping) SCF + minao (DIIS) SCF + SCGLED (Vanilla) SCF + SCGLED (Damping) SCF + SCGLED (DIIS)|
|---|---|
|||


10 1 10[0] 10[1] 10[2]

SCGLED (Damping)
SCGLED (DIIS)
SCF + minao (Vanilla)
SCF + minao (Damping)
SCF + minao (DIIS)
SCF + SCGLED (Vanilla)
SCF + SCGLED (Damping)
SCF + SCGLED (DIIS)

1 [0] [1] [2]

time cost (s)

Figure 6: Full-solver Performance Benchmark.

optimization-based method, SCGLED brings more randomness compared with traditional heuristics
initial guess methods that are built on domain knowledge. Therefore, while SCF + SCGLED performs better for most of the molecules, its distribution of time costs is wider, shown as curves with
smaller slope in Figure 6, and the end of the curve in Damping and DIIS settings can correspond to
larger time cost compared with SCF + minao.

E RESULT PER MOLECULE

In this section, we provide the description of the full numerical result listed in the supplementary
material of this paper, for all the 160 singlet molecules in the W4-17 dataset. For each molecule and
method, we list four values as follows:

-  Energy: the total Hartree-Fock energy of the molecule computed with the method (Unit:
Hartree, 1 Hartree = 4.3598 Ã— 10[âˆ’][10] Joule).

-  Energy error: the difference between the computed energy above and the exact HartreeFock energy listed in the second column of the table (expected to be as small as possible).
Note that we only keep 6 decimals due to the space limit, while the converge criterion is
stricter, so there will be some cases that the error is 0.000000 while the number of iterations
in the fourth line is not equal to zero.

-  Wall time: the wall time to run the method for the corresponding molecule.

-  Convergence: whether the computed result can reach to a converged solution with the
vanilla SCF iteration shown in Algorithm 3 (cannot reach a converged solution via SCF:
; can reach a converged solution via SCF: ; already a converged solution: ). If it can
reach to a converged solution, we also show the number of SCF iterations it costs. If the
number of SCF iterations is equal to 0, it means that the method already reaches a precise
(converged) solution before the SCF iteration.

In the result table, we bold the result if it is a dominated result over the baselines (the energy error
and wall time are both smaller than the best of the baseline methods while the number of iterations is
not larger than the best baseline). We underline the result if it takes more time than the best baseline
while the other target values are dominated. The Hcore method are not taken into account here since
both the energy error and the convergence performance are very unsatisfactory, even though it is
extremely fast.

The table shows that

-  75 out of 160 molecules contain at least one dominated result (in bold).

-  155 out of 160 molecules contain at least one more precise result (marked with underline).


-----

-  72 out of 160 molecules contain at least one result that already reached the converged solution (marked with , the number of SCF iterations is equal to 0) within 10,000 iterations
of SCGLED. That is, we already obtained the converged, precise solution. No further SCF
iterations are needed.

-  14 out of 160 molecules are successfully led to convergence by SCGLED while all the four
baseline methods failed to do so.

The full table of numerical result can be found in â€œfull numerical result.pdfâ€ as a supplementary material of this paper.


-----

