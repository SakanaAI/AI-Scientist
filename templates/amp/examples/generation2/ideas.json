[
    {
        "Name": "adaptive_reward_weighting",
        "Title": "Dynamic Loss Balancing in AMP: Adaptive Reward Weighting for Improved Motion Imitation",
        "Experiment": "Implement an adaptive reward weighting system that dynamically adjusts the balance between task and style rewards based on their relative magnitudes during training. The weights should be updated using a moving average of loss ratios. Compare pose error and task performance against the baseline AMP implementation.",
        "Interestingness": 7,
        "Feasibility": 8,
        "Novelty": 6,
        "novel": true
    },
    {
        "Name": "hierarchical_discriminator",
        "Title": "Multi-Scale Motion Assessment: Hierarchical Discriminators for Natural Movement Generation",
        "Experiment": "Modify the AMP discriminator to use a hierarchical architecture with both local and global motion discriminators. The local discriminator focuses on frame-level features while the global discriminator assesses longer temporal sequences. Compare the quality of generated motions against the baseline single discriminator approach.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 7,
        "novel": true
    },
    {
        "Name": "dataset_specialization",
        "Title": "Targeted Motion Priors: Investigating Dataset Specialization in AMP",
        "Experiment": "Compare the performance of AMP when trained on specialized motion datasets (e.g., HumanEva focused on basic locomotion) versus general motion capture collections (e.g., full AMASS dataset). Evaluate pose error and motion naturalness for specific tasks like walking.",
        "Interestingness": 6,
        "Feasibility": 9,
        "Novelty": 5,
        "novel": true
    },
    {
        "Name": "temporal_motion_discriminator",
        "Title": "Learning Natural Motion Dynamics: Temporal Discriminators for Physics-Based Character Animation",
        "Experiment": "Implement a simplified temporal discriminator using a fixed 15-frame window. Modifications: 1) Create a sequence buffer that maintains recent state history 2) Add two 1D conv layers (kernel size 5, 64 channels) followed by the existing fully connected layers 3) Compute temporal features: joint velocities and accelerations over the window. Compare against baseline using: a) average joint velocity consistency b) pose error c) discriminator loss convergence. Focus on walking motion as primary test case.",
        "Interestingness": 9,
        "Feasibility": 8,
        "Novelty": 8,
        "novel": true
    },
    {
        "Name": "curriculum_adversarial_training",
        "Title": "Balanced Curriculum Learning for Motion Imitation Networks",
        "Experiment": "Modify AMPAgent to implement dynamic learning rate adjustment: 1) Track discriminator accuracy using average output probabilities for real/fake samples 2) When discriminator accuracy exceeds 0.8, reduce policy learning rate by 50% and increase discriminator learning rate by 50% 3) When discriminator accuracy drops below 0.6, do the opposite 4) Compare against baseline using: time to convergence, final pose error, and learning stability measured by reward variance. Test on walk, run, and jump motions to verify generalization",
        "Interestingness": 8,
        "Feasibility": 9,
        "Novelty": 7,
        "novel": true
    }
]